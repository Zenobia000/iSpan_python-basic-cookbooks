{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# çµæ§‹åŒ–è³‡æ–™: CSV | Structured Data: CSV\n",
    "\n",
    "## ğŸ“ è©³è§£ç¯„ä¾‹ | Worked Examples\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ æœ¬æª”æ¡ˆç›®çš„\n",
    "\n",
    "æœ¬æª”æ¡ˆæä¾› **8 å€‹å¾ªåºæ¼¸é€²çš„è©³è§£ç¯„ä¾‹**ï¼Œæ¯å€‹ç¯„ä¾‹åŒ…å«ï¼š\n",
    "1. **å•é¡Œæè¿°**ï¼šå¯¦éš›æ‡‰ç”¨æƒ…å¢ƒ\n",
    "2. **åˆ†ææ€è·¯**ï¼šå¦‚ä½•æ‹†è§£å•é¡Œ\n",
    "3. **é€æ­¥å¯¦ä½œ**ï¼šç¨‹å¼ç¢¼ + è¨»è§£\n",
    "4. **åŸ·è¡Œçµæœ**ï¼šé æœŸè¼¸å‡º\n",
    "5. **çŸ¥è­˜é»ç¸½çµ**ï¼šå­¸åˆ°ä»€éº¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 1ï¼šå­¸ç”Ÿæˆç¸¾ CSV è®€å¯«\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "å»ºç«‹ä¸€å€‹å­¸ç”Ÿæˆç¸¾ç®¡ç†ç³»çµ±ï¼š\n",
    "1. å¯«å…¥ 5 ä½å­¸ç”Ÿçš„æˆç¸¾ï¼ˆå§“åã€æ•¸å­¸ã€è‹±æ–‡ã€ç¨‹å¼è¨­è¨ˆï¼‰\n",
    "2. è®€å– CSV æª”æ¡ˆä¸¦è¨ˆç®—æ¯ä½å­¸ç”Ÿçš„å¹³å‡åˆ†æ•¸\n",
    "3. æ‰¾å‡ºå¹³å‡æœ€é«˜çš„å­¸ç”Ÿ\n",
    "\n",
    "**é›£åº¦**ï¼šåŸºç¤\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. **å¯«å…¥éšæ®µ**ï¼šä½¿ç”¨ `csv.DictWriter` å»ºç«‹çµæ§‹åŒ– CSV\n",
    "2. **è®€å–éšæ®µ**ï¼šä½¿ç”¨ `csv.DictReader` è®€å–ä¸¦è¨ˆç®—\n",
    "3. **è³‡æ–™è™•ç†**ï¼šæ³¨æ„å‹åˆ¥è½‰æ›ï¼ˆå­—ä¸²â†’æ•´æ•¸ï¼‰\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# å»ºç«‹æ¸¬è©¦ç›®éŒ„\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 1ï¼šå­¸ç”Ÿæˆç¸¾ CSV è®€å¯« ===\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šæº–å‚™å­¸ç”Ÿæˆç¸¾è³‡æ–™\n",
    "students_data = [\n",
    "    {'å§“å': 'Alice', 'æ•¸å­¸': 85, 'è‹±æ–‡': 90, 'ç¨‹å¼è¨­è¨ˆ': 92},\n",
    "    {'å§“å': 'Bob', 'æ•¸å­¸': 78, 'è‹±æ–‡': 85, 'ç¨‹å¼è¨­è¨ˆ': 88},\n",
    "    {'å§“å': 'Charlie', 'æ•¸å­¸': 92, 'è‹±æ–‡': 88, 'ç¨‹å¼è¨­è¨ˆ': 95},\n",
    "    {'å§“å': 'David', 'æ•¸å­¸': 88, 'è‹±æ–‡': 92, 'ç¨‹å¼è¨­è¨ˆ': 90},\n",
    "    {'å§“å': 'Eve', 'æ•¸å­¸': 95, 'è‹±æ–‡': 96, 'ç¨‹å¼è¨­è¨ˆ': 98}\n",
    "]\n",
    "\n",
    "csv_file = test_dir / 'students_scores.csv'\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šå¯«å…¥ CSV æª”æ¡ˆ\n",
    "print(\"æ­¥é©Ÿ 1: å¯«å…¥å­¸ç”Ÿæˆç¸¾è³‡æ–™\")\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['å§“å', 'æ•¸å­¸', 'è‹±æ–‡', 'ç¨‹å¼è¨­è¨ˆ']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # å¯«å…¥æ¨™é¡Œåˆ—\n",
    "    writer.writerows(students_data)  # å¯«å…¥æ‰€æœ‰è³‡æ–™\n",
    "\n",
    "print(f\"âœ“ å·²å¯«å…¥ {len(students_data)} ä½å­¸ç”Ÿçš„æˆç¸¾\")\n",
    "print(f\"âœ“ æª”æ¡ˆä½ç½®: {csv_file}\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šè®€å–ä¸¦è¨ˆç®—å¹³å‡åˆ†æ•¸\n",
    "print(\"æ­¥é©Ÿ 2: è®€å–ä¸¦è¨ˆç®—å¹³å‡åˆ†æ•¸\")\n",
    "print()\n",
    "\n",
    "students_with_avg = []\n",
    "\n",
    "with open(csv_file, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        name = row['å§“å']\n",
    "        # æ³¨æ„ï¼šCSV è®€å–çš„éƒ½æ˜¯å­—ä¸²ï¼Œéœ€è½‰æ›ç‚ºæ•´æ•¸\n",
    "        math = int(row['æ•¸å­¸'])\n",
    "        english = int(row['è‹±æ–‡'])\n",
    "        programming = int(row['ç¨‹å¼è¨­è¨ˆ'])\n",
    "        \n",
    "        # è¨ˆç®—å¹³å‡\n",
    "        average = (math + english + programming) / 3\n",
    "        \n",
    "        students_with_avg.append({\n",
    "            'å§“å': name,\n",
    "            'å¹³å‡': average\n",
    "        })\n",
    "        \n",
    "        print(f\"{name:10s} | æ•¸å­¸: {math:2d} | è‹±æ–‡: {english:2d} | ç¨‹å¼: {programming:2d} | å¹³å‡: {average:.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šæ‰¾å‡ºå¹³å‡æœ€é«˜çš„å­¸ç”Ÿ\n",
    "print(\"æ­¥é©Ÿ 3: æ‰¾å‡ºå¹³å‡æœ€é«˜çš„å­¸ç”Ÿ\")\n",
    "best_student = max(students_with_avg, key=lambda s: s['å¹³å‡'])\n",
    "print(f\"ğŸ† æœ€é«˜å¹³å‡: {best_student['å§“å']} ({best_student['å¹³å‡']:.2f} åˆ†)\")\n",
    "print()\n",
    "\n",
    "# æª¢è¦–å¯¦éš›æª”æ¡ˆå…§å®¹\n",
    "print(\"æ­¥é©Ÿ 4: å¯¦éš› CSV æª”æ¡ˆå…§å®¹\")\n",
    "print(\"=\"*50)\n",
    "print(csv_file.read_text(encoding='utf-8'))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… ä½¿ç”¨ `csv.DictWriter` é€²è¡Œçµæ§‹åŒ–å¯«å…¥\n",
    "- âœ… `writeheader()` è‡ªå‹•å¯«å…¥æ¨™é¡Œåˆ—\n",
    "- âœ… `csv.DictReader` è®€å–æ™‚è‡ªå‹•å°æ‡‰æ¬„ä½åç¨±\n",
    "- âœ… **é‡è¦**ï¼šCSV è®€å–çš„æ‰€æœ‰è³‡æ–™éƒ½æ˜¯å­—ä¸²ï¼Œéœ€æ‰‹å‹•è½‰æ›å‹åˆ¥\n",
    "- âœ… ä½¿ç”¨ `max()` + `lambda` æ‰¾å‡ºæœ€å¤§å€¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 2ï¼šå•†å“è³‡æ–™éæ¿¾èˆ‡åŒ¯å‡º\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "æœ‰ä¸€å€‹å•†å“æ¸…å–® CSV æª”æ¡ˆï¼Œéœ€è¦ï¼š\n",
    "1. è®€å–æ‰€æœ‰å•†å“è³‡æ–™\n",
    "2. ç¯©é¸å‡ºåº«å­˜ä½æ–¼ 50 çš„å•†å“ï¼ˆéœ€è¦è£œè²¨ï¼‰\n",
    "3. å°‡ç¯©é¸çµæœå¯«å…¥æ–°çš„ CSV æª”æ¡ˆ\n",
    "4. é¡¯ç¤ºéœ€è¦è£œè²¨çš„å•†å“çµ±è¨ˆ\n",
    "\n",
    "**é›£åº¦**ï¼šä¸­ç´š\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. å»ºç«‹æ¸¬è©¦è³‡æ–™ï¼ˆ10 å€‹å•†å“ï¼‰\n",
    "2. ä½¿ç”¨ `DictReader` è®€å–ä¸¦éæ¿¾\n",
    "3. ä½¿ç”¨ `DictWriter` å¯«å…¥éæ¿¾çµæœ\n",
    "4. è¨ˆç®—çµ±è¨ˆè³‡è¨Š\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 2ï¼šå•†å“è³‡æ–™éæ¿¾èˆ‡åŒ¯å‡º ===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šå»ºç«‹æ¸¬è©¦å•†å“è³‡æ–™\n",
    "products = [\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P001', 'ç”¢å“åç¨±': 'è˜‹æœ', 'åƒ¹æ ¼': 50, 'åº«å­˜': 120},\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P002', 'ç”¢å“åç¨±': 'é¦™è•‰', 'åƒ¹æ ¼': 30, 'åº«å­˜': 25},  # éœ€è£œè²¨\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P003', 'ç”¢å“åç¨±': 'æ©˜å­', 'åƒ¹æ ¼': 40, 'åº«å­˜': 80},\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P004', 'ç”¢å“åç¨±': 'èŠ’æœ', 'åƒ¹æ ¼': 60, 'åº«å­˜': 15},  # éœ€è£œè²¨\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P005', 'ç”¢å“åç¨±': 'è‘¡è„', 'åƒ¹æ ¼': 80, 'åº«å­˜': 60},\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P006', 'ç”¢å“åç¨±': 'è¥¿ç“œ', 'åƒ¹æ ¼': 100, 'åº«å­˜': 10},  # éœ€è£œè²¨\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P007', 'ç”¢å“åç¨±': 'é³³æ¢¨', 'åƒ¹æ ¼': 55, 'åº«å­˜': 45},  # éœ€è£œè²¨\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P008', 'ç”¢å“åç¨±': 'è‰è“', 'åƒ¹æ ¼': 120, 'åº«å­˜': 70},\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P009', 'ç”¢å“åç¨±': 'æ«»æ¡ƒ', 'åƒ¹æ ¼': 150, 'åº«å­˜': 5},   # éœ€è£œè²¨\n",
    "    {'ç”¢å“ç·¨è™Ÿ': 'P010', 'ç”¢å“åç¨±': 'æ°´èœœæ¡ƒ', 'åƒ¹æ ¼': 90, 'åº«å­˜': 55}\n",
    "]\n",
    "\n",
    "products_csv = test_dir / 'products.csv'\n",
    "\n",
    "# å¯«å…¥åŸå§‹å•†å“è³‡æ–™\n",
    "print(\"æ­¥é©Ÿ 1: å»ºç«‹å•†å“è³‡æ–™æª”æ¡ˆ\")\n",
    "with open(products_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['ç”¢å“ç·¨è™Ÿ', 'ç”¢å“åç¨±', 'åƒ¹æ ¼', 'åº«å­˜']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(products)\n",
    "\n",
    "print(f\"âœ“ å·²å»ºç«‹ {len(products)} å€‹å•†å“\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šè®€å–ä¸¦éæ¿¾ä½åº«å­˜å•†å“\n",
    "print(\"æ­¥é©Ÿ 2: ç¯©é¸åº«å­˜ä½æ–¼ 50 çš„å•†å“\")\n",
    "print()\n",
    "\n",
    "LOW_STOCK_THRESHOLD = 50\n",
    "low_stock_products = []\n",
    "\n",
    "with open(products_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        stock = int(row['åº«å­˜'])\n",
    "        \n",
    "        # éæ¿¾æ¢ä»¶ï¼šåº«å­˜ < 50\n",
    "        if stock < LOW_STOCK_THRESHOLD:\n",
    "            low_stock_products.append(row)\n",
    "            print(f\"âš ï¸  {row['ç”¢å“ç·¨è™Ÿ']} | {row['ç”¢å“åç¨±']:6s} | åº«å­˜: {stock:3d} | åƒ¹æ ¼: {row['åƒ¹æ ¼']}\")\n",
    "\n",
    "print()\n",
    "print(f\"æ‰¾åˆ° {len(low_stock_products)} å€‹éœ€è¦è£œè²¨çš„å•†å“\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šåŒ¯å‡ºä½åº«å­˜å•†å“æ¸…å–®\n",
    "low_stock_csv = test_dir / 'low_stock_products.csv'\n",
    "\n",
    "print(\"æ­¥é©Ÿ 3: åŒ¯å‡ºä½åº«å­˜å•†å“æ¸…å–®\")\n",
    "with open(low_stock_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['ç”¢å“ç·¨è™Ÿ', 'ç”¢å“åç¨±', 'åƒ¹æ ¼', 'åº«å­˜']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(low_stock_products)\n",
    "\n",
    "print(f\"âœ“ å·²åŒ¯å‡ºè‡³: {low_stock_csv}\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šè¨ˆç®—çµ±è¨ˆè³‡è¨Š\n",
    "print(\"æ­¥é©Ÿ 4: çµ±è¨ˆè³‡è¨Š\")\n",
    "total_stock = sum(int(p['åº«å­˜']) for p in low_stock_products)\n",
    "total_value = sum(int(p['åƒ¹æ ¼']) * int(p['åº«å­˜']) for p in low_stock_products)\n",
    "avg_stock = total_stock / len(low_stock_products)\n",
    "\n",
    "print(f\"éœ€è£œè²¨å•†å“ç¸½æ•¸: {len(low_stock_products)} é …\")\n",
    "print(f\"ç¸½åº«å­˜é‡: {total_stock} ä»¶\")\n",
    "print(f\"å¹³å‡åº«å­˜: {avg_stock:.1f} ä»¶\")\n",
    "print(f\"ç¸½åƒ¹å€¼: ${total_value:,}\")\n",
    "print()\n",
    "\n",
    "# æª¢è¦–åŒ¯å‡ºçš„æª”æ¡ˆ\n",
    "print(\"åŒ¯å‡ºçš„ CSV æª”æ¡ˆå…§å®¹:\")\n",
    "print(\"=\"*60)\n",
    "print(low_stock_csv.read_text(encoding='utf-8'))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… ä½¿ç”¨è¿´åœˆ + æ¢ä»¶åˆ¤æ–·é€²è¡Œè³‡æ–™éæ¿¾\n",
    "- âœ… å°‡éæ¿¾çµæœæ”¶é›†åˆ°åˆ—è¡¨ä¸­\n",
    "- âœ… ä½¿ç”¨ `DictWriter` åŒ¯å‡ºéæ¿¾å¾Œçš„è³‡æ–™\n",
    "- âœ… ä½¿ç”¨ç”Ÿæˆå™¨è¡¨é”å¼è¨ˆç®—çµ±è¨ˆå€¼ï¼ˆsum + generatorï¼‰\n",
    "- âœ… å¯¦éš›æ‡‰ç”¨ï¼šåº«å­˜ç®¡ç†ã€è³‡æ–™ç¯©é¸\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 3ï¼šCSV èˆ‡ JSON æ ¼å¼äº’è½‰\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "å¯¦ä½œä¸€å€‹è³‡æ–™æ ¼å¼è½‰æ›å·¥å…·ï¼š\n",
    "1. è®€å– CSV æª”æ¡ˆä¸¦è½‰æ›ç‚º JSON æ ¼å¼\n",
    "2. è®€å– JSON æª”æ¡ˆä¸¦è½‰æ›ç‚º CSV æ ¼å¼\n",
    "3. æ¯”è¼ƒå…©ç¨®æ ¼å¼çš„æª”æ¡ˆå¤§å°èˆ‡ç‰¹æ€§\n",
    "\n",
    "**é›£åº¦**ï¼šä¸­ç´š\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. CSV â†’ JSONï¼š`DictReader` â†’ `json.dump`\n",
    "2. JSON â†’ CSVï¼š`json.load` â†’ `DictWriter`\n",
    "3. æ³¨æ„æ¬„ä½é †åºèˆ‡è³‡æ–™å‹åˆ¥\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 3ï¼šCSV èˆ‡ JSON æ ¼å¼äº’è½‰ ===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šå»ºç«‹æ¸¬è©¦è³‡æ–™ï¼ˆå“¡å·¥è³‡æ–™ï¼‰\n",
    "employees_csv = test_dir / 'employees.csv'\n",
    "employees_json = test_dir / 'employees.json'\n",
    "employees_from_json_csv = test_dir / 'employees_from_json.csv'\n",
    "\n",
    "employees_data = [\n",
    "    {'å“¡å·¥ç·¨è™Ÿ': 'E001', 'å§“å': 'å¼µä¸‰', 'éƒ¨é–€': 'å·¥ç¨‹éƒ¨', 'è–ªè³‡': 50000, 'å¹´è³‡': 3},\n",
    "    {'å“¡å·¥ç·¨è™Ÿ': 'E002', 'å§“å': 'æå››', 'éƒ¨é–€': 'æ¥­å‹™éƒ¨', 'è–ªè³‡': 45000, 'å¹´è³‡': 2},\n",
    "    {'å“¡å·¥ç·¨è™Ÿ': 'E003', 'å§“å': 'ç‹äº”', 'éƒ¨é–€': 'äººè³‡éƒ¨', 'è–ªè³‡': 48000, 'å¹´è³‡': 5},\n",
    "    {'å“¡å·¥ç·¨è™Ÿ': 'E004', 'å§“å': 'è¶™å…­', 'éƒ¨é–€': 'å·¥ç¨‹éƒ¨', 'è–ªè³‡': 52000, 'å¹´è³‡': 4}\n",
    "]\n",
    "\n",
    "# å…ˆå»ºç«‹åŸå§‹ CSV\n",
    "print(\"æº–å‚™åŸå§‹è³‡æ–™...\")\n",
    "with open(employees_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['å“¡å·¥ç·¨è™Ÿ', 'å§“å', 'éƒ¨é–€', 'è–ªè³‡', 'å¹´è³‡']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(employees_data)\n",
    "\n",
    "print(f\"âœ“ åŸå§‹ CSV å·²å»ºç«‹ ({employees_csv.stat().st_size} bytes)\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šCSV â†’ JSON\n",
    "print(\"=== è½‰æ› 1: CSV â†’ JSON ===\")\n",
    "print()\n",
    "\n",
    "# è®€å– CSV\n",
    "with open(employees_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data = list(reader)  # è½‰ç‚ºåˆ—è¡¨\n",
    "\n",
    "print(f\"å¾ CSV è®€å–äº† {len(data)} ç­†è³‡æ–™\")\n",
    "\n",
    "# å¯«å…¥ JSON\n",
    "with open(employees_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ“ å·²è½‰æ›ç‚º JSON ({employees_json.stat().st_size} bytes)\")\n",
    "print()\n",
    "\n",
    "print(\"JSON æª”æ¡ˆå…§å®¹:\")\n",
    "print(\"=\"*60)\n",
    "print(employees_json.read_text(encoding='utf-8'))\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šJSON â†’ CSV\n",
    "print(\"=== è½‰æ› 2: JSON â†’ CSV ===\")\n",
    "print()\n",
    "\n",
    "# è®€å– JSON\n",
    "with open(employees_json, encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"å¾ JSON è®€å–äº† {len(data)} ç­†è³‡æ–™\")\n",
    "\n",
    "# å¯«å…¥ CSV\n",
    "if data:  # ç¢ºä¿æœ‰è³‡æ–™\n",
    "    fieldnames = list(data[0].keys())  # å¾ç¬¬ä¸€ç­†è³‡æ–™å–å¾—æ¬„ä½åç¨±\n",
    "    \n",
    "    with open(employees_from_json_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    \n",
    "    print(f\"âœ“ å·²è½‰æ›ç‚º CSV ({employees_from_json_csv.stat().st_size} bytes)\")\n",
    "    print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šæ¯”è¼ƒåˆ†æ\n",
    "print(\"=== æ ¼å¼æ¯”è¼ƒåˆ†æ ===\")\n",
    "print()\n",
    "\n",
    "csv_size = employees_csv.stat().st_size\n",
    "json_size = employees_json.stat().st_size\n",
    "size_ratio = json_size / csv_size\n",
    "\n",
    "print(f\"CSV  æª”æ¡ˆå¤§å°: {csv_size:4d} bytes\")\n",
    "print(f\"JSON æª”æ¡ˆå¤§å°: {json_size:4d} bytes\")\n",
    "print(f\"å¤§å°æ¯”ä¾‹: JSON æ˜¯ CSV çš„ {size_ratio:.2f} å€\")\n",
    "print()\n",
    "\n",
    "print(\"æ ¼å¼ç‰¹æ€§æ¯”è¼ƒ:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'ç‰¹æ€§':<15} | {'CSV':<20} | {'JSON'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'å¯è®€æ€§':<15} | {'é«˜ (è¡¨æ ¼)':<20} | ä¸­ (çµæ§‹åŒ–)\")\n",
    "print(f\"{'æª”æ¡ˆå¤§å°':<15} | {'å°':<20} | è¼ƒå¤§ (ç´„ 1.5-2 å€)\")\n",
    "print(f\"{'è³‡æ–™å‹åˆ¥':<15} | {'å…¨æ˜¯å­—ä¸²':<20} | ä¿ç•™åŸå§‹å‹åˆ¥\")\n",
    "print(f\"{'æ”¯æ´å·¢ç‹€':<15} | {'å¦':<20} | æ˜¯\")\n",
    "print(f\"{'Excel ç›¸å®¹':<15} | {'æ˜¯':<20} | å¦\")\n",
    "print(\"-\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Œ å»ºè­°:\")\n",
    "print(\"  - è¡¨æ ¼è³‡æ–™ã€å¤§æª”æ¡ˆ â†’ ä½¿ç”¨ CSV\")\n",
    "print(\"  - API è³‡æ–™äº¤æ›ã€éœ€ä¿ç•™å‹åˆ¥ â†’ ä½¿ç”¨ JSON\")\n",
    "print(\"  - èˆ‡ Excel äº’å‹• â†’ ä½¿ç”¨ CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… CSV â†’ JSON: `DictReader` + `json.dump`\n",
    "- âœ… JSON â†’ CSV: `json.load` + `DictWriter`\n",
    "- âœ… JSON æª”æ¡ˆè¼ƒå¤§ä½†ä¿ç•™è³‡æ–™å‹åˆ¥\n",
    "- âœ… CSV æ›´è¼•é‡ä½†æ‰€æœ‰è³‡æ–™éƒ½æ˜¯å­—ä¸²\n",
    "- âœ… æ ¹æ“šéœ€æ±‚é¸æ“‡é©åˆçš„æ ¼å¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 4ï¼šè™•ç†ä¸­æ–‡èˆ‡ç‰¹æ®Šå­—å…ƒï¼ˆExcel ç›¸å®¹ï¼‰\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "å»ºç«‹ä¸€å€‹åŒ…å«ä¸­æ–‡èˆ‡ç‰¹æ®Šå­—å…ƒçš„ CSV æª”æ¡ˆï¼Œç¢ºä¿ï¼š\n",
    "1. åœ¨ Excel ä¸­èƒ½æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡\n",
    "2. æ­£ç¢ºè™•ç†æ¬„ä½ä¸­åŒ…å«é€—è™Ÿã€æ›è¡Œçš„è³‡æ–™\n",
    "3. æ¯”è¼ƒä¸åŒç·¨ç¢¼çš„æ•ˆæœ\n",
    "\n",
    "**é›£åº¦**ï¼šé€²éš\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. ä½¿ç”¨ **UTF-8-sig** ç·¨ç¢¼ï¼ˆå« BOMï¼‰ï¼Œè®“ Excel æ­£ç¢ºè¾¨è­˜\n",
    "2. csv æ¨¡çµ„æœƒè‡ªå‹•è™•ç†ç‰¹æ®Šå­—å…ƒï¼ˆåŠ å¼•è™Ÿï¼‰\n",
    "3. æ¯”è¼ƒ UTF-8 vs UTF-8-sig çš„å·®ç•°\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 4ï¼šè™•ç†ä¸­æ–‡èˆ‡ç‰¹æ®Šå­—å…ƒï¼ˆExcel ç›¸å®¹ï¼‰===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šæº–å‚™åŒ…å«ç‰¹æ®Šå­—å…ƒçš„è³‡æ–™\n",
    "print(\"æ­¥é©Ÿ 1: æº–å‚™æ¸¬è©¦è³‡æ–™ï¼ˆåŒ…å«ç‰¹æ®Šå­—å…ƒï¼‰\")\n",
    "print()\n",
    "\n",
    "special_data = [\n",
    "    {\n",
    "        'å§“å': 'å¼µä¸‰',\n",
    "        'è·ç¨±': 'è³‡æ·±å·¥ç¨‹å¸«, Team Lead',  # å«é€—è™Ÿ\n",
    "        'æŠ€èƒ½': 'Python\\nJavaScript\\nGo',  # å«æ›è¡Œ\n",
    "        'åº§å³éŠ˜': '\"Stay hungry, stay foolish\"'  # å«å¼•è™Ÿ\n",
    "    },\n",
    "    {\n",
    "        'å§“å': 'æå››',\n",
    "        'è·ç¨±': 'UI/UX è¨­è¨ˆå¸«',\n",
    "        'æŠ€èƒ½': 'Figma, Sketch, Adobe XD',  # å«é€—è™Ÿ\n",
    "        'åº§å³éŠ˜': 'è¨­è¨ˆæ”¹è®Šä¸–ç•Œ'\n",
    "    },\n",
    "    {\n",
    "        'å§“å': 'ç‹äº”',\n",
    "        'è·ç¨±': 'å°ˆæ¡ˆç¶“ç†ï¼ˆPMï¼‰',\n",
    "        'æŠ€èƒ½': 'Agile\\nScrum\\nKanban',  # å«æ›è¡Œ\n",
    "        'åº§å³éŠ˜': '\"Done is better than perfect\"'  # å«å¼•è™Ÿ\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, person in enumerate(special_data, 1):\n",
    "    print(f\"è³‡æ–™ {i}:\")\n",
    "    print(f\"  å§“å: {person['å§“å']}\")\n",
    "    print(f\"  è·ç¨±: {person['è·ç¨±']}\")\n",
    "    print(f\"  æŠ€èƒ½: {repr(person['æŠ€èƒ½'])}\")\n",
    "    print(f\"  åº§å³éŠ˜: {person['åº§å³éŠ˜']}\")\n",
    "    print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šä½¿ç”¨ UTF-8 å¯«å…¥ï¼ˆå¯èƒ½åœ¨ Windows Excel ä¸­é¡¯ç¤ºäº‚ç¢¼ï¼‰\n",
    "print(\"æ­¥é©Ÿ 2: ä½¿ç”¨ UTF-8 ç·¨ç¢¼å¯«å…¥\")\n",
    "utf8_csv = test_dir / 'special_utf8.csv'\n",
    "\n",
    "with open(utf8_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['å§“å', 'è·ç¨±', 'æŠ€èƒ½', 'åº§å³éŠ˜']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(special_data)\n",
    "\n",
    "print(f\"âœ“ UTF-8 æª”æ¡ˆ: {utf8_csv}\")\n",
    "print(f\"  æª”æ¡ˆå¤§å°: {utf8_csv.stat().st_size} bytes\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šä½¿ç”¨ UTF-8-sig å¯«å…¥ï¼ˆExcel ç›¸å®¹ï¼‰\n",
    "print(\"æ­¥é©Ÿ 3: ä½¿ç”¨ UTF-8-sig ç·¨ç¢¼å¯«å…¥ï¼ˆExcel ç›¸å®¹ï¼‰\")\n",
    "utf8sig_csv = test_dir / 'special_utf8_sig.csv'\n",
    "\n",
    "with open(utf8sig_csv, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    fieldnames = ['å§“å', 'è·ç¨±', 'æŠ€èƒ½', 'åº§å³éŠ˜']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(special_data)\n",
    "\n",
    "print(f\"âœ“ UTF-8-sig æª”æ¡ˆ: {utf8sig_csv}\")\n",
    "print(f\"  æª”æ¡ˆå¤§å°: {utf8sig_csv.stat().st_size} bytes\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šæª¢è¦–æª”æ¡ˆå…§å®¹\n",
    "print(\"æ­¥é©Ÿ 4: æª¢è¦–æª”æ¡ˆå…§å®¹ï¼ˆæ³¨æ„ç‰¹æ®Šå­—å…ƒè™•ç†ï¼‰\")\n",
    "print(\"=\"*70)\n",
    "print(utf8sig_csv.read_text(encoding='utf-8-sig'))\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Œ è§€å¯Ÿè¦é»:\")\n",
    "print(\"  1. å«é€—è™Ÿçš„æ¬„ä½ â†’ è‡ªå‹•åŠ ä¸Šé›™å¼•è™Ÿ\")\n",
    "print(\"  2. å«æ›è¡Œçš„æ¬„ä½ â†’ ç”¨é›™å¼•è™ŸåŒ…è£¹\")\n",
    "print(\"  3. å«å¼•è™Ÿçš„æ¬„ä½ â†’ å¼•è™Ÿè¢«è‡ªå‹•è·³è„«\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 5ï¼šè®€å–é©—è­‰\n",
    "print(\"æ­¥é©Ÿ 5: è®€å–é©—è­‰ï¼ˆç¢ºä¿è³‡æ–™æ­£ç¢ºé‚„åŸï¼‰\")\n",
    "print()\n",
    "\n",
    "with open(utf8sig_csv, encoding='utf-8-sig') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for i, row in enumerate(reader, 1):\n",
    "        print(f\"è®€å–ç¬¬ {i} ç­†:\")\n",
    "        print(f\"  å§“å: {row['å§“å']}\")\n",
    "        print(f\"  è·ç¨±: {row['è·ç¨±']}\")\n",
    "        print(f\"  æŠ€èƒ½: {repr(row['æŠ€èƒ½'])}\")\n",
    "        print(f\"  åº§å³éŠ˜: {row['åº§å³éŠ˜']}\")\n",
    "        print()\n",
    "\n",
    "print(\"âœ“ è³‡æ–™å®Œæ•´é‚„åŸï¼Œç„¡ä»»ä½•æå¤±\")\n",
    "print()\n",
    "\n",
    "# ç·¨ç¢¼æ¯”è¼ƒ\n",
    "print(\"=== ç·¨ç¢¼æ¯”è¼ƒ ===\")\n",
    "print()\n",
    "utf8_size = utf8_csv.stat().st_size\n",
    "utf8sig_size = utf8sig_csv.stat().st_size\n",
    "bom_size = utf8sig_size - utf8_size\n",
    "\n",
    "print(f\"UTF-8 æª”æ¡ˆ:     {utf8_size} bytes\")\n",
    "print(f\"UTF-8-sig æª”æ¡ˆ: {utf8sig_size} bytes\")\n",
    "print(f\"å·®ç•°ï¼ˆBOMï¼‰:    {bom_size} bytes\")\n",
    "print()\n",
    "print(\"ğŸ’¡ å»ºè­°:\")\n",
    "print(\"  - éœ€è¦åœ¨ Windows Excel é–‹å•Ÿ â†’ ä½¿ç”¨ UTF-8-sig\")\n",
    "print(\"  - ç´”ç¨‹å¼è™•ç† â†’ ä½¿ç”¨ UTF-8\")\n",
    "print(\"  - è·¨å¹³å°ç›¸å®¹æ€§ â†’ ä½¿ç”¨ UTF-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… **UTF-8-sig**ï¼šå« BOMï¼ŒExcel å¯æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡\n",
    "- âœ… csv æ¨¡çµ„è‡ªå‹•è™•ç†ç‰¹æ®Šå­—å…ƒï¼ˆåŠ å¼•è™Ÿã€è·³è„«ï¼‰\n",
    "- âœ… å«é€—è™Ÿã€æ›è¡Œã€å¼•è™Ÿçš„æ¬„ä½æœƒè‡ªå‹•åŠ é›™å¼•è™Ÿ\n",
    "- âœ… è®€å–æ™‚è³‡æ–™æœƒè‡ªå‹•é‚„åŸï¼Œç„¡éœ€æ‰‹å‹•è™•ç†\n",
    "- âœ… UTF-8-sig åƒ…æ¯” UTF-8 å¤š 3 bytesï¼ˆBOMï¼‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 5ï¼šCSV è³‡æ–™æ¸…ç†èˆ‡é©—è­‰\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "è™•ç†çœŸå¯¦ä¸–ç•Œçš„ã€Œé«’è³‡æ–™ã€CSV æª”æ¡ˆï¼š\n",
    "1. æª¢æ¸¬å¸¸è¦‹å•é¡Œï¼šç©ºå€¼ã€æ ¼å¼éŒ¯èª¤ã€ç•°å¸¸å€¼\n",
    "2. æ¸…ç†ä¸¦ä¿®æ­£è³‡æ–™\n",
    "3. ç”¢ç”Ÿæ¸…ç†å ±å‘Š\n",
    "4. åŒ¯å‡ºä¹¾æ·¨çš„è³‡æ–™\n",
    "\n",
    "**é›£åº¦**ï¼šé€²éš\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. å®šç¾©é©—è­‰è¦å‰‡\n",
    "2. é€åˆ—æª¢æŸ¥ä¸¦è¨˜éŒ„å•é¡Œ\n",
    "3. å¯¦æ–½æ¸…ç†ç­–ç•¥ï¼ˆä¿®æ­£æˆ–ç§»é™¤ï¼‰\n",
    "4. ç”¢ç”Ÿæ¸…ç†å‰å¾Œå°æ¯”å ±å‘Š\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 5ï¼šCSV è³‡æ–™æ¸…ç†èˆ‡é©—è­‰ ===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šå»ºç«‹ã€Œé«’è³‡æ–™ã€æª”æ¡ˆ\n",
    "print(\"æ­¥é©Ÿ 1: å»ºç«‹æ¸¬è©¦è³‡æ–™ï¼ˆåŒ…å«å„ç¨®å•é¡Œï¼‰\")\n",
    "print()\n",
    "\n",
    "dirty_csv = test_dir / 'dirty_data.csv'\n",
    "dirty_csv.write_text(\n",
    "'''å§“å,å¹´é½¡,Email,é›»è©±,è–ªè³‡\n",
    "å¼µä¸‰,25,zhang@example.com,0912345678,50000\n",
    "æå››,,li@example.com,0923456789,45000\n",
    ",30,wang@invalid,0934567890,48000\n",
    "è¶™å…­,abc,zhao@example.com,091-234-5678,52000\n",
    "éŒ¢ä¸ƒ,28,qian,0945678901,\n",
    "å­«å…«,150,sun@example.com,0956789012,30000\n",
    "å‘¨ä¹,27,zhou@example.com,123,99999999\n",
    "å³å,22,wu@example.com,0967890123,35000\n",
    "''',\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "print(\"åŸå§‹é«’è³‡æ–™å…§å®¹:\")\n",
    "print(\"=\"*70)\n",
    "print(dirty_csv.read_text(encoding='utf-8'))\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šè³‡æ–™é©—è­‰èˆ‡å•é¡Œæª¢æ¸¬\n",
    "print(\"æ­¥é©Ÿ 2: è³‡æ–™é©—è­‰èˆ‡å•é¡Œæª¢æ¸¬\")\n",
    "print()\n",
    "\n",
    "issues = []  # è¨˜éŒ„æ‰€æœ‰å•é¡Œ\n",
    "valid_rows = []  # å„²å­˜æœ‰æ•ˆè³‡æ–™\n",
    "\n",
    "def validate_email(email):\n",
    "    \"\"\"ç°¡å–®çš„ Email é©—è­‰\"\"\"\n",
    "    pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "    return re.match(pattern, email) is not None\n",
    "\n",
    "def validate_phone(phone):\n",
    "    \"\"\"å°ç£æ‰‹æ©Ÿè™Ÿç¢¼é©—è­‰ï¼ˆ09é–‹é ­10ç¢¼ï¼‰\"\"\"\n",
    "    # ç§»é™¤åˆ†éš”ç¬¦è™Ÿ\n",
    "    phone = phone.replace('-', '').replace(' ', '')\n",
    "    return phone.startswith('09') and len(phone) == 10 and phone.isdigit()\n",
    "\n",
    "with open(dirty_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for line_num, row in enumerate(reader, 2):  # å¾ç¬¬ 2 åˆ—é–‹å§‹ï¼ˆå«æ¨™é¡Œï¼‰\n",
    "        row_issues = []\n",
    "        \n",
    "        # é©—è­‰ 1: å§“åä¸å¯ç‚ºç©º\n",
    "        if not row['å§“å'].strip():\n",
    "            row_issues.append('å§“åç‚ºç©º')\n",
    "        \n",
    "        # é©—è­‰ 2: å¹´é½¡å¿…é ˆæ˜¯ 18-65 çš„æ•´æ•¸\n",
    "        try:\n",
    "            age = int(row['å¹´é½¡'])\n",
    "            if age < 18 or age > 65:\n",
    "                row_issues.append(f'å¹´é½¡ç•°å¸¸ ({age})')\n",
    "        except ValueError:\n",
    "            row_issues.append(f'å¹´é½¡æ ¼å¼éŒ¯èª¤ ({row[\"å¹´é½¡\"]})')\n",
    "        \n",
    "        # é©—è­‰ 3: Email æ ¼å¼\n",
    "        if not validate_email(row['Email']):\n",
    "            row_issues.append(f'Email æ ¼å¼éŒ¯èª¤ ({row[\"Email\"]})')\n",
    "        \n",
    "        # é©—è­‰ 4: é›»è©±æ ¼å¼\n",
    "        if not validate_phone(row['é›»è©±']):\n",
    "            row_issues.append(f'é›»è©±æ ¼å¼éŒ¯èª¤ ({row[\"é›»è©±\"]})')\n",
    "        \n",
    "        # é©—è­‰ 5: è–ªè³‡å¿…é ˆæ˜¯æ­£æ•´æ•¸\n",
    "        try:\n",
    "            salary = int(row['è–ªè³‡'])\n",
    "            if salary <= 0 or salary > 10000000:\n",
    "                row_issues.append(f'è–ªè³‡ç•°å¸¸ ({salary})')\n",
    "        except ValueError:\n",
    "            row_issues.append(f'è–ªè³‡æ ¼å¼éŒ¯èª¤ ({row[\"è–ªè³‡\"]})')\n",
    "        \n",
    "        # è¨˜éŒ„å•é¡Œ\n",
    "        if row_issues:\n",
    "            issues.append({\n",
    "                'line': line_num,\n",
    "                'data': row,\n",
    "                'issues': row_issues\n",
    "            })\n",
    "\n",
    "print(f\"æª¢æ¸¬å®Œæˆï¼ç™¼ç¾ {len(issues)} åˆ—æœ‰å•é¡Œï¼š\")\n",
    "print()\n",
    "\n",
    "for issue in issues:\n",
    "    print(f\"ç¬¬ {issue['line']} åˆ—: {issue['data']['å§“å'] or '(ç©ºç™½)'}\")\n",
    "    for problem in issue['issues']:\n",
    "        print(f\"  âŒ {problem}\")\n",
    "    print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šè³‡æ–™æ¸…ç†\n",
    "print(\"æ­¥é©Ÿ 3: è³‡æ–™æ¸…ç†\")\n",
    "print()\n",
    "\n",
    "clean_data = []\n",
    "\n",
    "with open(dirty_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        # ç­–ç•¥ 1: è·³éå§“åç‚ºç©ºçš„è³‡æ–™\n",
    "        if not row['å§“å'].strip():\n",
    "            continue\n",
    "        \n",
    "        # ç­–ç•¥ 2: ä¿®æ­£å¹´é½¡ï¼ˆç„¡æ•ˆå‰‡è¨­ç‚º 0ï¼‰\n",
    "        try:\n",
    "            age = int(row['å¹´é½¡'])\n",
    "            if age < 18 or age > 65:\n",
    "                age = 0  # æ¨™è¨˜ç‚ºç•°å¸¸\n",
    "        except ValueError:\n",
    "            age = 0\n",
    "        \n",
    "        # ç­–ç•¥ 3: ä¿®æ­£ Emailï¼ˆç„¡æ•ˆå‰‡è¨­é è¨­å€¼ï¼‰\n",
    "        email = row['Email'] if validate_email(row['Email']) else 'invalid@example.com'\n",
    "        \n",
    "        # ç­–ç•¥ 4: ä¿®æ­£é›»è©±ï¼ˆç§»é™¤åˆ†éš”ç¬¦è™Ÿï¼‰\n",
    "        phone = row['é›»è©±'].replace('-', '').replace(' ', '')\n",
    "        if not validate_phone(phone):\n",
    "            phone = '0900000000'  # é è¨­å€¼\n",
    "        \n",
    "        # ç­–ç•¥ 5: ä¿®æ­£è–ªè³‡ï¼ˆç„¡æ•ˆå‰‡è¨­ç‚º 0ï¼‰\n",
    "        try:\n",
    "            salary = int(row['è–ªè³‡'])\n",
    "            if salary <= 0 or salary > 10000000:\n",
    "                salary = 0\n",
    "        except ValueError:\n",
    "            salary = 0\n",
    "        \n",
    "        # å»ºç«‹ä¹¾æ·¨çš„è³‡æ–™\n",
    "        clean_row = {\n",
    "            'å§“å': row['å§“å'].strip(),\n",
    "            'å¹´é½¡': age,\n",
    "            'Email': email,\n",
    "            'é›»è©±': phone,\n",
    "            'è–ªè³‡': salary\n",
    "        }\n",
    "        clean_data.append(clean_row)\n",
    "\n",
    "print(f\"æ¸…ç†å®Œæˆï¼å‰©é¤˜ {len(clean_data)} åˆ—æœ‰æ•ˆè³‡æ–™\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šåŒ¯å‡ºä¹¾æ·¨çš„è³‡æ–™\n",
    "clean_csv = test_dir / 'clean_data.csv'\n",
    "\n",
    "with open(clean_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['å§“å', 'å¹´é½¡', 'Email', 'é›»è©±', 'è–ªè³‡']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(clean_data)\n",
    "\n",
    "print(f\"âœ“ ä¹¾æ·¨è³‡æ–™å·²åŒ¯å‡º: {clean_csv}\")\n",
    "print()\n",
    "\n",
    "print(\"æ¸…ç†å¾Œçš„è³‡æ–™:\")\n",
    "print(\"=\"*70)\n",
    "print(clean_csv.read_text(encoding='utf-8'))\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 5ï¼šæ¸…ç†å ±å‘Š\n",
    "print(\"=== æ¸…ç†å ±å‘Š ===\")\n",
    "print()\n",
    "print(f\"åŸå§‹è³‡æ–™: 8 åˆ—\")\n",
    "print(f\"å•é¡Œè³‡æ–™: {len(issues)} åˆ—\")\n",
    "print(f\"æ¸…ç†å¾Œ: {len(clean_data)} åˆ—\")\n",
    "print(f\"ç§»é™¤: {8 - len(clean_data)} åˆ—\")\n",
    "print()\n",
    "print(\"æ¸…ç†ç­–ç•¥:\")\n",
    "print(\"  âœ“ ç©ºå§“å â†’ ç§»é™¤è©²åˆ—\")\n",
    "print(\"  âœ“ ç„¡æ•ˆå¹´é½¡ â†’ è¨­ç‚º 0ï¼ˆæ¨™è¨˜ç•°å¸¸ï¼‰\")\n",
    "print(\"  âœ“ ç„¡æ•ˆ Email â†’ è¨­ç‚º invalid@example.com\")\n",
    "print(\"  âœ“ ç„¡æ•ˆé›»è©± â†’ è¨­ç‚º 0900000000\")\n",
    "print(\"  âœ“ ç„¡æ•ˆè–ªè³‡ â†’ è¨­ç‚º 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… ä½¿ç”¨æ­£è¦è¡¨é”å¼é©—è­‰ Email æ ¼å¼\n",
    "- âœ… å®šç¾©é©—è­‰è¦å‰‡ä¸¦é€åˆ—æª¢æŸ¥\n",
    "- âœ… æ¸…ç†ç­–ç•¥ï¼šç§»é™¤ã€ä¿®æ­£ã€å¡«å…¥é è¨­å€¼\n",
    "- âœ… è¨˜éŒ„æ‰€æœ‰å•é¡Œä»¥ä¾¿è¿½è¹¤ç¨½æ ¸\n",
    "- âœ… ç”¢ç”Ÿæ¸…ç†å‰å¾Œå°æ¯”å ±å‘Š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 6ï¼šå¤§å‹ CSV æª”æ¡ˆä¸²æµè™•ç†\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "è™•ç†åŒ…å« 10,000 ç­†è³‡æ–™çš„å¤§å‹ CSV æª”æ¡ˆï¼š\n",
    "1. æ¯”è¼ƒä¸€æ¬¡è¼‰å…¥ vs ä¸²æµè™•ç†çš„æ•ˆèƒ½\n",
    "2. å¯¦ä½œæ‰¹æ¬¡è™•ç†ï¼ˆæ¯ 1000 ç­†è™•ç†ä¸€æ¬¡ï¼‰\n",
    "3. è¨ˆç®—çµ±è¨ˆè³‡è¨Šï¼ˆä¸è¼‰å…¥å…¨éƒ¨åˆ°è¨˜æ†¶é«”ï¼‰\n",
    "\n",
    "**é›£åº¦**ï¼šé€²éš\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. ç”Ÿæˆå¤§å‹æ¸¬è©¦æª”æ¡ˆ\n",
    "2. é¿å… `list(reader)` è¼‰å…¥å…¨éƒ¨\n",
    "3. ä½¿ç”¨ for è¿´åœˆé€åˆ—è™•ç†ï¼ˆä¸²æµï¼‰\n",
    "4. æ‰¹æ¬¡ç´¯ç©è™•ç†å¹³è¡¡æ•ˆèƒ½\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 6ï¼šå¤§å‹ CSV æª”æ¡ˆä¸²æµè™•ç† ===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šç”Ÿæˆå¤§å‹æ¸¬è©¦æª”æ¡ˆ\n",
    "print(\"æ­¥é©Ÿ 1: ç”Ÿæˆå¤§å‹æ¸¬è©¦æª”æ¡ˆ (10,000 ç­†è³‡æ–™)...\")\n",
    "\n",
    "large_csv = test_dir / 'large_transactions.csv'\n",
    "NUM_RECORDS = 10000\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with open(large_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['äº¤æ˜“ID', 'æ—¥æœŸ', 'é‡‘é¡', 'åˆ†é¡', 'å‚™è¨»'])\n",
    "    writer.writeheader()\n",
    "    \n",
    "    categories = ['é£Ÿå“', 'äº¤é€š', 'å¨›æ¨‚', 'è³¼ç‰©', 'é†«ç™‚']\n",
    "    \n",
    "    for i in range(1, NUM_RECORDS + 1):\n",
    "        writer.writerow({\n",
    "            'äº¤æ˜“ID': f'T{i:06d}',\n",
    "            'æ—¥æœŸ': f'2024-{(i % 12) + 1:02d}-{(i % 28) + 1:02d}',\n",
    "            'é‡‘é¡': (i * 13) % 5000 + 100,  # 100-5100 ä¹‹é–“\n",
    "            'åˆ†é¡': categories[i % len(categories)],\n",
    "            'å‚™è¨»': f'äº¤æ˜“å‚™è¨» {i}'\n",
    "        })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "file_size = large_csv.stat().st_size\n",
    "\n",
    "print(f\"âœ“ ç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"  è¨˜éŒ„æ•¸: {NUM_RECORDS:,}\")\n",
    "print(f\"  æª”æ¡ˆå¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)\")\n",
    "print(f\"  è€—æ™‚: {elapsed:.3f} ç§’\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šéŒ¯èª¤æ–¹æ³• - ä¸€æ¬¡è¼‰å…¥å…¨éƒ¨\n",
    "print(\"æ­¥é©Ÿ 2: æ–¹æ³• A - ä¸€æ¬¡è¼‰å…¥å…¨éƒ¨ï¼ˆä¸æ¨è–¦ï¼‰\")\n",
    "print()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with open(large_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    all_data = list(reader)  # âŒ è¼‰å…¥å…¨éƒ¨åˆ°è¨˜æ†¶é«”\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"è¼‰å…¥ {len(all_data):,} ç­†è³‡æ–™\")\n",
    "print(f\"è€—æ™‚: {elapsed:.3f} ç§’\")\n",
    "print(f\"âš ï¸  è¨˜æ†¶é«”ä½¿ç”¨: æ‰€æœ‰è³‡æ–™éƒ½åœ¨è¨˜æ†¶é«”ä¸­\")\n",
    "print()\n",
    "\n",
    "# è¨ˆç®—çµ±è¨ˆï¼ˆä½¿ç”¨è¼‰å…¥çš„è³‡æ–™ï¼‰\n",
    "total_amount = sum(int(row['é‡‘é¡']) for row in all_data)\n",
    "avg_amount = total_amount / len(all_data)\n",
    "print(f\"ç¸½é‡‘é¡: ${total_amount:,}\")\n",
    "print(f\"å¹³å‡é‡‘é¡: ${avg_amount:.2f}\")\n",
    "print()\n",
    "\n",
    "del all_data  # é‡‹æ”¾è¨˜æ†¶é«”\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šæ­£ç¢ºæ–¹æ³• - ä¸²æµè™•ç†\n",
    "print(\"æ­¥é©Ÿ 3: æ–¹æ³• B - ä¸²æµè™•ç†ï¼ˆæ¨è–¦ï¼‰\")\n",
    "print()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "count = 0\n",
    "total_amount = 0\n",
    "category_counts = {}\n",
    "\n",
    "with open(large_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    # âœ… é€åˆ—è™•ç†ï¼Œä¸è¼‰å…¥å…¨éƒ¨\n",
    "    for row in reader:\n",
    "        count += 1\n",
    "        total_amount += int(row['é‡‘é¡'])\n",
    "        \n",
    "        # çµ±è¨ˆåˆ†é¡\n",
    "        category = row['åˆ†é¡']\n",
    "        category_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "elapsed = time.time() - start\n",
    "avg_amount = total_amount / count\n",
    "\n",
    "print(f\"è™•ç† {count:,} ç­†è³‡æ–™\")\n",
    "print(f\"è€—æ™‚: {elapsed:.3f} ç§’\")\n",
    "print(f\"âœ“ è¨˜æ†¶é«”ä½¿ç”¨: ç©©å®šï¼ˆåƒ…ä¿ç•™ç•¶å‰åˆ—ï¼‰\")\n",
    "print()\n",
    "print(f\"ç¸½é‡‘é¡: ${total_amount:,}\")\n",
    "print(f\"å¹³å‡é‡‘é¡: ${avg_amount:.2f}\")\n",
    "print()\n",
    "print(\"åˆ†é¡çµ±è¨ˆ:\")\n",
    "for category, count in sorted(category_counts.items()):\n",
    "    print(f\"  {category}: {count:,} ç­†\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šæ‰¹æ¬¡è™•ç†\n",
    "print(\"æ­¥é©Ÿ 4: æ–¹æ³• C - æ‰¹æ¬¡è™•ç†ï¼ˆå¹³è¡¡æ•ˆèƒ½ï¼‰\")\n",
    "print()\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "batch_num = 0\n",
    "current_batch = []\n",
    "batch_stats = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with open(large_csv, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        current_batch.append(row)\n",
    "        \n",
    "        # æ¯ç´¯ç©åˆ° BATCH_SIZE ç­†å°±è™•ç†ä¸€æ¬¡\n",
    "        if len(current_batch) >= BATCH_SIZE:\n",
    "            batch_num += 1\n",
    "            \n",
    "            # è™•ç†é€™æ‰¹è³‡æ–™\n",
    "            batch_total = sum(int(r['é‡‘é¡']) for r in current_batch)\n",
    "            batch_avg = batch_total / len(current_batch)\n",
    "            \n",
    "            batch_stats.append({\n",
    "                'batch': batch_num,\n",
    "                'count': len(current_batch),\n",
    "                'total': batch_total,\n",
    "                'avg': batch_avg\n",
    "            })\n",
    "            \n",
    "            print(f\"æ‰¹æ¬¡ {batch_num:2d}: {len(current_batch):4d} ç­† | ç¸½è¨ˆ: ${batch_total:8,} | å¹³å‡: ${batch_avg:7.2f}\")\n",
    "            \n",
    "            current_batch = []  # æ¸…ç©ºæ‰¹æ¬¡\n",
    "    \n",
    "    # è™•ç†å‰©é¤˜è³‡æ–™\n",
    "    if current_batch:\n",
    "        batch_num += 1\n",
    "        batch_total = sum(int(r['é‡‘é¡']) for r in current_batch)\n",
    "        batch_avg = batch_total / len(current_batch)\n",
    "        \n",
    "        batch_stats.append({\n",
    "            'batch': batch_num,\n",
    "            'count': len(current_batch),\n",
    "            'total': batch_total,\n",
    "            'avg': batch_avg\n",
    "        })\n",
    "        \n",
    "        print(f\"æ‰¹æ¬¡ {batch_num:2d}: {len(current_batch):4d} ç­† | ç¸½è¨ˆ: ${batch_total:8,} | å¹³å‡: ${batch_avg:7.2f}\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print()\n",
    "print(f\"å…±è™•ç† {batch_num} å€‹æ‰¹æ¬¡\")\n",
    "print(f\"è€—æ™‚: {elapsed:.3f} ç§’\")\n",
    "print()\n",
    "\n",
    "# ç¸½çµ\n",
    "print(\"=== æ•ˆèƒ½å»ºè­° ===\")\n",
    "print()\n",
    "print(\"âœ“ å°æª”æ¡ˆ (< 10MB): ä¸€æ¬¡è¼‰å…¥ OK\")\n",
    "print(\"âœ“ ä¸­æª”æ¡ˆ (10-100MB): ä¸²æµè™•ç†\")\n",
    "print(\"âœ“ å¤§æª”æ¡ˆ (> 100MB): æ‰¹æ¬¡è™•ç†\")\n",
    "print(\"âœ“ è¶…å¤§æª”æ¡ˆ (> 1GB): è€ƒæ…®ä½¿ç”¨ pandas + chunking\")\n",
    "print()\n",
    "print(\"åŸå‰‡:\")\n",
    "print(\"  1. é¿å… list(reader) è¼‰å…¥å…¨éƒ¨\")\n",
    "print(\"  2. ä½¿ç”¨ for è¿´åœˆé€åˆ—è™•ç†\")\n",
    "print(\"  3. åªä¿ç•™éœ€è¦çš„è³‡æ–™\")\n",
    "print(\"  4. æ‰¹æ¬¡è™•ç†å¹³è¡¡è¨˜æ†¶é«”èˆ‡æ•ˆèƒ½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… **ä¸²æµè™•ç†**ï¼šé€åˆ—è®€å–ï¼Œè¨˜æ†¶é«”ä½¿ç”¨ç©©å®š\n",
    "- âœ… **æ‰¹æ¬¡è™•ç†**ï¼šç´¯ç©ä¸€å®šæ•¸é‡å†è™•ç†ï¼Œå¹³è¡¡æ•ˆèƒ½\n",
    "- âœ… é¿å… `list(reader)` è¼‰å…¥å…¨éƒ¨åˆ°è¨˜æ†¶é«”\n",
    "- âœ… ä½¿ç”¨ for è¿´åœˆæ˜¯æœ€ä½³å¯¦è¸\n",
    "- âœ… é©ç”¨æ–¼è™•ç† GB ç´šåˆ¥çš„è¶…å¤§ CSV æª”æ¡ˆ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 7ï¼šä¸åŒåˆ†éš”ç¬¦è™Ÿçš„ CSV è™•ç†\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "è™•ç†ä½¿ç”¨ä¸åŒåˆ†éš”ç¬¦è™Ÿçš„è³‡æ–™æª”æ¡ˆï¼š\n",
    "1. Tab åˆ†éš”ï¼ˆTSVï¼‰\n",
    "2. åˆ†è™Ÿåˆ†éš”ï¼ˆå¸¸è¦‹æ–¼æ­æ´²ï¼‰\n",
    "3. ç®¡ç·šåˆ†éš”ï¼ˆPSVï¼‰\n",
    "4. è‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦è™Ÿ\n",
    "\n",
    "**é›£åº¦**ï¼šä¸­ç´š\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. ä½¿ç”¨ `delimiter` åƒæ•¸æŒ‡å®šåˆ†éš”ç¬¦è™Ÿ\n",
    "2. å¯¦ä½œè‡ªå‹•åµæ¸¬é‚è¼¯\n",
    "3. æ¯”è¼ƒä¸åŒåˆ†éš”ç¬¦è™Ÿçš„å„ªç¼ºé»\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 7ï¼šä¸åŒåˆ†éš”ç¬¦è™Ÿçš„ CSV è™•ç† ===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ¸¬è©¦è³‡æ–™\n",
    "test_data = [\n",
    "    {'ç”¢å“': 'è˜‹æœ', 'åƒ¹æ ¼': '50', 'æè¿°': 'æ–°é®®æ°´æœï¼Œå¯Œå«ç¶­ç”Ÿç´ C'},\n",
    "    {'ç”¢å“': 'é¦™è•‰', 'åƒ¹æ ¼': '30', 'æè¿°': 'é€²å£é¦™è•‰ï¼Œç‡Ÿé¤Šè±å¯Œ'},\n",
    "    {'ç”¢å“': 'æ©˜å­', 'åƒ¹æ ¼': '40', 'æè¿°': 'ç•¶å­£æ°´æœï¼Œé…¸ç”œå¯å£'}\n",
    "]\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šå»ºç«‹ä¸åŒåˆ†éš”ç¬¦è™Ÿçš„æª”æ¡ˆ\n",
    "print(\"æ­¥é©Ÿ 1: å»ºç«‹ä¸åŒåˆ†éš”ç¬¦è™Ÿçš„æª”æ¡ˆ\")\n",
    "print()\n",
    "\n",
    "delimiters = [\n",
    "    (',', 'comma', 'CSV (é€—è™Ÿ)', '.csv'),\n",
    "    ('\\t', 'tab', 'TSV (Tab)', '.tsv'),\n",
    "    (';', 'semicolon', 'SSV (åˆ†è™Ÿ)', '.csv'),\n",
    "    ('|', 'pipe', 'PSV (ç®¡ç·š)', '.psv')\n",
    "]\n",
    "\n",
    "files = []\n",
    "\n",
    "for delimiter, name, description, ext in delimiters:\n",
    "    filename = test_dir / f'products_{name}{ext}'\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        fieldnames = ['ç”¢å“', 'åƒ¹æ ¼', 'æè¿°']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=delimiter)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(test_data)\n",
    "    \n",
    "    files.append((filename, delimiter, description))\n",
    "    print(f\"âœ“ {description}: {filename.name}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šè®€å–ä¸åŒåˆ†éš”ç¬¦è™Ÿçš„æª”æ¡ˆ\n",
    "print(\"æ­¥é©Ÿ 2: è®€å–ä¸åŒåˆ†éš”ç¬¦è™Ÿçš„æª”æ¡ˆ\")\n",
    "print()\n",
    "\n",
    "for filename, delimiter, description in files:\n",
    "    print(f\"=== {description} ===\")\n",
    "    print(f\"æª”æ¡ˆå…§å®¹ï¼ˆåŸå§‹ï¼‰:\")\n",
    "    content = filename.read_text(encoding='utf-8')\n",
    "    print(repr(content[:100]) + '...')  # é¡¯ç¤ºå‰ 100 å­—å…ƒ\n",
    "    print()\n",
    "    \n",
    "    print(\"è§£æçµæœ:\")\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter)\n",
    "        for i, row in enumerate(reader, 1):\n",
    "            print(f\"  {i}. {row['ç”¢å“']:6s} | ${row['åƒ¹æ ¼']:3s} | {row['æè¿°']}\")\n",
    "    print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šè‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦è™Ÿ\n",
    "print(\"æ­¥é©Ÿ 3: è‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦è™Ÿ\")\n",
    "print()\n",
    "\n",
    "def detect_delimiter(file_path, possible_delimiters=[',', '\\t', ';', '|']):\n",
    "    \"\"\"\n",
    "    è‡ªå‹•åµæ¸¬ CSV æª”æ¡ˆçš„åˆ†éš”ç¬¦è™Ÿ\n",
    "    \n",
    "    ç­–ç•¥ï¼šè®€å–ç¬¬ä¸€åˆ—ï¼Œè¨ˆç®—æ¯å€‹å€™é¸åˆ†éš”ç¬¦è™Ÿå‡ºç¾çš„æ¬¡æ•¸\n",
    "    \"\"\"\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        first_line = f.readline()\n",
    "    \n",
    "    # è¨ˆç®—æ¯å€‹åˆ†éš”ç¬¦è™Ÿçš„å‡ºç¾æ¬¡æ•¸\n",
    "    counts = {}\n",
    "    for delim in possible_delimiters:\n",
    "        counts[delim] = first_line.count(delim)\n",
    "    \n",
    "    # æ‰¾å‡ºå‡ºç¾æœ€å¤šæ¬¡çš„åˆ†éš”ç¬¦è™Ÿ\n",
    "    if max(counts.values()) == 0:\n",
    "        return None\n",
    "    \n",
    "    return max(counts, key=counts.get)\n",
    "\n",
    "# æ¸¬è©¦è‡ªå‹•åµæ¸¬\n",
    "for filename, actual_delimiter, description in files:\n",
    "    detected = detect_delimiter(filename)\n",
    "    delim_name = {\n",
    "        ',': 'é€—è™Ÿ (,)',\n",
    "        '\\t': 'Tab (\\\\t)',\n",
    "        ';': 'åˆ†è™Ÿ (;)',\n",
    "        '|': 'ç®¡ç·š (|)'\n",
    "    }.get(detected, 'æœªçŸ¥')\n",
    "    \n",
    "    status = 'âœ“' if detected == actual_delimiter else 'âœ—'\n",
    "    print(f\"{status} {description:15s} â†’ åµæ¸¬ç‚º: {delim_name}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4ï¼šä½¿ç”¨ csv.Sniffer è‡ªå‹•åµæ¸¬ï¼ˆé€²éšï¼‰\n",
    "print(\"æ­¥é©Ÿ 4: ä½¿ç”¨ csv.Sniffer è‡ªå‹•åµæ¸¬ï¼ˆå…§å»ºæ–¹æ³•ï¼‰\")\n",
    "print()\n",
    "\n",
    "for filename, actual_delimiter, description in files:\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        sample = f.read(1024)  # è®€å–å‰ 1024 å­—å…ƒä½œç‚ºæ¨£æœ¬\n",
    "        f.seek(0)  # å›åˆ°é–‹é ­\n",
    "        \n",
    "        try:\n",
    "            sniffer = csv.Sniffer()\n",
    "            dialect = sniffer.sniff(sample)\n",
    "            detected = dialect.delimiter\n",
    "            \n",
    "            delim_name = {\n",
    "                ',': 'é€—è™Ÿ (,)',\n",
    "                '\\t': 'Tab (\\\\t)',\n",
    "                ';': 'åˆ†è™Ÿ (;)',\n",
    "                '|': 'ç®¡ç·š (|)'\n",
    "            }.get(detected, f'å…¶ä»– ({repr(detected)})')\n",
    "            \n",
    "            status = 'âœ“' if detected == actual_delimiter else 'âœ—'\n",
    "            print(f\"{status} {description:15s} â†’ Sniffer åµæ¸¬ç‚º: {delim_name}\")\n",
    "        \n",
    "        except csv.Error as e:\n",
    "            print(f\"âœ— {description:15s} â†’ ç„¡æ³•åµæ¸¬: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ç¸½çµ\n",
    "print(\"=== åˆ†éš”ç¬¦è™Ÿé¸æ“‡æŒ‡å— ===\")\n",
    "print()\n",
    "print(\"é€—è™Ÿ (,):  æœ€å¸¸è¦‹ï¼Œä½†è³‡æ–™ä¸­å¯èƒ½åŒ…å«é€—è™Ÿ\")\n",
    "print(\"Tab (\\\\t):  é©åˆè³‡æ–™ä¸­åŒ…å«é€—è™Ÿçš„æƒ…æ³\")\n",
    "print(\"åˆ†è™Ÿ (;):  æ­æ´²åœ°å€å¸¸ç”¨ï¼ˆå°æ•¸é»ç”¨é€—è™Ÿï¼‰\")\n",
    "print(\"ç®¡ç·š (|):  è³‡æ–™è¤‡é›œæ™‚çš„é¸æ“‡\")\n",
    "print()\n",
    "print(\"å»ºè­°:\")\n",
    "print(\"  1. å„ªå…ˆä½¿ç”¨é€—è™Ÿï¼ˆæ¨™æº–ï¼‰\")\n",
    "print(\"  2. è³‡æ–™å«é€—è™Ÿæ™‚ä½¿ç”¨ Tab\")\n",
    "print(\"  3. ä½¿ç”¨ csv.Sniffer è‡ªå‹•åµæ¸¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… ä½¿ç”¨ `delimiter` åƒæ•¸æŒ‡å®šåˆ†éš”ç¬¦è™Ÿ\n",
    "- âœ… å¸¸è¦‹åˆ†éš”ç¬¦è™Ÿï¼š`,`ã€`\\t`ã€`;`ã€`|`\n",
    "- âœ… å¯¦ä½œè‡ªå‹•åµæ¸¬é‚è¼¯ï¼ˆè¨ˆç®—å‡ºç¾æ¬¡æ•¸ï¼‰\n",
    "- âœ… `csv.Sniffer` å¯è‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦è™Ÿ\n",
    "- âœ… æ ¹æ“šè³‡æ–™ç‰¹æ€§é¸æ“‡é©åˆçš„åˆ†éš”ç¬¦è™Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 8ï¼šå¯¦æˆ° - éŠ·å”®è³‡æ–™åˆ†æç³»çµ±\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "\n",
    "å»ºç«‹ä¸€å€‹å®Œæ•´çš„éŠ·å”®è³‡æ–™åˆ†æç³»çµ±ï¼š\n",
    "1. è®€å–éŠ·å”®è¨˜éŒ„ CSV\n",
    "2. è¨ˆç®—å„ç¨®çµ±è¨ˆæŒ‡æ¨™ï¼ˆç¸½éŠ·å”®é¡ã€å¹³å‡å–®åƒ¹ã€æœ€æš¢éŠ·å•†å“ï¼‰\n",
    "3. æŒ‰æœˆä»½åˆ†çµ„åˆ†æ\n",
    "4. ç”¢ç”Ÿåˆ†æå ±å‘Šä¸¦åŒ¯å‡º\n",
    "\n",
    "**é›£åº¦**ï¼šç¶œåˆæ‡‰ç”¨\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "\n",
    "1. è¨­è¨ˆè³‡æ–™çµæ§‹ï¼ˆéŠ·å”®è¨˜éŒ„ï¼‰\n",
    "2. ä½¿ç”¨ DictReader è®€å–\n",
    "3. é€²è¡Œå¤šç¶­åº¦åˆ†æ\n",
    "4. åŒ¯å‡ºåˆ†æçµæœ\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=== ç¯„ä¾‹ 8ï¼šå¯¦æˆ° - éŠ·å”®è³‡æ–™åˆ†æç³»çµ± ===\")\n",
    "print()\n",
    "\n",
    "test_dir = Path('csv_worked_examples')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ­¥é©Ÿ 1ï¼šå»ºç«‹éŠ·å”®è³‡æ–™\n",
    "print(\"æ­¥é©Ÿ 1: å»ºç«‹æ¸¬è©¦éŠ·å”®è³‡æ–™\")\n",
    "print()\n",
    "\n",
    "sales_data = [\n",
    "    {'æ—¥æœŸ': '2024-01-05', 'ç”¢å“': 'Python æ›¸ç±', 'æ•¸é‡': 5, 'å–®åƒ¹': 450},\n",
    "    {'æ—¥æœŸ': '2024-01-10', 'ç”¢å“': 'JavaScript æ›¸ç±', 'æ•¸é‡': 3, 'å–®åƒ¹': 500},\n",
    "    {'æ—¥æœŸ': '2024-01-15', 'ç”¢å“': 'Python æ›¸ç±', 'æ•¸é‡': 8, 'å–®åƒ¹': 450},\n",
    "    {'æ—¥æœŸ': '2024-02-03', 'ç”¢å“': 'Java æ›¸ç±', 'æ•¸é‡': 6, 'å–®åƒ¹': 480},\n",
    "    {'æ—¥æœŸ': '2024-02-08', 'ç”¢å“': 'Python æ›¸ç±', 'æ•¸é‡': 10, 'å–®åƒ¹': 450},\n",
    "    {'æ—¥æœŸ': '2024-02-12', 'ç”¢å“': 'JavaScript æ›¸ç±', 'æ•¸é‡': 7, 'å–®åƒ¹': 500},\n",
    "    {'æ—¥æœŸ': '2024-03-01', 'ç”¢å“': 'Go æ›¸ç±', 'æ•¸é‡': 4, 'å–®åƒ¹': 550},\n",
    "    {'æ—¥æœŸ': '2024-03-07', 'ç”¢å“': 'Python æ›¸ç±', 'æ•¸é‡': 12, 'å–®åƒ¹': 450},\n",
    "    {'æ—¥æœŸ': '2024-03-15', 'ç”¢å“': 'Java æ›¸ç±', 'æ•¸é‡': 9, 'å–®åƒ¹': 480},\n",
    "    {'æ—¥æœŸ': '2024-03-20', 'ç”¢å“': 'JavaScript æ›¸ç±', 'æ•¸é‡': 6, 'å–®åƒ¹': 500}\n",
    "]\n",
    "\n",
    "sales_csv = test_dir / 'sales_records.csv'\n",
    "\n",
    "with open(sales_csv, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    fieldnames = ['æ—¥æœŸ', 'ç”¢å“', 'æ•¸é‡', 'å–®åƒ¹']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sales_data)\n",
    "\n",
    "print(f\"âœ“ å»ºç«‹ {len(sales_data)} ç­†éŠ·å”®è¨˜éŒ„\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šè®€å–ä¸¦è¨ˆç®—ç¸½é«”çµ±è¨ˆ\n",
    "print(\"æ­¥é©Ÿ 2: ç¸½é«”éŠ·å”®çµ±è¨ˆ\")\n",
    "print()\n",
    "\n",
    "total_revenue = 0\n",
    "total_quantity = 0\n",
    "product_stats = defaultdict(lambda: {'quantity': 0, 'revenue': 0})\n",
    "\n",
    "with open(sales_csv, encoding='utf-8-sig') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        quantity = int(row['æ•¸é‡'])\n",
    "        price = int(row['å–®åƒ¹'])\n",
    "        revenue = quantity * price\n",
    "        product = row['ç”¢å“']\n",
    "        \n",
    "        total_revenue += revenue\n",
    "        total_quantity += quantity\n",
    "        \n",
    "        product_stats[product]['quantity'] += quantity\n",
    "        product_stats[product]['revenue'] += revenue\n",
    "\n",
    "print(f\"ç¸½éŠ·å”®é¡: ${total_revenue:,}\")\n",
    "print(f\"ç¸½éŠ·å”®é‡: {total_quantity} ä»¶\")\n",
    "print(f\"å¹³å‡å–®ç­†: ${total_revenue / len(sales_data):.2f}\")\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šç”¢å“éŠ·å”®æ’å\n",
    "print(\"æ­¥é©Ÿ 3: ç”¢å“éŠ·å”®æ’å\")\n",
    "print()\n",
    "\n",
    "print(f\"{'ç”¢å“':<20} | {'éŠ·å”®é‡':>6} | {'éŠ·å”®é¡':>10} | {'å¹³å‡å–®åƒ¹':>8}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# æŒ‰éŠ·å”®é¡æ’åº\n",
    "sorted_products = sorted(\n",
    "    product_stats.items(),\n",
    "    key=lambda x: x[1]['revenue'],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for product, stats in sorted_products:\n",
    "    quantity = stats['quantity']\n",
    "    revenue = stats['revenue']\n",
    "    avg_price = revenue / quantity\n",
    "    print(f\"{product:<20} | {quantity:6d} | ${revenue:9,} | ${avg_price:7.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 4: æŒ‰æœˆä»½åˆ†æ\n",
    "print(\"æ­¥é©Ÿ 4: æŒ‰æœˆä»½åˆ†æ\")\n",
    "print()\n",
    "\n",
    "monthly_stats = defaultdict(lambda: {'revenue': 0, 'quantity': 0, 'orders': 0})\n",
    "\n",
    "with open(sales_csv, encoding='utf-8-sig') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        date = row['æ—¥æœŸ']\n",
    "        month = date[:7]  # å– YYYY-MM\n",
    "        \n",
    "        quantity = int(row['æ•¸é‡'])\n",
    "        price = int(row['å–®åƒ¹'])\n",
    "        revenue = quantity * price\n",
    "        \n",
    "        monthly_stats[month]['revenue'] += revenue\n",
    "        monthly_stats[month]['quantity'] += quantity\n",
    "        monthly_stats[month]['orders'] += 1\n",
    "\n",
    "print(f\"{'æœˆä»½':<10} | {'è¨‚å–®æ•¸':>6} | {'éŠ·å”®é‡':>6} | {'éŠ·å”®é¡':>10} | {'å¹³å‡è¨‚å–®':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for month in sorted(monthly_stats.keys()):\n",
    "    stats = monthly_stats[month]\n",
    "    orders = stats['orders']\n",
    "    quantity = stats['quantity']\n",
    "    revenue = stats['revenue']\n",
    "    avg_order = revenue / orders\n",
    "    \n",
    "    print(f\"{month:<10} | {orders:6d} | {quantity:6d} | ${revenue:9,} | ${avg_order:9.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# æ­¥é©Ÿ 5: åŒ¯å‡ºåˆ†æå ±å‘Š\n",
    "print(\"æ­¥é©Ÿ 5: åŒ¯å‡ºåˆ†æå ±å‘Š\")\n",
    "print()\n",
    "\n",
    "report_csv = test_dir / 'sales_report.csv'\n",
    "\n",
    "with open(report_csv, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    fieldnames = ['ç”¢å“', 'éŠ·å”®é‡', 'éŠ·å”®é¡', 'å¹³å‡å–®åƒ¹', 'æ’å']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for rank, (product, stats) in enumerate(sorted_products, 1):\n",
    "        writer.writerow({\n",
    "            'ç”¢å“': product,\n",
    "            'éŠ·å”®é‡': stats['quantity'],\n",
    "            'éŠ·å”®é¡': stats['revenue'],\n",
    "            'å¹³å‡å–®åƒ¹': stats['revenue'] / stats['quantity'],\n",
    "            'æ’å': rank\n",
    "        })\n",
    "\n",
    "print(f\"âœ“ åˆ†æå ±å‘Šå·²åŒ¯å‡º: {report_csv}\")\n",
    "print()\n",
    "\n",
    "print(\"å ±å‘Šå…§å®¹:\")\n",
    "print(\"=\"*60)\n",
    "print(report_csv.read_text(encoding='utf-8-sig'))\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# ç¸½çµ\n",
    "best_product = sorted_products[0]\n",
    "best_month = max(monthly_stats.items(), key=lambda x: x[1]['revenue'])\n",
    "\n",
    "print(\"=== åˆ†æç¸½çµ ===\")\n",
    "print()\n",
    "print(f\"ğŸ† æœ€æš¢éŠ·ç”¢å“: {best_product[0]}\")\n",
    "print(f\"   - éŠ·å”®é‡: {best_product[1]['quantity']} ä»¶\")\n",
    "print(f\"   - éŠ·å”®é¡: ${best_product[1]['revenue']:,}\")\n",
    "print()\n",
    "print(f\"ğŸ“… æœ€ä½³éŠ·å”®æœˆ: {best_month[0]}\")\n",
    "print(f\"   - è¨‚å–®æ•¸: {best_month[1]['orders']} ç­†\")\n",
    "print(f\"   - éŠ·å”®é¡: ${best_month[1]['revenue']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "\n",
    "- âœ… ä½¿ç”¨ `defaultdict` é€²è¡Œåˆ†çµ„çµ±è¨ˆ\n",
    "- âœ… å¤šç¶­åº¦è³‡æ–™åˆ†æï¼ˆç”¢å“ã€æœˆä»½ï¼‰\n",
    "- âœ… ä½¿ç”¨ `sorted()` + `lambda` é€²è¡Œæ’åº\n",
    "- âœ… è¨ˆç®—ç¸½é«”èˆ‡åˆ†çµ„çµ±è¨ˆæŒ‡æ¨™\n",
    "- âœ… åŒ¯å‡ºåˆ†æå ±å‘Šä¾›å¾ŒçºŒä½¿ç”¨\n",
    "- âœ… å®Œæ•´çš„å¯¦æˆ°æ‡‰ç”¨æµç¨‹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç¸½çµ\n",
    "\n",
    "æœ¬æª”æ¡ˆå®Œæˆäº† **8 å€‹å¾ªåºæ¼¸é€²çš„è©³è§£ç¯„ä¾‹**ï¼Œæ¶µè“‹ï¼š\n",
    "\n",
    "1. âœ… **åŸºç¤è®€å¯«**ï¼šå­¸ç”Ÿæˆç¸¾ç®¡ç†\n",
    "2. âœ… **è³‡æ–™éæ¿¾**ï¼šå•†å“åº«å­˜ç®¡ç†\n",
    "3. âœ… **æ ¼å¼è½‰æ›**ï¼šCSV â†” JSON\n",
    "4. âœ… **ç·¨ç¢¼è™•ç†**ï¼šä¸­æ–‡èˆ‡ Excel ç›¸å®¹\n",
    "5. âœ… **è³‡æ–™æ¸…ç†**ï¼šé©—è­‰èˆ‡ä¿®æ­£é«’è³‡æ–™\n",
    "6. âœ… **æ•ˆèƒ½å„ªåŒ–**ï¼šå¤§å‹æª”æ¡ˆä¸²æµè™•ç†\n",
    "7. âœ… **åˆ†éš”ç¬¦è™Ÿ**ï¼šå¤šæ ¼å¼æ”¯æ´èˆ‡è‡ªå‹•åµæ¸¬\n",
    "8. âœ… **ç¶œåˆæ‡‰ç”¨**ï¼šéŠ·å”®è³‡æ–™åˆ†æç³»çµ±\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**ï¼šå®Œæˆ `03-practice.ipynb` çš„èª²å ‚ç·´ç¿’ï¼Œéå›ºæ‰€å­¸ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
