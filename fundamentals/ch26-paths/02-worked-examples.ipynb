{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è·¯å¾‘èˆ‡æª”æ¡ˆç³»çµ± | Paths and File Systems\n",
    "\n",
    "## ğŸ“ è©³è§£ç¯„ä¾‹ | Worked Examples\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ æœ¬æª”æ¡ˆç›®çš„\n",
    "\n",
    "æœ¬æª”æ¡ˆæä¾› **5 å€‹å¾ªåºæ¼¸é€²çš„è©³è§£ç¯„ä¾‹**ï¼Œæ¯å€‹ç¯„ä¾‹åŒ…å«ï¼š\n",
    "1. **å•é¡Œæè¿°**ï¼šå¯¦éš›æ‡‰ç”¨æƒ…å¢ƒ\n",
    "2. **åˆ†ææ€è·¯**ï¼šå¦‚ä½•æ‹†è§£å•é¡Œ\n",
    "3. **é€æ­¥å¯¦ä½œ**ï¼šç¨‹å¼ç¢¼ + è¨»è§£\n",
    "4. **åŸ·è¡Œçµæœ**ï¼šé æœŸè¼¸å‡º\n",
    "5. **çŸ¥è­˜é»ç¸½çµ**ï¼šå­¸åˆ°ä»€éº¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 1ï¼šæª”æ¡ˆæœå°‹å·¥å…·\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "å»ºç«‹ä¸€å€‹æª”æ¡ˆæœå°‹å·¥å…·ï¼Œèƒ½å¤ ï¼š\n",
    "1. åœ¨æŒ‡å®šç›®éŒ„ä¸­æœå°‹ç‰¹å®šå‰¯æª”åçš„æª”æ¡ˆ\n",
    "2. æ”¯æ´éè¿´æœå°‹å­ç›®éŒ„\n",
    "3. é¡¯ç¤ºæª”æ¡ˆå¤§å°èˆ‡ä¿®æ”¹æ™‚é–“\n",
    "4. ä¾å¤§å°æ’åºçµæœ\n",
    "\n",
    "**é›£åº¦**ï¼šåŸºç¤-ä¸­ç´š\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "1. ä½¿ç”¨ `rglob()` éè¿´æœå°‹æª”æ¡ˆ\n",
    "2. ä½¿ç”¨ `stat()` å–å¾—æª”æ¡ˆå±¬æ€§\n",
    "3. å°‡çµæœå­˜å…¥åˆ—è¡¨ä¸¦æ’åº\n",
    "4. æ ¼å¼åŒ–è¼¸å‡ºï¼ˆæª”åã€å¤§å°ã€æ™‚é–“ï¼‰\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def search_files(directory, pattern='*', sort_by='size', reverse=True):\n",
    "    \"\"\"\n",
    "    æœå°‹æª”æ¡ˆä¸¦é¡¯ç¤ºè©³ç´°è³‡è¨Š\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        directory: æœå°‹ç›®éŒ„\n",
    "        pattern: glob æ¨¡å¼ (é è¨­ '*' æœå°‹æ‰€æœ‰)\n",
    "        sort_by: æ’åºæ–¹å¼ ('size', 'name', 'time')\n",
    "        reverse: æ˜¯å¦åå‘æ’åº\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: é©—è­‰ç›®éŒ„\n",
    "    search_dir = Path(directory)\n",
    "    if not search_dir.exists() or not search_dir.is_dir():\n",
    "        print(f\"éŒ¯èª¤ï¼š{directory} ä¸æ˜¯æœ‰æ•ˆçš„ç›®éŒ„\")\n",
    "        return\n",
    "    \n",
    "    print(f\"æœå°‹ç›®éŒ„: {search_dir.resolve()}\")\n",
    "    print(f\"æœå°‹æ¨¡å¼: {pattern}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: æœå°‹æª”æ¡ˆ\n",
    "    files = []\n",
    "    for file in search_dir.rglob(pattern):\n",
    "        if file.is_file():  # åªè™•ç†æª”æ¡ˆ\n",
    "            stat = file.stat()\n",
    "            files.append({\n",
    "                'path': file,\n",
    "                'name': file.name,\n",
    "                'size': stat.st_size,\n",
    "                'mtime': stat.st_mtime,\n",
    "                'relative': file.relative_to(search_dir)\n",
    "            })\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: æ’åº\n",
    "    if sort_by == 'size':\n",
    "        files.sort(key=lambda x: x['size'], reverse=reverse)\n",
    "    elif sort_by == 'name':\n",
    "        files.sort(key=lambda x: x['name'].lower(), reverse=reverse)\n",
    "    elif sort_by == 'time':\n",
    "        files.sort(key=lambda x: x['mtime'], reverse=reverse)\n",
    "    \n",
    "    # æ­¥é©Ÿ 4: é¡¯ç¤ºçµæœ\n",
    "    if not files:\n",
    "        print(\"æœªæ‰¾åˆ°ä»»ä½•æª”æ¡ˆ\")\n",
    "        return\n",
    "    \n",
    "    print(f\"æ‰¾åˆ° {len(files)} å€‹æª”æ¡ˆï¼š\\n\")\n",
    "    \n",
    "    # è¡¨é ­\n",
    "    print(f\"{'æª”å':<30} {'å¤§å°':>12} {'ä¿®æ”¹æ™‚é–“':>20} {'è·¯å¾‘'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # æª”æ¡ˆæ¸…å–®\n",
    "    for file in files:\n",
    "        # æ ¼å¼åŒ–å¤§å°\n",
    "        size = file['size']\n",
    "        if size < 1024:\n",
    "            size_str = f\"{size} B\"\n",
    "        elif size < 1024 * 1024:\n",
    "            size_str = f\"{size / 1024:.1f} KB\"\n",
    "        else:\n",
    "            size_str = f\"{size / (1024 * 1024):.1f} MB\"\n",
    "        \n",
    "        # æ ¼å¼åŒ–æ™‚é–“\n",
    "        mtime_str = datetime.fromtimestamp(file['mtime']).strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        # è¼¸å‡º\n",
    "        name = file['name'][:28] + '..' if len(file['name']) > 30 else file['name']\n",
    "        print(f\"{name:<30} {size_str:>12} {mtime_str:>20} {file['relative']}\")\n",
    "    \n",
    "    # çµ±è¨ˆè³‡è¨Š\n",
    "    total_size = sum(f['size'] for f in files)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ç¸½è¨ˆ: {len(files)} å€‹æª”æ¡ˆï¼Œç¸½å¤§å°: {total_size / 1024:.1f} KB\")\n",
    "\n",
    "# æ¸¬è©¦ï¼šå»ºç«‹æ¸¬è©¦ç’°å¢ƒ\n",
    "print(\"=== å»ºç«‹æ¸¬è©¦ç’°å¢ƒ ===\")\n",
    "test_dir = Path('search_test')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# å»ºç«‹å„ç¨®æª”æ¡ˆ\n",
    "(test_dir / 'small.txt').write_text('Hello' * 10)\n",
    "(test_dir / 'medium.txt').write_text('World' * 100)\n",
    "(test_dir / 'data.csv').write_text('a,b,c\\n' * 50)\n",
    "(test_dir / 'script.py').write_text('print(\"test\")' * 20)\n",
    "\n",
    "# å»ºç«‹å­ç›®éŒ„èˆ‡æª”æ¡ˆ\n",
    "subdir = test_dir / 'subdir'\n",
    "subdir.mkdir(exist_ok=True)\n",
    "(subdir / 'nested.txt').write_text('Nested content' * 30)\n",
    "(subdir / 'config.json').write_text('{\"key\": \"value\"}' * 10)\n",
    "\n",
    "print(\"\\n=== æ¸¬è©¦ 1: æœå°‹æ‰€æœ‰ .txt æª”æ¡ˆï¼ˆä¾å¤§å°æ’åºï¼‰===\")\n",
    "search_files(test_dir, '*.txt', sort_by='size')\n",
    "\n",
    "print(\"\\n\\n=== æ¸¬è©¦ 2: æœå°‹æ‰€æœ‰æª”æ¡ˆï¼ˆä¾åç¨±æ’åºï¼‰===\")\n",
    "search_files(test_dir, '*', sort_by='name', reverse=False)\n",
    "\n",
    "# æ¸…ç†\n",
    "import shutil\n",
    "shutil.rmtree(test_dir)\n",
    "print(\"\\n[æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š åŸ·è¡Œçµæœ\n",
    "```\n",
    "=== å»ºç«‹æ¸¬è©¦ç’°å¢ƒ ===\n",
    "\n",
    "=== æ¸¬è©¦ 1: æœå°‹æ‰€æœ‰ .txt æª”æ¡ˆï¼ˆä¾å¤§å°æ’åºï¼‰===\n",
    "æœå°‹ç›®éŒ„: D:\\...\\search_test\n",
    "æœå°‹æ¨¡å¼: *.txt\n",
    "================================================================================\n",
    "æ‰¾åˆ° 4 å€‹æª”æ¡ˆï¼š\n",
    "\n",
    "æª”å                                   å¤§å°             ä¿®æ”¹æ™‚é–“ è·¯å¾‘\n",
    "--------------------------------------------------------------------------------\n",
    "medium.txt                         500 B    2025-10-08 12:30 medium.txt\n",
    "nested.txt                         420 B    2025-10-08 12:30 subdir\\nested.txt\n",
    "small.txt                           50 B    2025-10-08 12:30 small.txt\n",
    "\n",
    "================================================================================\n",
    "ç¸½è¨ˆ: 4 å€‹æª”æ¡ˆï¼Œç¸½å¤§å°: 0.9 KB\n",
    "```\n",
    "\n",
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "- âœ… ä½¿ç”¨ `rglob()` éè¿´æœå°‹æª”æ¡ˆ\n",
    "- âœ… ä½¿ç”¨ `stat()` å–å¾—æª”æ¡ˆå¤§å°èˆ‡æ™‚é–“\n",
    "- âœ… ä½¿ç”¨ `relative_to()` é¡¯ç¤ºç›¸å°è·¯å¾‘\n",
    "- âœ… æ ¼å¼åŒ–æª”æ¡ˆå¤§å°ï¼ˆB/KB/MBï¼‰\n",
    "- âœ… ä½¿ç”¨ lambda å‡½å¼æ’åº\n",
    "- âœ… å­—ä¸²æ ¼å¼åŒ–å°é½Šè¼¸å‡º\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 2ï¼šç›®éŒ„æ•´ç†å™¨\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "å»ºç«‹ä¸€å€‹ç›®éŒ„æ•´ç†å·¥å…·ï¼Œèƒ½å¤ ï¼š\n",
    "1. å°‡æ··äº‚çš„æª”æ¡ˆä¾å‰¯æª”ååˆ†é¡åˆ°å­è³‡æ–™å¤¾\n",
    "2. è™•ç†åŒåæª”æ¡ˆè¡çªï¼ˆè‡ªå‹•é‡æ–°å‘½åï¼‰\n",
    "3. æ”¯æ´ä¹¾è·‘æ¨¡å¼ï¼ˆé è¦½è€Œä¸å¯¦éš›ç§»å‹•ï¼‰\n",
    "4. ç”¢ç”Ÿæ•´ç†å ±å‘Š\n",
    "\n",
    "**é›£åº¦**ï¼šä¸­ç´š\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "1. éæ­·ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ\n",
    "2. æ ¹æ“šå‰¯æª”åæ±ºå®šç›®æ¨™è³‡æ–™å¤¾\n",
    "3. æª¢æŸ¥ä¸¦è™•ç†åŒåæª”æ¡ˆ\n",
    "4. ç§»å‹•æª”æ¡ˆä¸¦è¨˜éŒ„æ“ä½œ\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def organize_directory(directory, dry_run=True, custom_categories=None):\n",
    "    \"\"\"\n",
    "    æ•´ç†ç›®éŒ„ï¼šä¾å‰¯æª”ååˆ†é¡æª”æ¡ˆ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        directory: è¦æ•´ç†çš„ç›®éŒ„\n",
    "        dry_run: True=é è¦½æ¨¡å¼ï¼ŒFalse=å¯¦éš›åŸ·è¡Œ\n",
    "        custom_categories: è‡ªè¨‚åˆ†é¡è¦å‰‡ {é¡åˆ¥åç¨±: [å‰¯æª”ååˆ—è¡¨]}\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: é è¨­åˆ†é¡è¦å‰‡\n",
    "    if custom_categories is None:\n",
    "        categories = {\n",
    "            'æ–‡ä»¶': ['.txt', '.doc', '.docx', '.pdf', '.md'],\n",
    "            'åœ–ç‰‡': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg'],\n",
    "            'å½±ç‰‡': ['.mp4', '.avi', '.mkv', '.mov'],\n",
    "            'éŸ³æ¨‚': ['.mp3', '.wav', '.flac', '.m4a'],\n",
    "            'ç¨‹å¼': ['.py', '.js', '.java', '.cpp', '.c', '.html', '.css'],\n",
    "            'è³‡æ–™': ['.csv', '.json', '.xml', '.xlsx', '.db'],\n",
    "            'å£“ç¸®': ['.zip', '.rar', '.7z', '.tar', '.gz'],\n",
    "        }\n",
    "    else:\n",
    "        categories = custom_categories\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: å»ºç«‹å‰¯æª”ååˆ°é¡åˆ¥çš„å°æ‡‰\n",
    "    ext_to_category = {}\n",
    "    for category, extensions in categories.items():\n",
    "        for ext in extensions:\n",
    "            ext_to_category[ext.lower()] = category\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: é©—è­‰ç›®éŒ„\n",
    "    source_dir = Path(directory)\n",
    "    if not source_dir.exists() or not source_dir.is_dir():\n",
    "        print(f\"éŒ¯èª¤ï¼š{directory} ä¸æ˜¯æœ‰æ•ˆçš„ç›®éŒ„\")\n",
    "        return\n",
    "    \n",
    "    mode = \"é è¦½æ¨¡å¼\" if dry_run else \"åŸ·è¡Œæ¨¡å¼\"\n",
    "    print(f\"ç›®éŒ„æ•´ç†å·¥å…· - {mode}\")\n",
    "    print(f\"ç›®æ¨™ç›®éŒ„: {source_dir.resolve()}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ­¥é©Ÿ 4: æƒææª”æ¡ˆ\n",
    "    files_to_organize = []\n",
    "    for file in source_dir.glob('*'):\n",
    "        # åªè™•ç†æª”æ¡ˆï¼Œå¿½ç•¥ç›®éŒ„\n",
    "        if file.is_file():\n",
    "            files_to_organize.append(file)\n",
    "    \n",
    "    if not files_to_organize:\n",
    "        print(\"ç›®éŒ„ä¸­æ²’æœ‰æª”æ¡ˆéœ€è¦æ•´ç†\")\n",
    "        return\n",
    "    \n",
    "    # æ­¥é©Ÿ 5: æ•´ç†æª”æ¡ˆ\n",
    "    operations = defaultdict(list)  # è¨˜éŒ„æ¯å€‹é¡åˆ¥çš„æ“ä½œ\n",
    "    conflicts = []  # è¨˜éŒ„è¡çª\n",
    "    \n",
    "    for file in files_to_organize:\n",
    "        # æ±ºå®šé¡åˆ¥\n",
    "        ext = file.suffix.lower()\n",
    "        category = ext_to_category.get(ext, 'å…¶ä»–')\n",
    "        \n",
    "        # ç›®æ¨™ç›®éŒ„\n",
    "        target_dir = source_dir / category\n",
    "        target_path = target_dir / file.name\n",
    "        \n",
    "        # è™•ç†åŒåæª”æ¡ˆ\n",
    "        if target_path.exists():\n",
    "            # ç”¢ç”Ÿæ–°æª”å: file_1.txt, file_2.txt...\n",
    "            stem = file.stem\n",
    "            suffix = file.suffix\n",
    "            counter = 1\n",
    "            while target_path.exists():\n",
    "                target_path = target_dir / f\"{stem}_{counter}{suffix}\"\n",
    "                counter += 1\n",
    "            conflicts.append((file.name, target_path.name))\n",
    "        \n",
    "        # è¨˜éŒ„æ“ä½œ\n",
    "        operations[category].append({\n",
    "            'source': file,\n",
    "            'target': target_path,\n",
    "            'target_dir': target_dir\n",
    "        })\n",
    "    \n",
    "    # æ­¥é©Ÿ 6: åŸ·è¡Œæˆ–é è¦½\n",
    "    print(f\"\\nç™¼ç¾ {len(files_to_organize)} å€‹æª”æ¡ˆéœ€è¦æ•´ç†ï¼š\\n\")\n",
    "    \n",
    "    total_moved = 0\n",
    "    for category in sorted(operations.keys()):\n",
    "        ops = operations[category]\n",
    "        print(f\"[{category}] {len(ops)} å€‹æª”æ¡ˆ\")\n",
    "        \n",
    "        # å»ºç«‹ç›®æ¨™ç›®éŒ„\n",
    "        if not dry_run:\n",
    "            ops[0]['target_dir'].mkdir(exist_ok=True)\n",
    "        \n",
    "        # ç§»å‹•æª”æ¡ˆ\n",
    "        for op in ops:\n",
    "            print(f\"  {op['source'].name} -> {category}/{op['target'].name}\")\n",
    "            if not dry_run:\n",
    "                op['source'].rename(op['target'])\n",
    "            total_moved += 1\n",
    "        print()\n",
    "    \n",
    "    # æ­¥é©Ÿ 7: å ±å‘Š\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"æ•´ç†å®Œæˆï¼\")\n",
    "    print(f\"  è™•ç†æª”æ¡ˆ: {total_moved} å€‹\")\n",
    "    print(f\"  å»ºç«‹é¡åˆ¥: {len(operations)} å€‹\")\n",
    "    if conflicts:\n",
    "        print(f\"  æª”åè¡çª: {len(conflicts)} å€‹ï¼ˆå·²è‡ªå‹•é‡æ–°å‘½åï¼‰\")\n",
    "        for original, renamed in conflicts[:3]:  # åªé¡¯ç¤ºå‰ 3 å€‹\n",
    "            print(f\"    {original} -> {renamed}\")\n",
    "    if dry_run:\n",
    "        print(\"\\nâ€» é€™æ˜¯é è¦½æ¨¡å¼ï¼Œæª”æ¡ˆå°šæœªå¯¦éš›ç§»å‹•\")\n",
    "        print(\"  è‹¥è¦å¯¦éš›åŸ·è¡Œï¼Œè«‹è¨­å®š dry_run=False\")\n",
    "\n",
    "# æ¸¬è©¦\n",
    "print(\"=== å»ºç«‹æ¸¬è©¦ç’°å¢ƒ ===\")\n",
    "test_dir = Path('organize_test')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# å»ºç«‹æ··äº‚çš„æª”æ¡ˆ\n",
    "test_files = [\n",
    "    'report.txt', 'presentation.pdf', 'notes.md',\n",
    "    'photo1.jpg', 'photo2.png', 'diagram.svg',\n",
    "    'song.mp3', 'podcast.wav',\n",
    "    'script.py', 'index.html', 'style.css',\n",
    "    'data.csv', 'config.json',\n",
    "    'archive.zip'\n",
    "]\n",
    "\n",
    "for filename in test_files:\n",
    "    (test_dir / filename).write_text('test content')\n",
    "\n",
    "print(f\"å·²å»ºç«‹ {len(test_files)} å€‹æ¸¬è©¦æª”æ¡ˆ\\n\")\n",
    "\n",
    "# æ¸¬è©¦ 1: é è¦½æ¨¡å¼\n",
    "print(\"\\n=== æ¸¬è©¦ 1: é è¦½æ¨¡å¼ ===\")\n",
    "organize_directory(test_dir, dry_run=True)\n",
    "\n",
    "# æ¸¬è©¦ 2: å¯¦éš›åŸ·è¡Œ\n",
    "print(\"\\n\\n=== æ¸¬è©¦ 2: å¯¦éš›åŸ·è¡Œ ===\")\n",
    "organize_directory(test_dir, dry_run=False)\n",
    "\n",
    "print(\"\\n=== æ•´ç†å¾Œçš„ç›®éŒ„çµæ§‹ ===\")\n",
    "for item in sorted(test_dir.rglob('*')):\n",
    "    if item.is_file():\n",
    "        print(f\"  {item.relative_to(test_dir)}\")\n",
    "\n",
    "# æ¸…ç†\n",
    "import shutil\n",
    "shutil.rmtree(test_dir)\n",
    "print(\"\\n[æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š åŸ·è¡Œçµæœ\n",
    "```\n",
    "=== æ¸¬è©¦ 2: å¯¦éš›åŸ·è¡Œ ===\n",
    "ç›®éŒ„æ•´ç†å·¥å…· - åŸ·è¡Œæ¨¡å¼\n",
    "ç›®æ¨™ç›®éŒ„: D:\\...\\organize_test\n",
    "======================================================================\n",
    "\n",
    "ç™¼ç¾ 14 å€‹æª”æ¡ˆéœ€è¦æ•´ç†ï¼š\n",
    "\n",
    "[æ–‡ä»¶] 3 å€‹æª”æ¡ˆ\n",
    "  report.txt -> æ–‡ä»¶/report.txt\n",
    "  presentation.pdf -> æ–‡ä»¶/presentation.pdf\n",
    "  notes.md -> æ–‡ä»¶/notes.md\n",
    "\n",
    "[åœ–ç‰‡] 3 å€‹æª”æ¡ˆ\n",
    "  photo1.jpg -> åœ–ç‰‡/photo1.jpg\n",
    "  photo2.png -> åœ–ç‰‡/photo2.png\n",
    "  diagram.svg -> åœ–ç‰‡/diagram.svg\n",
    "\n",
    "[éŸ³æ¨‚] 2 å€‹æª”æ¡ˆ\n",
    "  song.mp3 -> éŸ³æ¨‚/song.mp3\n",
    "  podcast.wav -> éŸ³æ¨‚/podcast.wav\n",
    "\n",
    "======================================================================\n",
    "æ•´ç†å®Œæˆï¼\n",
    "  è™•ç†æª”æ¡ˆ: 14 å€‹\n",
    "  å»ºç«‹é¡åˆ¥: 6 å€‹\n",
    "  æª”åè¡çª: 0 å€‹\n",
    "```\n",
    "\n",
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "- âœ… ä½¿ç”¨ `glob('*')` éæ­·ç›®éŒ„ï¼ˆä¸éè¿´ï¼‰\n",
    "- âœ… å‹•æ…‹å»ºç«‹åˆ†é¡ç›®éŒ„ `mkdir(exist_ok=True)`\n",
    "- âœ… è™•ç†æª”åè¡çªï¼ˆè‡ªå‹•ç·¨è™Ÿï¼‰\n",
    "- âœ… ä½¿ç”¨ `defaultdict` åˆ†çµ„è³‡æ–™\n",
    "- âœ… å¯¦ä½œä¹¾è·‘æ¨¡å¼ï¼ˆé è¦½åŠŸèƒ½ï¼‰\n",
    "- âœ… ç”¢ç”Ÿæ“ä½œå ±å‘Š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 3ï¼šè‡ªå‹•å‚™ä»½ç³»çµ±\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "å»ºç«‹ä¸€å€‹ç°¡æ˜“å‚™ä»½ç³»çµ±ï¼Œèƒ½å¤ ï¼š\n",
    "1. å°‡æŒ‡å®šç›®éŒ„å‚™ä»½åˆ°ç›®æ¨™ä½ç½®\n",
    "2. åªè¤‡è£½æ–°å¢æˆ–ä¿®æ”¹çš„æª”æ¡ˆï¼ˆå¢é‡å‚™ä»½ï¼‰\n",
    "3. ä¿æŒç›®éŒ„çµæ§‹\n",
    "4. ç”¢ç”Ÿå‚™ä»½å ±å‘Š\n",
    "\n",
    "**é›£åº¦**ï¼šä¸­ç´š-é€²éš\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "1. éæ­·ä¾†æºç›®éŒ„çš„æ‰€æœ‰æª”æ¡ˆ\n",
    "2. æ¯”è¼ƒä¾†æºèˆ‡å‚™ä»½æª”æ¡ˆçš„ä¿®æ”¹æ™‚é–“\n",
    "3. åªè¤‡è£½éœ€è¦æ›´æ–°çš„æª”æ¡ˆ\n",
    "4. å»ºç«‹å¿…è¦çš„ç›®éŒ„çµæ§‹\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "def backup_directory(source, destination, incremental=True):\n",
    "    \"\"\"\n",
    "    å‚™ä»½ç›®éŒ„\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        source: ä¾†æºç›®éŒ„\n",
    "        destination: å‚™ä»½ç›®éŒ„\n",
    "        incremental: True=å¢é‡å‚™ä»½ï¼ŒFalse=å®Œæ•´å‚™ä»½\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: é©—è­‰ä¾†æºç›®éŒ„\n",
    "    source_path = Path(source)\n",
    "    if not source_path.exists() or not source_path.is_dir():\n",
    "        print(f\"éŒ¯èª¤ï¼šä¾†æºç›®éŒ„ {source} ä¸å­˜åœ¨\")\n",
    "        return\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: å»ºç«‹å‚™ä»½ç›®éŒ„\n",
    "    dest_path = Path(destination)\n",
    "    dest_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    backup_mode = \"å¢é‡å‚™ä»½\" if incremental else \"å®Œæ•´å‚™ä»½\"\n",
    "    print(f\"å‚™ä»½ç³»çµ± - {backup_mode}\")\n",
    "    print(f\"ä¾†æº: {source_path.resolve()}\")\n",
    "    print(f\"ç›®æ¨™: {dest_path.resolve()}\")\n",
    "    print(f\"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: æƒæä¾†æºæª”æ¡ˆ\n",
    "    all_files = list(source_path.rglob('*'))\n",
    "    source_files = [f for f in all_files if f.is_file()]\n",
    "    \n",
    "    print(f\"\\næƒæåˆ° {len(source_files)} å€‹æª”æ¡ˆ\\n\")\n",
    "    \n",
    "    # æ­¥é©Ÿ 4: æ±ºå®šéœ€è¦å‚™ä»½çš„æª”æ¡ˆ\n",
    "    files_to_backup = []\n",
    "    skipped_files = []\n",
    "    \n",
    "    for source_file in source_files:\n",
    "        # è¨ˆç®—ç›®æ¨™è·¯å¾‘ï¼ˆä¿æŒç›¸å°çµæ§‹ï¼‰\n",
    "        relative_path = source_file.relative_to(source_path)\n",
    "        dest_file = dest_path / relative_path\n",
    "        \n",
    "        # æ±ºå®šæ˜¯å¦éœ€è¦è¤‡è£½\n",
    "        need_copy = False\n",
    "        reason = \"\"\n",
    "        \n",
    "        if not dest_file.exists():\n",
    "            need_copy = True\n",
    "            reason = \"æ–°æª”æ¡ˆ\"\n",
    "        elif not incremental:\n",
    "            need_copy = True\n",
    "            reason = \"å®Œæ•´å‚™ä»½\"\n",
    "        else:\n",
    "            # æ¯”è¼ƒä¿®æ”¹æ™‚é–“\n",
    "            source_mtime = source_file.stat().st_mtime\n",
    "            dest_mtime = dest_file.stat().st_mtime\n",
    "            if source_mtime > dest_mtime:\n",
    "                need_copy = True\n",
    "                reason = \"å·²ä¿®æ”¹\"\n",
    "        \n",
    "        if need_copy:\n",
    "            files_to_backup.append({\n",
    "                'source': source_file,\n",
    "                'dest': dest_file,\n",
    "                'relative': relative_path,\n",
    "                'reason': reason\n",
    "            })\n",
    "        else:\n",
    "            skipped_files.append(relative_path)\n",
    "    \n",
    "    # æ­¥é©Ÿ 5: åŸ·è¡Œå‚™ä»½\n",
    "    print(f\"éœ€è¦å‚™ä»½: {len(files_to_backup)} å€‹æª”æ¡ˆ\")\n",
    "    print(f\"ç•¥é: {len(skipped_files)} å€‹æª”æ¡ˆï¼ˆæœªä¿®æ”¹ï¼‰\\n\")\n",
    "    \n",
    "    copied_count = 0\n",
    "    total_size = 0\n",
    "    \n",
    "    for item in files_to_backup:\n",
    "        try:\n",
    "            # å»ºç«‹ç›®æ¨™ç›®éŒ„\n",
    "            item['dest'].parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # è¤‡è£½æª”æ¡ˆ\n",
    "            shutil.copy2(item['source'], item['dest'])  # copy2 ä¿ç•™æ™‚é–“æˆ³è¨˜\n",
    "            \n",
    "            # çµ±è¨ˆ\n",
    "            size = item['source'].stat().st_size\n",
    "            total_size += size\n",
    "            copied_count += 1\n",
    "            \n",
    "            # é¡¯ç¤ºé€²åº¦\n",
    "            size_kb = size / 1024\n",
    "            print(f\"[{item['reason']}] {item['relative']} ({size_kb:.1f} KB)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[éŒ¯èª¤] {item['relative']}: {e}\")\n",
    "    \n",
    "    # æ­¥é©Ÿ 6: å ±å‘Š\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"å‚™ä»½å®Œæˆï¼\")\n",
    "    print(f\"  è¤‡è£½æª”æ¡ˆ: {copied_count} å€‹\")\n",
    "    print(f\"  ç•¥éæª”æ¡ˆ: {len(skipped_files)} å€‹\")\n",
    "    print(f\"  ç¸½å¤§å°: {total_size / 1024:.1f} KB\")\n",
    "    print(f\"  çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    return {\n",
    "        'copied': copied_count,\n",
    "        'skipped': len(skipped_files),\n",
    "        'total_size': total_size\n",
    "    }\n",
    "\n",
    "# æ¸¬è©¦\n",
    "print(\"=== å»ºç«‹æ¸¬è©¦ç’°å¢ƒ ===\")\n",
    "\n",
    "# å»ºç«‹ä¾†æºç›®éŒ„\n",
    "source_dir = Path('backup_source')\n",
    "source_dir.mkdir(exist_ok=True)\n",
    "\n",
    "(source_dir / 'file1.txt').write_text('Content 1' * 100)\n",
    "(source_dir / 'file2.txt').write_text('Content 2' * 200)\n",
    "\n",
    "subdir = source_dir / 'data'\n",
    "subdir.mkdir(exist_ok=True)\n",
    "(subdir / 'data1.csv').write_text('a,b,c\\n' * 50)\n",
    "(subdir / 'data2.json').write_text('{\"key\": \"value\"}' * 30)\n",
    "\n",
    "print(\"å·²å»ºç«‹ä¾†æºç›®éŒ„\\n\")\n",
    "\n",
    "# æ¸¬è©¦ 1: é¦–æ¬¡å®Œæ•´å‚™ä»½\n",
    "print(\"=== æ¸¬è©¦ 1: é¦–æ¬¡å‚™ä»½ ===\")\n",
    "backup_directory(source_dir, 'backup_dest', incremental=True)\n",
    "\n",
    "# ä¿®æ”¹ä¸€å€‹æª”æ¡ˆ\n",
    "import time\n",
    "time.sleep(1)  # ç¢ºä¿æ™‚é–“æˆ³è¨˜ä¸åŒ\n",
    "(source_dir / 'file1.txt').write_text('Modified content' * 150)\n",
    "\n",
    "# æ¸¬è©¦ 2: å¢é‡å‚™ä»½\n",
    "print(\"\\n\\n=== æ¸¬è©¦ 2: å¢é‡å‚™ä»½ï¼ˆåªå‚™ä»½ä¿®æ”¹çš„æª”æ¡ˆï¼‰===\")\n",
    "backup_directory(source_dir, 'backup_dest', incremental=True)\n",
    "\n",
    "# æ¸…ç†\n",
    "shutil.rmtree(source_dir)\n",
    "shutil.rmtree('backup_dest')\n",
    "print(\"\\n[æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š åŸ·è¡Œçµæœ\n",
    "```\n",
    "=== æ¸¬è©¦ 2: å¢é‡å‚™ä»½ï¼ˆåªå‚™ä»½ä¿®æ”¹çš„æª”æ¡ˆï¼‰===\n",
    "å‚™ä»½ç³»çµ± - å¢é‡å‚™ä»½\n",
    "ä¾†æº: D:\\...\\backup_source\n",
    "ç›®æ¨™: D:\\...\\backup_dest\n",
    "é–‹å§‹æ™‚é–“: 2025-10-08 12:35:20\n",
    "======================================================================\n",
    "\n",
    "æƒæåˆ° 4 å€‹æª”æ¡ˆ\n",
    "\n",
    "éœ€è¦å‚™ä»½: 1 å€‹æª”æ¡ˆ\n",
    "ç•¥é: 3 å€‹æª”æ¡ˆï¼ˆæœªä¿®æ”¹ï¼‰\n",
    "\n",
    "[å·²ä¿®æ”¹] file1.txt (1.5 KB)\n",
    "\n",
    "======================================================================\n",
    "å‚™ä»½å®Œæˆï¼\n",
    "  è¤‡è£½æª”æ¡ˆ: 1 å€‹\n",
    "  ç•¥éæª”æ¡ˆ: 3 å€‹\n",
    "  ç¸½å¤§å°: 1.5 KB\n",
    "  çµæŸæ™‚é–“: 2025-10-08 12:35:21\n",
    "```\n",
    "\n",
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "- âœ… ä½¿ç”¨ `rglob('*')` éè¿´æƒææ‰€æœ‰æª”æ¡ˆ\n",
    "- âœ… ä½¿ç”¨ `relative_to()` è¨ˆç®—ç›¸å°è·¯å¾‘\n",
    "- âœ… æ¯”è¼ƒæª”æ¡ˆä¿®æ”¹æ™‚é–“ `stat().st_mtime`\n",
    "- âœ… ä½¿ç”¨ `shutil.copy2()` ä¿ç•™æ™‚é–“æˆ³è¨˜\n",
    "- âœ… ä½¿ç”¨ `mkdir(parents=True)` å»ºç«‹å¤šå±¤ç›®éŒ„\n",
    "- âœ… å¢é‡å‚™ä»½é‚è¼¯å¯¦ä½œ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 4ï¼šæ‰¹æ¬¡é‡æ–°å‘½åå·¥å…·\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "å»ºç«‹æ‰¹æ¬¡é‡æ–°å‘½åå·¥å…·ï¼Œèƒ½å¤ ï¼š\n",
    "1. æ”¯æ´å¤šç¨®å‘½åè¦å‰‡ï¼ˆç·¨è™Ÿã€æ—¥æœŸã€å–ä»£æ–‡å­—ï¼‰\n",
    "2. é è¦½é‡æ–°å‘½åçµæœ\n",
    "3. è™•ç†åç¨±è¡çª\n",
    "4. æ”¯æ´å¾©åŸæ“ä½œ\n",
    "\n",
    "**é›£åº¦**ï¼šé€²éš\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "1. æƒæç›®éŒ„ä¸­çš„æª”æ¡ˆ\n",
    "2. æ ¹æ“šè¦å‰‡ç”¢ç”Ÿæ–°æª”å\n",
    "3. æª¢æŸ¥è¡çªä¸¦èª¿æ•´\n",
    "4. åŸ·è¡Œé‡æ–°å‘½åä¸¦è¨˜éŒ„\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def batch_rename(directory, pattern, mode='number', dry_run=True, start=1):\n",
    "    \"\"\"\n",
    "    æ‰¹æ¬¡é‡æ–°å‘½åæª”æ¡ˆ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        directory: ç›®æ¨™ç›®éŒ„\n",
    "        pattern: æª”åæ¨¡å¼ï¼ˆå¯å« {n}, {name}, {date} ç­‰è®Šæ•¸ï¼‰\n",
    "        mode: å‘½åæ¨¡å¼ ('number', 'date', 'replace')\n",
    "        dry_run: é è¦½æ¨¡å¼\n",
    "        start: èµ·å§‹ç·¨è™Ÿï¼ˆmode='number' æ™‚ä½¿ç”¨ï¼‰\n",
    "    \n",
    "    æ¨¡å¼èªªæ˜:\n",
    "        - number: ä½¿ç”¨ç·¨è™Ÿï¼Œå¦‚ file_001.txt\n",
    "        - date: ä½¿ç”¨æ—¥æœŸï¼Œå¦‚ 2025-10-08_file.txt\n",
    "        - replace: å–ä»£æ–‡å­—ï¼ˆpattern ç‚º 'èˆŠæ–‡å­—->æ–°æ–‡å­—'ï¼‰\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: é©—è­‰ç›®éŒ„\n",
    "    target_dir = Path(directory)\n",
    "    if not target_dir.exists() or not target_dir.is_dir():\n",
    "        print(f\"éŒ¯èª¤ï¼š{directory} ä¸æ˜¯æœ‰æ•ˆçš„ç›®éŒ„\")\n",
    "        return\n",
    "    \n",
    "    mode_text = \"é è¦½æ¨¡å¼\" if dry_run else \"åŸ·è¡Œæ¨¡å¼\"\n",
    "    print(f\"æ‰¹æ¬¡é‡æ–°å‘½åå·¥å…· - {mode_text}\")\n",
    "    print(f\"ç›®æ¨™ç›®éŒ„: {target_dir.resolve()}\")\n",
    "    print(f\"å‘½åæ¨¡å¼: {mode}\")\n",
    "    print(f\"å‘½åè¦å‰‡: {pattern}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: æ”¶é›†æª”æ¡ˆ\n",
    "    files = sorted([f for f in target_dir.glob('*') if f.is_file()])\n",
    "    \n",
    "    if not files:\n",
    "        print(\"ç›®éŒ„ä¸­æ²’æœ‰æª”æ¡ˆ\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\næ‰¾åˆ° {len(files)} å€‹æª”æ¡ˆ\\n\")\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: ç”¢ç”Ÿæ–°æª”å\n",
    "    rename_plan = []\n",
    "    counter = start\n",
    "    \n",
    "    for file in files:\n",
    "        # æ ¹æ“šæ¨¡å¼ç”¢ç”Ÿæ–°æª”å\n",
    "        if mode == 'number':\n",
    "            # è¨ˆç®—éœ€è¦çš„ä½æ•¸ï¼ˆè‡ªå‹•è£œé›¶ï¼‰\n",
    "            digits = len(str(len(files) + start - 1))\n",
    "            new_stem = pattern.format(\n",
    "                n=str(counter).zfill(digits),\n",
    "                name=file.stem\n",
    "            )\n",
    "            new_name = new_stem + file.suffix\n",
    "            counter += 1\n",
    "            \n",
    "        elif mode == 'date':\n",
    "            # ä½¿ç”¨æª”æ¡ˆä¿®æ”¹æ—¥æœŸ\n",
    "            mtime = file.stat().st_mtime\n",
    "            date_str = datetime.fromtimestamp(mtime).strftime('%Y%m%d')\n",
    "            new_stem = pattern.format(\n",
    "                date=date_str,\n",
    "                name=file.stem\n",
    "            )\n",
    "            new_name = new_stem + file.suffix\n",
    "            \n",
    "        elif mode == 'replace':\n",
    "            # å–ä»£æ–‡å­—\n",
    "            if '->' not in pattern:\n",
    "                print(f\"éŒ¯èª¤ï¼šreplace æ¨¡å¼éœ€è¦ 'èˆŠæ–‡å­—->æ–°æ–‡å­—' æ ¼å¼\")\n",
    "                return\n",
    "            old_text, new_text = pattern.split('->', 1)\n",
    "            new_name = file.name.replace(old_text, new_text)\n",
    "        \n",
    "        else:\n",
    "            print(f\"éŒ¯èª¤ï¼šä¸æ”¯æ´çš„æ¨¡å¼ {mode}\")\n",
    "            return\n",
    "        \n",
    "        new_path = file.parent / new_name\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦çœŸçš„éœ€è¦é‡æ–°å‘½å\n",
    "        if file.name != new_name:\n",
    "            rename_plan.append({\n",
    "                'old': file,\n",
    "                'new': new_path,\n",
    "                'old_name': file.name,\n",
    "                'new_name': new_name\n",
    "            })\n",
    "    \n",
    "    if not rename_plan:\n",
    "        print(\"æ‰€æœ‰æª”æ¡ˆå·²ç¬¦åˆå‘½åè¦å‰‡ï¼Œç„¡éœ€é‡æ–°å‘½å\")\n",
    "        return\n",
    "    \n",
    "    # æ­¥é©Ÿ 4: æª¢æŸ¥è¡çª\n",
    "    conflicts = []\n",
    "    new_names = set()\n",
    "    \n",
    "    for item in rename_plan:\n",
    "        if item['new'].exists() and item['new'] != item['old']:\n",
    "            conflicts.append(item['new_name'])\n",
    "        if item['new_name'] in new_names:\n",
    "            conflicts.append(f\"{item['new_name']} (é‡è¤‡)\")\n",
    "        new_names.add(item['new_name'])\n",
    "    \n",
    "    # æ­¥é©Ÿ 5: é¡¯ç¤ºé è¦½\n",
    "    print(\"é‡æ–°å‘½åè¨ˆåŠƒï¼š\\n\")\n",
    "    for i, item in enumerate(rename_plan, 1):\n",
    "        print(f\"{i:3d}. {item['old_name']:30s} -> {item['new_name']}\")\n",
    "    \n",
    "    # æ­¥é©Ÿ 6: è­¦å‘Šè¡çª\n",
    "    if conflicts:\n",
    "        print(\"\\nâš ï¸  è­¦å‘Šï¼šç™¼ç¾æª”åè¡çªï¼\")\n",
    "        for conflict in conflicts:\n",
    "            print(f\"  - {conflict}\")\n",
    "        print(\"\\nè«‹ä¿®æ­£å‘½åè¦å‰‡å¾Œé‡è©¦\")\n",
    "        return\n",
    "    \n",
    "    # æ­¥é©Ÿ 7: åŸ·è¡Œé‡æ–°å‘½å\n",
    "    if not dry_run:\n",
    "        print(\"\\né–‹å§‹é‡æ–°å‘½å...\")\n",
    "        \n",
    "        # è¨˜éŒ„æ“ä½œï¼ˆç”¨æ–¼å¾©åŸï¼‰\n",
    "        log = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'directory': str(target_dir.resolve()),\n",
    "            'mode': mode,\n",
    "            'pattern': pattern,\n",
    "            'operations': []\n",
    "        }\n",
    "        \n",
    "        success = 0\n",
    "        for item in rename_plan:\n",
    "            try:\n",
    "                item['old'].rename(item['new'])\n",
    "                log['operations'].append({\n",
    "                    'old': item['old_name'],\n",
    "                    'new': item['new_name']\n",
    "                })\n",
    "                success += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  éŒ¯èª¤: {item['old_name']} -> {e}\")\n",
    "        \n",
    "        # å„²å­˜æ“ä½œè¨˜éŒ„\n",
    "        log_file = target_dir / '.rename_log.json'\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(log, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nå®Œæˆï¼æˆåŠŸé‡æ–°å‘½å {success} å€‹æª”æ¡ˆ\")\n",
    "        print(f\"æ“ä½œè¨˜éŒ„å·²å„²å­˜è‡³: {log_file.name}\")\n",
    "    else:\n",
    "        print(\"\\nâ€» é€™æ˜¯é è¦½æ¨¡å¼ï¼Œæª”æ¡ˆå°šæœªå¯¦éš›é‡æ–°å‘½å\")\n",
    "        print(\"  è‹¥è¦å¯¦éš›åŸ·è¡Œï¼Œè«‹è¨­å®š dry_run=False\")\n",
    "\n",
    "# æ¸¬è©¦\n",
    "print(\"=== å»ºç«‹æ¸¬è©¦ç’°å¢ƒ ===\")\n",
    "test_dir = Path('rename_test')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# å»ºç«‹æ¸¬è©¦æª”æ¡ˆ\n",
    "test_files = ['IMG_001.jpg', 'IMG_002.jpg', 'IMG_003.jpg', \n",
    "              'document.txt', 'report.txt', 'notes.txt']\n",
    "for filename in test_files:\n",
    "    (test_dir / filename).write_text('test')\n",
    "\n",
    "print(f\"å·²å»ºç«‹ {len(test_files)} å€‹æ¸¬è©¦æª”æ¡ˆ\\n\")\n",
    "\n",
    "# æ¸¬è©¦ 1: ç·¨è™Ÿæ¨¡å¼ï¼ˆé è¦½ï¼‰\n",
    "print(\"=== æ¸¬è©¦ 1: ç·¨è™Ÿæ¨¡å¼ï¼ˆé è¦½ï¼‰===\")\n",
    "batch_rename(test_dir, 'photo_{n}', mode='number', dry_run=True)\n",
    "\n",
    "# æ¸¬è©¦ 2: å–ä»£æ–‡å­—æ¨¡å¼ï¼ˆå¯¦éš›åŸ·è¡Œï¼‰\n",
    "print(\"\\n\\n=== æ¸¬è©¦ 2: å–ä»£æ–‡å­—ï¼ˆå¯¦éš›åŸ·è¡Œï¼‰===\")\n",
    "batch_rename(test_dir, 'IMG_->photo_', mode='replace', dry_run=False)\n",
    "\n",
    "print(\"\\né‡æ–°å‘½åå¾Œçš„æª”æ¡ˆï¼š\")\n",
    "for file in sorted(test_dir.glob('*')):\n",
    "    if file.is_file() and not file.name.startswith('.'):\n",
    "        print(f\"  {file.name}\")\n",
    "\n",
    "# æ¸…ç†\n",
    "import shutil\n",
    "shutil.rmtree(test_dir)\n",
    "print(\"\\n[æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š åŸ·è¡Œçµæœ\n",
    "```\n",
    "=== æ¸¬è©¦ 2: å–ä»£æ–‡å­—ï¼ˆå¯¦éš›åŸ·è¡Œï¼‰===\n",
    "æ‰¹æ¬¡é‡æ–°å‘½åå·¥å…· - åŸ·è¡Œæ¨¡å¼\n",
    "ç›®æ¨™ç›®éŒ„: D:\\...\\rename_test\n",
    "å‘½åæ¨¡å¼: replace\n",
    "å‘½åè¦å‰‡: IMG_->photo_\n",
    "======================================================================\n",
    "\n",
    "æ‰¾åˆ° 6 å€‹æª”æ¡ˆ\n",
    "\n",
    "é‡æ–°å‘½åè¨ˆåŠƒï¼š\n",
    "\n",
    "  1. IMG_001.jpg                     -> photo_001.jpg\n",
    "  2. IMG_002.jpg                     -> photo_002.jpg\n",
    "  3. IMG_003.jpg                     -> photo_003.jpg\n",
    "\n",
    "é–‹å§‹é‡æ–°å‘½å...\n",
    "\n",
    "å®Œæˆï¼æˆåŠŸé‡æ–°å‘½å 3 å€‹æª”æ¡ˆ\n",
    "æ“ä½œè¨˜éŒ„å·²å„²å­˜è‡³: .rename_log.json\n",
    "```\n",
    "\n",
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "- âœ… ä½¿ç”¨ `rename()` é‡æ–°å‘½åæª”æ¡ˆ\n",
    "- âœ… å­—ä¸²æ ¼å¼åŒ–ç”¢ç”Ÿæ–°æª”å `format()`\n",
    "- âœ… æª¢æ¸¬æª”åè¡çª\n",
    "- âœ… ä½¿ç”¨ `zfill()` è£œé›¶\n",
    "- âœ… æ“ä½œè¨˜éŒ„å„²å­˜ï¼ˆJSONï¼‰\n",
    "- âœ… å¯¦ä½œé è¦½èˆ‡åŸ·è¡Œæ¨¡å¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 5ï¼šæª”æ¡ˆå¤§å°åˆ†æå™¨\n",
    "\n",
    "### ğŸ“‹ å•é¡Œæè¿°\n",
    "å»ºç«‹ç›®éŒ„åˆ†æå·¥å…·ï¼Œèƒ½å¤ ï¼š\n",
    "1. çµ±è¨ˆç›®éŒ„ä¸­å„é¡å‹æª”æ¡ˆçš„æ•¸é‡èˆ‡å¤§å°\n",
    "2. æ‰¾å‡ºæœ€å¤§çš„æª”æ¡ˆèˆ‡è³‡æ–™å¤¾\n",
    "3. ç”¢ç”Ÿè¦–è¦ºåŒ–å ±å‘Š\n",
    "4. è¨ˆç®—ç›®éŒ„æ¨¹çš„æ·±åº¦\n",
    "\n",
    "**é›£åº¦**ï¼šé€²éš\n",
    "\n",
    "### ğŸ” åˆ†ææ€è·¯\n",
    "1. éè¿´éæ­·æ‰€æœ‰æª”æ¡ˆèˆ‡ç›®éŒ„\n",
    "2. ä¾å‰¯æª”ååˆ†é¡çµ±è¨ˆ\n",
    "3. è¨ˆç®—æ¯å€‹ç›®éŒ„çš„ç¸½å¤§å°\n",
    "4. æ’åºä¸¦ç”¢ç”Ÿå ±å‘Š\n",
    "\n",
    "### ğŸ’» é€æ­¥å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_directory(directory, top_n=10):\n",
    "    \"\"\"\n",
    "    åˆ†æç›®éŒ„çµæ§‹èˆ‡æª”æ¡ˆå¤§å°\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        directory: è¦åˆ†æçš„ç›®éŒ„\n",
    "        top_n: é¡¯ç¤ºå‰ N å¤§çš„æª”æ¡ˆ/ç›®éŒ„\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: é©—è­‰ç›®éŒ„\n",
    "    root = Path(directory)\n",
    "    if not root.exists() or not root.is_dir():\n",
    "        print(f\"éŒ¯èª¤ï¼š{directory} ä¸æ˜¯æœ‰æ•ˆçš„ç›®éŒ„\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ç›®éŒ„åˆ†æå·¥å…·\")\n",
    "    print(f\"åˆ†æç›®éŒ„: {root.resolve()}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: åˆå§‹åŒ–çµ±è¨ˆè³‡æ–™\n",
    "    stats = {\n",
    "        'total_files': 0,\n",
    "        'total_dirs': 0,\n",
    "        'total_size': 0,\n",
    "        'by_extension': defaultdict(lambda: {'count': 0, 'size': 0}),\n",
    "        'largest_files': [],\n",
    "        'dir_sizes': {},\n",
    "        'max_depth': 0\n",
    "    }\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: æƒææ‰€æœ‰é …ç›®\n",
    "    print(\"\\næ­£åœ¨æƒææª”æ¡ˆ...\")\n",
    "    \n",
    "    all_items = list(root.rglob('*'))\n",
    "    \n",
    "    for item in all_items:\n",
    "        # è¨ˆç®—æ·±åº¦\n",
    "        depth = len(item.relative_to(root).parts)\n",
    "        stats['max_depth'] = max(stats['max_depth'], depth)\n",
    "        \n",
    "        if item.is_file():\n",
    "            # æª”æ¡ˆçµ±è¨ˆ\n",
    "            stats['total_files'] += 1\n",
    "            size = item.stat().st_size\n",
    "            stats['total_size'] += size\n",
    "            \n",
    "            # æŒ‰å‰¯æª”ååˆ†é¡\n",
    "            ext = item.suffix.lower() or '(ç„¡å‰¯æª”å)'\n",
    "            stats['by_extension'][ext]['count'] += 1\n",
    "            stats['by_extension'][ext]['size'] += size\n",
    "            \n",
    "            # è¨˜éŒ„å¤§æª”æ¡ˆ\n",
    "            stats['largest_files'].append({\n",
    "                'path': item,\n",
    "                'size': size,\n",
    "                'relative': item.relative_to(root)\n",
    "            })\n",
    "            \n",
    "        elif item.is_dir():\n",
    "            stats['total_dirs'] += 1\n",
    "    \n",
    "    # æ­¥é©Ÿ 4: è¨ˆç®—æ¯å€‹ç›®éŒ„çš„å¤§å°\n",
    "    print(\"è¨ˆç®—ç›®éŒ„å¤§å°...\\n\")\n",
    "    \n",
    "    for dir_path in [d for d in all_items if d.is_dir()]:\n",
    "        dir_size = sum(\n",
    "            f.stat().st_size \n",
    "            for f in dir_path.rglob('*') \n",
    "            if f.is_file()\n",
    "        )\n",
    "        stats['dir_sizes'][dir_path] = dir_size\n",
    "    \n",
    "    # æ­¥é©Ÿ 5: æ’åº\n",
    "    stats['largest_files'].sort(key=lambda x: x['size'], reverse=True)\n",
    "    largest_dirs = sorted(\n",
    "        stats['dir_sizes'].items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # æ­¥é©Ÿ 6: ç”¢ç”Ÿå ±å‘Š\n",
    "    def format_size(size):\n",
    "        \"\"\"æ ¼å¼åŒ–æª”æ¡ˆå¤§å°\"\"\"\n",
    "        if size < 1024:\n",
    "            return f\"{size} B\"\n",
    "        elif size < 1024 * 1024:\n",
    "            return f\"{size / 1024:.1f} KB\"\n",
    "        elif size < 1024 * 1024 * 1024:\n",
    "            return f\"{size / (1024 * 1024):.1f} MB\"\n",
    "        else:\n",
    "            return f\"{size / (1024 * 1024 * 1024):.1f} GB\"\n",
    "    \n",
    "    # ç¸½è¦½\n",
    "    print(\"ğŸ“Š ç¸½è¦½\")\n",
    "    print(f\"  ç¸½æª”æ¡ˆæ•¸: {stats['total_files']:,}\")\n",
    "    print(f\"  ç¸½ç›®éŒ„æ•¸: {stats['total_dirs']:,}\")\n",
    "    print(f\"  ç¸½å¤§å°: {format_size(stats['total_size'])}\")\n",
    "    print(f\"  ç›®éŒ„æ·±åº¦: {stats['max_depth']} å±¤\")\n",
    "    print()\n",
    "    \n",
    "    # æŒ‰å‰¯æª”åçµ±è¨ˆ\n",
    "    print(\"ğŸ“ æª”æ¡ˆé¡å‹çµ±è¨ˆï¼ˆå‰ 10 åï¼‰\")\n",
    "    ext_sorted = sorted(\n",
    "        stats['by_extension'].items(),\n",
    "        key=lambda x: x[1]['size'],\n",
    "        reverse=True\n",
    "    )[:10]\n",
    "    \n",
    "    print(f\"{'å‰¯æª”å':<15} {'æ•¸é‡':>8} {'ç¸½å¤§å°':>15} {'ç™¾åˆ†æ¯”':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for ext, data in ext_sorted:\n",
    "        percentage = (data['size'] / stats['total_size'] * 100) if stats['total_size'] > 0 else 0\n",
    "        print(f\"{ext:<15} {data['count']:>8} {format_size(data['size']):>15} {percentage:>9.1f}%\")\n",
    "    print()\n",
    "    \n",
    "    # æœ€å¤§æª”æ¡ˆ\n",
    "    print(f\"ğŸ“„ æœ€å¤§çš„ {min(top_n, len(stats['largest_files']))} å€‹æª”æ¡ˆ\")\n",
    "    print(f\"{'å¤§å°':>12} {'æª”æ¡ˆè·¯å¾‘'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for item in stats['largest_files'][:top_n]:\n",
    "        print(f\"{format_size(item['size']):>12} {item['relative']}\")\n",
    "    print()\n",
    "    \n",
    "    # æœ€å¤§ç›®éŒ„\n",
    "    print(f\"ğŸ“‚ æœ€å¤§çš„ {min(top_n, len(largest_dirs))} å€‹ç›®éŒ„\")\n",
    "    print(f\"{'å¤§å°':>12} {'ç›®éŒ„è·¯å¾‘'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for dir_path, size in largest_dirs[:top_n]:\n",
    "        relative = dir_path.relative_to(root)\n",
    "        print(f\"{format_size(size):>12} {relative if str(relative) != '.' else '(æ ¹ç›®éŒ„)'}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# æ¸¬è©¦\n",
    "print(\"=== å»ºç«‹æ¸¬è©¦ç’°å¢ƒ ===\")\n",
    "test_dir = Path('analyze_test')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# å»ºç«‹å„ç¨®å¤§å°çš„æª”æ¡ˆ\n",
    "(test_dir / 'small.txt').write_text('x' * 100)\n",
    "(test_dir / 'medium.txt').write_text('x' * 5000)\n",
    "(test_dir / 'large.txt').write_text('x' * 50000)\n",
    "\n",
    "(test_dir / 'data1.csv').write_text('a,b,c\\n' * 1000)\n",
    "(test_dir / 'data2.csv').write_text('a,b,c\\n' * 2000)\n",
    "\n",
    "(test_dir / 'script1.py').write_text('print(\"hello\")' * 100)\n",
    "(test_dir / 'script2.py').write_text('print(\"world\")' * 200)\n",
    "\n",
    "# å»ºç«‹å­ç›®éŒ„\n",
    "subdir1 = test_dir / 'images'\n",
    "subdir1.mkdir()\n",
    "(subdir1 / 'photo1.jpg').write_text('x' * 8000)\n",
    "(subdir1 / 'photo2.jpg').write_text('x' * 12000)\n",
    "\n",
    "subdir2 = test_dir / 'documents'\n",
    "subdir2.mkdir()\n",
    "(subdir2 / 'report.pdf').write_text('x' * 15000)\n",
    "(subdir2 / 'notes.txt').write_text('x' * 3000)\n",
    "\n",
    "print(\"å·²å»ºç«‹æ¸¬è©¦ç›®éŒ„çµæ§‹\\n\")\n",
    "\n",
    "# åŸ·è¡Œåˆ†æ\n",
    "print(\"=\" * 70)\n",
    "analyze_directory(test_dir, top_n=5)\n",
    "\n",
    "# æ¸…ç†\n",
    "import shutil\n",
    "shutil.rmtree(test_dir)\n",
    "print(\"\\n[æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š åŸ·è¡Œçµæœ\n",
    "```\n",
    "ç›®éŒ„åˆ†æå·¥å…·\n",
    "åˆ†æç›®éŒ„: D:\\...\\analyze_test\n",
    "======================================================================\n",
    "\n",
    "æ­£åœ¨æƒææª”æ¡ˆ...\n",
    "è¨ˆç®—ç›®éŒ„å¤§å°...\n",
    "\n",
    "ğŸ“Š ç¸½è¦½\n",
    "  ç¸½æª”æ¡ˆæ•¸: 11\n",
    "  ç¸½ç›®éŒ„æ•¸: 2\n",
    "  ç¸½å¤§å°: 103.0 KB\n",
    "  ç›®éŒ„æ·±åº¦: 2 å±¤\n",
    "\n",
    "ğŸ“ æª”æ¡ˆé¡å‹çµ±è¨ˆï¼ˆå‰ 10 åï¼‰\n",
    "å‰¯æª”å              æ•¸é‡          ç¸½å¤§å°     ç™¾åˆ†æ¯”\n",
    "--------------------------------------------------\n",
    ".txt                   4         56.5 KB      54.8%\n",
    ".jpg                   2         19.5 KB      19.0%\n",
    ".pdf                   1         14.6 KB      14.2%\n",
    ".csv                   2          5.9 KB       5.7%\n",
    ".py                    2          4.5 KB       4.4%\n",
    "\n",
    "ğŸ“„ æœ€å¤§çš„ 5 å€‹æª”æ¡ˆ\n",
    "        å¤§å° æª”æ¡ˆè·¯å¾‘\n",
    "----------------------------------------------------------------------\n",
    "     48.8 KB large.txt\n",
    "     14.6 KB documents\\report.pdf\n",
    "     11.7 KB images\\photo2.jpg\n",
    "      7.8 KB images\\photo1.jpg\n",
    "      4.9 KB medium.txt\n",
    "\n",
    "ğŸ“‚ æœ€å¤§çš„ 5 å€‹ç›®éŒ„\n",
    "        å¤§å° ç›®éŒ„è·¯å¾‘\n",
    "----------------------------------------------------------------------\n",
    "    103.0 KB (æ ¹ç›®éŒ„)\n",
    "     19.5 KB images\n",
    "     17.6 KB documents\n",
    "```\n",
    "\n",
    "### ğŸ“š çŸ¥è­˜é»ç¸½çµ\n",
    "- âœ… éè¿´çµ±è¨ˆç›®éŒ„èˆ‡æª”æ¡ˆ\n",
    "- âœ… ä½¿ç”¨ `defaultdict` åˆ†é¡çµ±è¨ˆ\n",
    "- âœ… è¨ˆç®—ç›®éŒ„æ·±åº¦ `len(parts)`\n",
    "- âœ… å¤šç¶­åº¦æ’åºèˆ‡ç¯©é¸\n",
    "- âœ… æ ¼å¼åŒ–è¼¸å‡ºè¡¨æ ¼\n",
    "- âœ… ç™¾åˆ†æ¯”è¨ˆç®—èˆ‡é¡¯ç¤º\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç¸½çµ\n",
    "\n",
    "æœ¬æª”æ¡ˆå®Œæˆäº† 5 å€‹å¯¦æˆ°ç¯„ä¾‹ï¼š\n",
    "\n",
    "1. **æª”æ¡ˆæœå°‹å·¥å…·** - éè¿´æœå°‹ã€å±¬æ€§æŸ¥è©¢ã€æ’åº\n",
    "2. **ç›®éŒ„æ•´ç†å™¨** - åˆ†é¡æ•´ç†ã€è¡çªè™•ç†ã€é è¦½æ¨¡å¼\n",
    "3. **è‡ªå‹•å‚™ä»½ç³»çµ±** - å¢é‡å‚™ä»½ã€æ™‚é–“æ¯”è¼ƒã€çµæ§‹ä¿æŒ\n",
    "4. **æ‰¹æ¬¡é‡æ–°å‘½å** - å¤šç¨®æ¨¡å¼ã€è¡çªæª¢æ¸¬ã€æ“ä½œè¨˜éŒ„\n",
    "5. **æª”æ¡ˆå¤§å°åˆ†æå™¨** - çµ±è¨ˆåˆ†æã€è¦–è¦ºåŒ–å ±å‘Šã€å¤šç¶­åº¦æ’åº\n",
    "\n",
    "### æ ¸å¿ƒæŠ€èƒ½\n",
    "- âœ… Path ç‰©ä»¶çš„ç¶œåˆæ‡‰ç”¨\n",
    "- âœ… æª”æ¡ˆç³»çµ±éæ­·èˆ‡æ“ä½œ\n",
    "- âœ… éŒ¯èª¤è™•ç†èˆ‡è¡çªè§£æ±º\n",
    "- âœ… è³‡æ–™çµ±è¨ˆèˆ‡åˆ†æ\n",
    "- âœ… å¯¦ç”¨å·¥å…·è¨­è¨ˆ\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "- å®Œæˆ `03-practice.ipynb` èª²å ‚ç·´ç¿’\n",
    "- å®Œæˆ `04-exercises.ipynb` èª²å¾Œç¿’é¡Œ\n",
    "- æŒ‘æˆ° `quiz.ipynb` è‡ªæˆ‘æ¸¬é©—"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
