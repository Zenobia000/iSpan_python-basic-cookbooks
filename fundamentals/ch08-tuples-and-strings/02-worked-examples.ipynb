{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Worked Examples - è©³è§£ç¯„ä¾‹\n",
    "\n",
    "æœ¬æª”æ¡ˆæä¾› 5 å€‹å®Œæ•´çš„è§£é¡Œç¯„ä¾‹ï¼Œå±•ç¤ºå…ƒçµ„èˆ‡å­—ä¸²çš„å¯¦å‹™æ‡‰ç”¨ã€‚\n",
    "æ¯å€‹ç¯„ä¾‹åŒ…å«ï¼š\n",
    "1. å•é¡Œæè¿°\n",
    "2. æ€è·¯åˆ†æ\n",
    "3. å®Œæ•´ç¨‹å¼ç¢¼\n",
    "4. åŸ·è¡Œçµæœ\n",
    "5. å»¶ä¼¸æ€è€ƒ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 1ï¼šåº§æ¨™é»è™•ç†ç³»çµ±\n",
    "\n",
    "### å•é¡Œæè¿°\n",
    "è¨­è¨ˆä¸€å€‹åº§æ¨™é»è™•ç†ç³»çµ±ï¼Œèƒ½å¤ ï¼š\n",
    "1. å„²å­˜ 2D åº§æ¨™é»ï¼ˆä½¿ç”¨å…ƒçµ„ï¼‰\n",
    "2. è¨ˆç®—å…©é»ä¹‹é–“çš„è·é›¢\n",
    "3. è¨ˆç®—å¤šå€‹é»çš„ä¸­å¿ƒé»\n",
    "4. æ‰¾å‡ºè·é›¢åŸé»æœ€é /æœ€è¿‘çš„é»\n",
    "\n",
    "### æ€è·¯åˆ†æ\n",
    "- ä½¿ç”¨å…ƒçµ„ `(x, y)` è¡¨ç¤ºåº§æ¨™é»ï¼ˆä¸å¯è®Šï¼Œé©åˆè¡¨ç¤ºä½ç½®ï¼‰\n",
    "- è·é›¢å…¬å¼ï¼š$\\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}$\n",
    "- ä¸­å¿ƒé»ï¼šæ‰€æœ‰é»çš„ x å¹³å‡å€¼å’Œ y å¹³å‡å€¼\n",
    "- ä½¿ç”¨å…ƒçµ„è§£åŒ…ç°¡åŒ–ç¨‹å¼ç¢¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "def distance(p1, p2):\n",
    "    \"\"\"è¨ˆç®—å…©é»ä¹‹é–“çš„è·é›¢\"\"\"\n",
    "    x1, y1 = p1  # å…ƒçµ„è§£åŒ…\n",
    "    x2, y2 = p2\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def center_point(points):\n",
    "    \"\"\"è¨ˆç®—å¤šå€‹é»çš„ä¸­å¿ƒé»\"\"\"\n",
    "    if not points:\n",
    "        return None\n",
    "    \n",
    "    # åˆ†åˆ¥è¨ˆç®—æ‰€æœ‰ x å’Œ y çš„å¹³å‡å€¼\n",
    "    x_sum = sum(x for x, y in points)  # å…ƒçµ„è§£åŒ…\n",
    "    y_sum = sum(y for x, y in points)\n",
    "    count = len(points)\n",
    "    \n",
    "    return (x_sum / count, y_sum / count)\n",
    "\n",
    "def find_extremes(points, origin=(0, 0)):\n",
    "    \"\"\"æ‰¾å‡ºè·é›¢åŸé»æœ€é å’Œæœ€è¿‘çš„é»\"\"\"\n",
    "    if not points:\n",
    "        return None, None\n",
    "    \n",
    "    distances = [(p, distance(origin, p)) for p in points]\n",
    "    \n",
    "    # æ‰¾æœ€é å’Œæœ€è¿‘\n",
    "    farthest = max(distances, key=lambda item: item[1])\n",
    "    nearest = min(distances, key=lambda item: item[1])\n",
    "    \n",
    "    return nearest, farthest\n",
    "\n",
    "# æ¸¬è©¦ç¨‹å¼\n",
    "print(\"=== åº§æ¨™é»è™•ç†ç³»çµ± ===\")\n",
    "\n",
    "# å®šç¾©ä¸€äº›åº§æ¨™é»\n",
    "points = [\n",
    "    (0, 0),\n",
    "    (3, 4),\n",
    "    (6, 8),\n",
    "    (-2, 1),\n",
    "    (5, -3)\n",
    "]\n",
    "\n",
    "print(\"\\nåº§æ¨™é»åˆ—è¡¨ï¼š\")\n",
    "for i, point in enumerate(points, 1):\n",
    "    print(f\"  é» {i}: {point}\")\n",
    "\n",
    "# è¨ˆç®—å…©é»è·é›¢\n",
    "p1, p2 = points[0], points[1]\n",
    "dist = distance(p1, p2)\n",
    "print(f\"\\né» {p1} åˆ°é» {p2} çš„è·é›¢ï¼š{dist:.2f}\")\n",
    "\n",
    "# è¨ˆç®—ä¸­å¿ƒé»\n",
    "center = center_point(points)\n",
    "print(f\"\\næ‰€æœ‰é»çš„ä¸­å¿ƒé»ï¼š({center[0]:.2f}, {center[1]:.2f})\")\n",
    "\n",
    "# æ‰¾å‡ºæ¥µå€¼\n",
    "nearest, farthest = find_extremes(points)\n",
    "print(f\"\\nè·é›¢åŸé»æœ€è¿‘çš„é»ï¼š{nearest[0]}, è·é›¢ {nearest[1]:.2f}\")\n",
    "print(f\"è·é›¢åŸé»æœ€é çš„é»ï¼š{farthest[0]}, è·é›¢ {farthest[1]:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å»¶ä¼¸æ€è€ƒ\n",
    "1. å¦‚ä½•æ“´å±•åˆ° 3D åº§æ¨™é» `(x, y, z)`ï¼Ÿ\n",
    "2. å¦‚ä½•åˆ¤æ–·ä¸‰å€‹é»æ˜¯å¦åœ¨åŒä¸€æ¢ç›´ç·šä¸Šï¼Ÿ\n",
    "3. èƒ½å¦ç”¨å…ƒçµ„å„²å­˜æ¥µåº§æ¨™ `(r, Î¸)`ï¼Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 2ï¼šæ–‡å­—è³‡æ–™æ¸…ç†å·¥å…·\n",
    "\n",
    "### å•é¡Œæè¿°\n",
    "é–‹ç™¼ä¸€å€‹æ–‡å­—æ¸…ç†å·¥å…·ï¼Œè™•ç†ä½¿ç”¨è€…è¼¸å…¥çš„é«’è³‡æ–™ï¼š\n",
    "1. å»é™¤å‰å¾Œç©ºç™½\n",
    "2. çµ±ä¸€å¤§å°å¯«\n",
    "3. ç§»é™¤å¤šé¤˜ç©ºç™½ï¼ˆå¤šå€‹ç©ºç™½è®Šä¸€å€‹ï¼‰\n",
    "4. ç§»é™¤ç‰¹æ®Šå­—å…ƒ\n",
    "5. æ¨™æº–åŒ–æ¨™é»ç¬¦è™Ÿ\n",
    "\n",
    "### æ€è·¯åˆ†æ\n",
    "- ä½¿ç”¨å­—ä¸²æ–¹æ³•éˆå¼å‘¼å«\n",
    "- `strip()` å»é™¤å‰å¾Œç©ºç™½\n",
    "- `split()` + `join()` è™•ç†å¤šé¤˜ç©ºç™½\n",
    "- å­—å…ƒéæ¿¾è™•ç†ç‰¹æ®Šå­—å…ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def clean_text(text, lowercase=True, remove_special=True):\n",
    "    \"\"\"æ¸…ç†æ–‡å­—è³‡æ–™\"\"\"\n",
    "    # 1. å»é™¤å‰å¾Œç©ºç™½\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 2. çµ±ä¸€å°å¯«ï¼ˆå¯é¸ï¼‰\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # 3. ç§»é™¤å¤šé¤˜ç©ºç™½\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # 4. ç§»é™¤ç‰¹æ®Šå­—å…ƒï¼ˆå¯é¸ï¼Œä¿ç•™å­—æ¯ã€æ•¸å­—ã€ç©ºç™½ï¼‰\n",
    "    if remove_special:\n",
    "        allowed = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 ')\n",
    "        text = ''.join(c for c in text if c in allowed)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def standardize_punctuation(text):\n",
    "    \"\"\"æ¨™æº–åŒ–æ¨™é»ç¬¦è™Ÿ\"\"\"\n",
    "    # å…¨å½¢è½‰åŠå½¢\n",
    "    replacements = {\n",
    "        'ï¼Œ': ',',\n",
    "        'ã€‚': '.',\n",
    "        'ï¼': '!',\n",
    "        'ï¼Ÿ': '?',\n",
    "        'ï¼š': ':',\n",
    "        'ï¼›': ';',\n",
    "        'ã€Œ': '\"',\n",
    "        'ã€': '\"',\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def batch_clean(texts):\n",
    "    \"\"\"æ‰¹æ¬¡æ¸…ç†æ–‡å­—\"\"\"\n",
    "    return [clean_text(text) for text in texts]\n",
    "\n",
    "# æ¸¬è©¦ç¨‹å¼\n",
    "print(\"=== æ–‡å­—æ¸…ç†å·¥å…· ===\")\n",
    "\n",
    "# æ¸¬è©¦å–®ä¸€æ–‡å­—æ¸…ç†\n",
    "dirty_text = \"  Hello,   WORLD!  This  is   a  TEST.  \"\n",
    "clean = clean_text(dirty_text)\n",
    "print(f\"\\nåŸå§‹ï¼š'{dirty_text}'\")\n",
    "print(f\"æ¸…ç†ï¼š'{clean}'\")\n",
    "\n",
    "# æ¸¬è©¦ä¿ç•™å¤§å°å¯«\n",
    "clean2 = clean_text(dirty_text, lowercase=False)\n",
    "print(f\"\\nä¿ç•™å¤§å°å¯«ï¼š'{clean2}'\")\n",
    "\n",
    "# æ¸¬è©¦æ¨™é»ç¬¦è™Ÿæ¨™æº–åŒ–\n",
    "chinese_text = \"ä½ å¥½ï¼Œä¸–ç•Œï¼é€™æ˜¯ä¸€å€‹æ¸¬è©¦ã€‚\"\n",
    "standardized = standardize_punctuation(chinese_text)\n",
    "print(f\"\\nåŸå§‹ï¼š{chinese_text}\")\n",
    "print(f\"æ¨™æº–åŒ–ï¼š{standardized}\")\n",
    "\n",
    "# æ¸¬è©¦æ‰¹æ¬¡æ¸…ç†\n",
    "dirty_texts = [\n",
    "    \"  python  \",\n",
    "    \"  JAVA   programming  \",\n",
    "    \"   web    development  \"\n",
    "]\n",
    "cleaned_texts = batch_clean(dirty_texts)\n",
    "print(\"\\næ‰¹æ¬¡æ¸…ç†çµæœï¼š\")\n",
    "for original, cleaned in zip(dirty_texts, cleaned_texts):\n",
    "    print(f\"  '{original}' â†’ '{cleaned}'\")\n",
    "\n",
    "# æ¸¬è©¦ç‰¹æ®Šå­—å…ƒç§»é™¤\n",
    "special_text = \"Hello@#$World123!??\"\n",
    "clean3 = clean_text(special_text, remove_special=True)\n",
    "print(f\"\\nå«ç‰¹æ®Šå­—å…ƒï¼š'{special_text}'\")\n",
    "print(f\"ç§»é™¤å¾Œï¼š'{clean3}'\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å»¶ä¼¸æ€è€ƒ\n",
    "1. å¦‚ä½•è™•ç† HTML æ¨™ç±¤ï¼Ÿ\n",
    "2. å¦‚ä½•ä¿ç•™æŸäº›ç‰¹æ®Šå­—å…ƒï¼ˆå¦‚ @ã€#ï¼‰ï¼Ÿ\n",
    "3. å¦‚ä½•è™•ç† emoji è¡¨æƒ…ç¬¦è™Ÿï¼Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 3ï¼šCSV è³‡æ–™è§£æå™¨\n",
    "\n",
    "### å•é¡Œæè¿°\n",
    "è§£æ CSV æ ¼å¼çš„ä½¿ç”¨è€…è³‡æ–™ï¼š\n",
    "1. åˆ†å‰² CSV è¡Œç‚ºæ¬„ä½\n",
    "2. æ¸…ç†æ¬„ä½è³‡æ–™ï¼ˆå»ç©ºç™½ï¼‰\n",
    "3. å‹æ…‹è½‰æ›ï¼ˆå­—ä¸² â†’ æ•¸å­—ï¼‰\n",
    "4. è³‡æ–™é©—è­‰\n",
    "5. ç”Ÿæˆå ±è¡¨\n",
    "\n",
    "### æ€è·¯åˆ†æ\n",
    "- ä½¿ç”¨ `split(',')` åˆ†å‰²æ¬„ä½\n",
    "- ä½¿ç”¨ `strip()` æ¸…ç†ç©ºç™½\n",
    "- ä½¿ç”¨å…ƒçµ„è§£åŒ…å–å¾—æ¬„ä½\n",
    "- é€²è¡Œè³‡æ–™é©—è­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def parse_csv_line(line):\n",
    "    \"\"\"è§£æ CSV è¡Œ\"\"\"\n",
    "    # åˆ†å‰²ä¸¦æ¸…ç†æ¯å€‹æ¬„ä½\n",
    "    fields = [field.strip() for field in line.split(',')]\n",
    "    return fields\n",
    "\n",
    "def parse_user_data(csv_line):\n",
    "    \"\"\"è§£æä½¿ç”¨è€…è³‡æ–™\"\"\"\n",
    "    fields = parse_csv_line(csv_line)\n",
    "    \n",
    "    # ç¢ºä¿æœ‰è¶³å¤ æ¬„ä½\n",
    "    if len(fields) < 4:\n",
    "        return None, \"æ¬„ä½æ•¸é‡ä¸è¶³\"\n",
    "    \n",
    "    # å…ƒçµ„è§£åŒ…å–å¾—æ¬„ä½\n",
    "    name, age_str, email, city = fields[:4]\n",
    "    \n",
    "    # é©—è­‰èˆ‡è½‰æ›\n",
    "    errors = []\n",
    "    \n",
    "    # é©—è­‰å§“å\n",
    "    if not name or not name.replace(' ', '').isalpha():\n",
    "        errors.append(\"å§“åç„¡æ•ˆ\")\n",
    "    \n",
    "    # é©—è­‰å¹´é½¡\n",
    "    try:\n",
    "        age = int(age_str)\n",
    "        if age < 0 or age > 150:\n",
    "            errors.append(\"å¹´é½¡è¶…å‡ºç¯„åœ\")\n",
    "    except ValueError:\n",
    "        errors.append(\"å¹´é½¡å¿…é ˆæ˜¯æ•¸å­—\")\n",
    "        age = None\n",
    "    \n",
    "    # é©—è­‰ Email\n",
    "    if '@' not in email or '.' not in email:\n",
    "        errors.append(\"Email æ ¼å¼éŒ¯èª¤\")\n",
    "    \n",
    "    # é©—è­‰åŸå¸‚\n",
    "    if not city:\n",
    "        errors.append(\"åŸå¸‚ä¸èƒ½ç‚ºç©º\")\n",
    "    \n",
    "    if errors:\n",
    "        return None, '; '.join(errors)\n",
    "    \n",
    "    # è¿”å›è§£æçµæœï¼ˆå…ƒçµ„ï¼‰\n",
    "    return (name, age, email, city), None\n",
    "\n",
    "def generate_report(users):\n",
    "    \"\"\"ç”Ÿæˆä½¿ç”¨è€…å ±è¡¨\"\"\"\n",
    "    if not users:\n",
    "        return \"ç„¡è³‡æ–™\"\n",
    "    \n",
    "    total = len(users)\n",
    "    avg_age = sum(age for _, age, _, _ in users) / total\n",
    "    cities = {city for _, _, _, city in users}\n",
    "    \n",
    "    report = f\"\"\"ä½¿ç”¨è€…çµ±è¨ˆå ±è¡¨\n",
    "{'='*40}\n",
    "ç¸½äººæ•¸ï¼š{total}\n",
    "å¹³å‡å¹´é½¡ï¼š{avg_age:.1f} æ­²\n",
    "åŸå¸‚æ•¸é‡ï¼š{len(cities)}\n",
    "åŸå¸‚åˆ—è¡¨ï¼š{', '.join(sorted(cities))}\n",
    "    \"\"\"\n",
    "    return report\n",
    "\n",
    "# æ¸¬è©¦ç¨‹å¼\n",
    "print(\"=== CSV è³‡æ–™è§£æå™¨ ===\")\n",
    "\n",
    "# æ¸¬è©¦è³‡æ–™ï¼ˆCSV æ ¼å¼ï¼‰\n",
    "csv_data = [\n",
    "    \"Alice, 25, alice@example.com, Taipei\",\n",
    "    \"Bob, 30, bob@example.com, Kaohsiung\",\n",
    "    \"Charlie, 28, charlie@example.com, Taipei\",\n",
    "    \"David, ABC, david@example.com, Taichung\",  # éŒ¯èª¤ï¼šå¹´é½¡\n",
    "    \"Eve, 22, eve.example.com, Tainan\",  # éŒ¯èª¤ï¼šEmail\n",
    "]\n",
    "\n",
    "valid_users = []\n",
    "errors = []\n",
    "\n",
    "print(\"\\nè§£æçµæœï¼š\")\n",
    "for i, line in enumerate(csv_data, 1):\n",
    "    user, error = parse_user_data(line)\n",
    "    \n",
    "    if user:\n",
    "        valid_users.append(user)\n",
    "        name, age, email, city = user\n",
    "        print(f\"âœ“ è¡Œ {i}: {name}, {age} æ­², {city}\")\n",
    "    else:\n",
    "        errors.append((i, line, error))\n",
    "        print(f\"âœ— è¡Œ {i}: {error}\")\n",
    "\n",
    "# é¡¯ç¤ºéŒ¯èª¤è©³æƒ…\n",
    "if errors:\n",
    "    print(\"\\néŒ¯èª¤è©³æƒ…ï¼š\")\n",
    "    for line_num, line, error in errors:\n",
    "        print(f\"  è¡Œ {line_num}: {line}\")\n",
    "        print(f\"    â†’ {error}\")\n",
    "\n",
    "# ç”Ÿæˆå ±è¡¨\n",
    "print(\"\\n\" + generate_report(valid_users))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å»¶ä¼¸æ€è€ƒ\n",
    "1. å¦‚ä½•è™•ç†æ¬„ä½ä¸­åŒ…å«é€—è™Ÿçš„æƒ…æ³ï¼ˆå¦‚åœ°å€ï¼‰ï¼Ÿ\n",
    "2. å¦‚ä½•æ”¯æ´ä¸åŒçš„åˆ†éš”ç¬¦ï¼ˆtabã€åˆ†è™Ÿï¼‰ï¼Ÿ\n",
    "3. å¦‚ä½•åŒ¯å‡ºç‚º CSV æ ¼å¼ï¼Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 4ï¼šå¯†ç¢¼é©—è­‰å™¨\n",
    "\n",
    "### å•é¡Œæè¿°\n",
    "å¯¦ä½œä¸€å€‹å¯†ç¢¼å¼·åº¦é©—è­‰å™¨ï¼š\n",
    "1. æª¢æŸ¥é•·åº¦ï¼ˆè‡³å°‘ 8 å­—å…ƒï¼‰\n",
    "2. åŒ…å«å¤§å¯«å­—æ¯\n",
    "3. åŒ…å«å°å¯«å­—æ¯\n",
    "4. åŒ…å«æ•¸å­—\n",
    "5. åŒ…å«ç‰¹æ®Šå­—å…ƒ\n",
    "6. è¨ˆç®—å¯†ç¢¼å¼·åº¦åˆ†æ•¸\n",
    "\n",
    "### æ€è·¯åˆ†æ\n",
    "- ä½¿ç”¨å­—ä¸²æ–¹æ³•åˆ¤æ–·å­—å…ƒé¡å‹\n",
    "- ä½¿ç”¨ `any()` æª¢æŸ¥æ˜¯å¦å­˜åœ¨æŸé¡å­—å…ƒ\n",
    "- æ ¹æ“šæ¢ä»¶ç´¯è¨ˆå¼·åº¦åˆ†æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def validate_password(password):\n",
    "    \"\"\"é©—è­‰å¯†ç¢¼ä¸¦è¿”å›è©³ç´°è³‡è¨Š\"\"\"\n",
    "    results = {\n",
    "        'valid': True,\n",
    "        'strength': 0,\n",
    "        'checks': {},\n",
    "        'feedback': []\n",
    "    }\n",
    "    \n",
    "    # 1. é•·åº¦æª¢æŸ¥\n",
    "    length_ok = len(password) >= 8\n",
    "    results['checks']['length'] = length_ok\n",
    "    if length_ok:\n",
    "        results['strength'] += 1\n",
    "    else:\n",
    "        results['feedback'].append(\"å¯†ç¢¼è‡³å°‘éœ€è¦ 8 å€‹å­—å…ƒ\")\n",
    "        results['valid'] = False\n",
    "    \n",
    "    # 2. å¤§å¯«å­—æ¯æª¢æŸ¥\n",
    "    has_upper = any(c.isupper() for c in password)\n",
    "    results['checks']['uppercase'] = has_upper\n",
    "    if has_upper:\n",
    "        results['strength'] += 1\n",
    "    else:\n",
    "        results['feedback'].append(\"éœ€è¦è‡³å°‘ä¸€å€‹å¤§å¯«å­—æ¯\")\n",
    "    \n",
    "    # 3. å°å¯«å­—æ¯æª¢æŸ¥\n",
    "    has_lower = any(c.islower() for c in password)\n",
    "    results['checks']['lowercase'] = has_lower\n",
    "    if has_lower:\n",
    "        results['strength'] += 1\n",
    "    else:\n",
    "        results['feedback'].append(\"éœ€è¦è‡³å°‘ä¸€å€‹å°å¯«å­—æ¯\")\n",
    "    \n",
    "    # 4. æ•¸å­—æª¢æŸ¥\n",
    "    has_digit = any(c.isdigit() for c in password)\n",
    "    results['checks']['digit'] = has_digit\n",
    "    if has_digit:\n",
    "        results['strength'] += 1\n",
    "    else:\n",
    "        results['feedback'].append(\"éœ€è¦è‡³å°‘ä¸€å€‹æ•¸å­—\")\n",
    "    \n",
    "    # 5. ç‰¹æ®Šå­—å…ƒæª¢æŸ¥\n",
    "    special_chars = \"!@#$%^&*()_+-=[]{}|;:',.<>?/\"\n",
    "    has_special = any(c in special_chars for c in password)\n",
    "    results['checks']['special'] = has_special\n",
    "    if has_special:\n",
    "        results['strength'] += 2  # ç‰¹æ®Šå­—å…ƒåŠ  2 åˆ†\n",
    "    else:\n",
    "        results['feedback'].append(\"å»ºè­°åŠ å…¥ç‰¹æ®Šå­—å…ƒä»¥æé«˜å®‰å…¨æ€§\")\n",
    "    \n",
    "    # 6. é¡å¤–æª¢æŸ¥ï¼šé€£çºŒå­—å…ƒ\n",
    "    has_consecutive = any(\n",
    "        password[i:i+3].isdigit() or \n",
    "        password[i:i+3].lower() in 'abcdefghijklmnopqrstuvwxyz'\n",
    "        for i in range(len(password) - 2)\n",
    "    )\n",
    "    if has_consecutive:\n",
    "        results['strength'] -= 1\n",
    "        results['feedback'].append(\"é¿å…ä½¿ç”¨é€£çºŒå­—å…ƒï¼ˆå¦‚ abcã€123ï¼‰\")\n",
    "    \n",
    "    # 7. é•·åº¦åŠ åˆ†\n",
    "    if len(password) >= 12:\n",
    "        results['strength'] += 1\n",
    "    if len(password) >= 16:\n",
    "        results['strength'] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_strength_label(score):\n",
    "    \"\"\"æ ¹æ“šåˆ†æ•¸è¿”å›å¼·åº¦æ¨™ç±¤\"\"\"\n",
    "    if score >= 7:\n",
    "        return \"éå¸¸å¼· ğŸ’ª\"\n",
    "    elif score >= 5:\n",
    "        return \"å¼· ğŸ‘\"\n",
    "    elif score >= 3:\n",
    "        return \"ä¸­ç­‰ ğŸ‘Œ\"\n",
    "    elif score >= 1:\n",
    "        return \"å¼± âš ï¸\"\n",
    "    else:\n",
    "        return \"æ¥µå¼± âŒ\"\n",
    "\n",
    "def print_password_report(password):\n",
    "    \"\"\"é¡¯ç¤ºå¯†ç¢¼é©—è­‰å ±å‘Š\"\"\"\n",
    "    results = validate_password(password)\n",
    "    \n",
    "    print(f\"\\nå¯†ç¢¼ï¼š{'*' * len(password)}\")\n",
    "    print(f\"å¼·åº¦åˆ†æ•¸ï¼š{results['strength']} / 8\")\n",
    "    print(f\"å¼·åº¦ç­‰ç´šï¼š{get_strength_label(results['strength'])}\")\n",
    "    print(f\"æ˜¯å¦æœ‰æ•ˆï¼š{'âœ“' if results['valid'] else 'âœ—'}\")\n",
    "    \n",
    "    print(\"\\næª¢æŸ¥é …ç›®ï¼š\")\n",
    "    checks = results['checks']\n",
    "    print(f\"  é•·åº¦ (â‰¥8): {'âœ“' if checks.get('length') else 'âœ—'}\")\n",
    "    print(f\"  å¤§å¯«å­—æ¯: {'âœ“' if checks.get('uppercase') else 'âœ—'}\")\n",
    "    print(f\"  å°å¯«å­—æ¯: {'âœ“' if checks.get('lowercase') else 'âœ—'}\")\n",
    "    print(f\"  æ•¸å­—: {'âœ“' if checks.get('digit') else 'âœ—'}\")\n",
    "    print(f\"  ç‰¹æ®Šå­—å…ƒ: {'âœ“' if checks.get('special') else 'âœ—'}\")\n",
    "    \n",
    "    if results['feedback']:\n",
    "        print(\"\\nå»ºè­°ï¼š\")\n",
    "        for tip in results['feedback']:\n",
    "            print(f\"  â€¢ {tip}\")\n",
    "\n",
    "# æ¸¬è©¦ç¨‹å¼\n",
    "print(\"=== å¯†ç¢¼é©—è­‰å™¨ ===\")\n",
    "\n",
    "test_passwords = [\n",
    "    \"abc\",           # æ¥µå¼±\n",
    "    \"password\",      # å¼±\n",
    "    \"Password123\",   # ä¸­ç­‰\n",
    "    \"P@ssw0rd\",      # å¼·\n",
    "    \"P@ssw0rd!2024\", # éå¸¸å¼·\n",
    "]\n",
    "\n",
    "for pwd in test_passwords:\n",
    "    print_password_report(pwd)\n",
    "    print(\"-\" * 50)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å»¶ä¼¸æ€è€ƒ\n",
    "1. å¦‚ä½•æª¢æŸ¥å¯†ç¢¼æ˜¯å¦ç‚ºå¸¸è¦‹å¼±å¯†ç¢¼ï¼ˆå¦‚ password123ï¼‰ï¼Ÿ\n",
    "2. å¦‚ä½•æª¢æŸ¥å¯†ç¢¼æ˜¯å¦åŒ…å«ä½¿ç”¨è€…åç¨±ï¼Ÿ\n",
    "3. å¦‚ä½•å¯¦ä½œå¯†ç¢¼å¼·åº¦å³æ™‚å›é¥‹ï¼ˆå¦‚ç¶²é è¡¨å–®ï¼‰ï¼Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 5ï¼šç°¡æ˜“æ–‡å­—åˆ†æå™¨\n",
    "\n",
    "### å•é¡Œæè¿°\n",
    "é–‹ç™¼ä¸€å€‹æ–‡å­—åˆ†æå·¥å…·ï¼Œèƒ½å¤ ï¼š\n",
    "1. çµ±è¨ˆå­—æ•¸ã€å¥æ•¸ã€æ®µè½æ•¸\n",
    "2. è¨ˆç®—å¹³å‡å­—æ•¸\n",
    "3. æ‰¾å‡ºæœ€å¸¸è¦‹çš„è©å½™\n",
    "4. è¨ˆç®—å­—å…ƒé »ç‡\n",
    "5. åˆ†æé–±è®€æ™‚é–“\n",
    "\n",
    "### æ€è·¯åˆ†æ\n",
    "- ä½¿ç”¨ `split()` åˆ†å‰²å–®å­—\n",
    "- ä½¿ç”¨å­—å…¸çµ±è¨ˆè©é »\n",
    "- ä½¿ç”¨å­—ä¸²æ–¹æ³•è™•ç†æ¨™é»ç¬¦è™Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_text(text):\n",
    "    \"\"\"åˆ†ææ–‡å­—å…§å®¹\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # åŸºæœ¬çµ±è¨ˆ\n",
    "    results['char_count'] = len(text)\n",
    "    results['char_count_no_space'] = len(text.replace(' ', ''))\n",
    "    \n",
    "    # æ®µè½æ•¸ï¼ˆä»¥é›™æ›è¡Œåˆ†éš”ï¼‰\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    results['paragraph_count'] = len(paragraphs)\n",
    "    \n",
    "    # å¥æ•¸ï¼ˆç°¡åŒ–ï¼šä»¥ .!? çµå°¾ï¼‰\n",
    "    sentence_enders = '.!?'\n",
    "    results['sentence_count'] = sum(text.count(c) for c in sentence_enders)\n",
    "    \n",
    "    # ç§»é™¤æ¨™é»ç¬¦è™Ÿä¸¦åˆ†å‰²å–®å­—\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    clean_text = text.translate(translator)\n",
    "    words = clean_text.lower().split()\n",
    "    \n",
    "    results['word_count'] = len(words)\n",
    "    results['unique_words'] = len(set(words))\n",
    "    \n",
    "    # å¹³å‡å€¼\n",
    "    if results['sentence_count'] > 0:\n",
    "        results['avg_words_per_sentence'] = results['word_count'] / results['sentence_count']\n",
    "    else:\n",
    "        results['avg_words_per_sentence'] = 0\n",
    "    \n",
    "    if results['word_count'] > 0:\n",
    "        results['avg_word_length'] = sum(len(w) for w in words) / len(words)\n",
    "    else:\n",
    "        results['avg_word_length'] = 0\n",
    "    \n",
    "    # è©é »çµ±è¨ˆï¼ˆå‰ 5 åï¼‰\n",
    "    word_freq = Counter(words)\n",
    "    results['top_words'] = word_freq.most_common(5)\n",
    "    \n",
    "    # å­—å…ƒé »ç‡ï¼ˆè‹±æ–‡å­—æ¯ï¼‰\n",
    "    letters = [c.lower() for c in text if c.isalpha()]\n",
    "    letter_freq = Counter(letters)\n",
    "    results['top_letters'] = letter_freq.most_common(5)\n",
    "    \n",
    "    # é–±è®€æ™‚é–“ä¼°ç®—ï¼ˆå¹³å‡ 200 å­—/åˆ†é˜ï¼‰\n",
    "    results['reading_time'] = results['word_count'] / 200\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_analysis(text):\n",
    "    \"\"\"é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
    "    results = analyze_text(text)\n",
    "    \n",
    "    print(\"æ–‡å­—åˆ†æå ±å‘Š\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nåŸºæœ¬çµ±è¨ˆï¼š\")\n",
    "    print(f\"  ç¸½å­—å…ƒæ•¸ï¼š{results['char_count']:,}\")\n",
    "    print(f\"  å­—å…ƒæ•¸ï¼ˆä¸å«ç©ºç™½ï¼‰ï¼š{results['char_count_no_space']:,}\")\n",
    "    print(f\"  æ®µè½æ•¸ï¼š{results['paragraph_count']}\")\n",
    "    print(f\"  å¥æ•¸ï¼š{results['sentence_count']}\")\n",
    "    print(f\"  ç¸½å­—æ•¸ï¼š{results['word_count']:,}\")\n",
    "    print(f\"  ä¸é‡è¤‡å­—æ•¸ï¼š{results['unique_words']:,}\")\n",
    "    \n",
    "    print(\"\\nå¹³å‡å€¼ï¼š\")\n",
    "    print(f\"  æ¯å¥å¹³å‡å­—æ•¸ï¼š{results['avg_words_per_sentence']:.1f}\")\n",
    "    print(f\"  å¹³å‡å­—é•·ï¼š{results['avg_word_length']:.1f} å­—å…ƒ\")\n",
    "    \n",
    "    print(\"\\næœ€å¸¸è¦‹çš„å–®å­—ï¼š\")\n",
    "    for word, count in results['top_words']:\n",
    "        print(f\"  {word}: {count} æ¬¡\")\n",
    "    \n",
    "    print(\"\\næœ€å¸¸è¦‹çš„å­—æ¯ï¼š\")\n",
    "    for letter, count in results['top_letters']:\n",
    "        print(f\"  {letter}: {count} æ¬¡\")\n",
    "    \n",
    "    print(f\"\\né ä¼°é–±è®€æ™‚é–“ï¼š{results['reading_time']:.1f} åˆ†é˜\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# æ¸¬è©¦ç¨‹å¼\n",
    "print(\"=== æ–‡å­—åˆ†æå™¨ ===\")\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Python is a high-level programming language. It is widely used for web development, \n",
    "data analysis, artificial intelligence, and scientific computing.\n",
    "\n",
    "Python's syntax is clear and readable. This makes it an excellent choice for beginners. \n",
    "Many companies use Python for their projects. Python has a large and active community.\n",
    "\n",
    "Learning Python opens many opportunities. You can build web applications, analyze data, \n",
    "or create machine learning models. Python is versatile and powerful!\n",
    "\"\"\"\n",
    "\n",
    "print_analysis(sample_text)\n",
    "\n",
    "# æ¸¬è©¦ä¸­æ–‡æ–‡å­—\n",
    "chinese_text = \"\"\"\n",
    "Python æ˜¯ä¸€ç¨®é«˜éšç¨‹å¼èªè¨€ã€‚å®ƒè¢«å»£æ³›ç”¨æ–¼ç¶²é é–‹ç™¼ã€è³‡æ–™åˆ†æã€äººå·¥æ™ºæ…§å’Œç§‘å­¸è¨ˆç®—ã€‚\n",
    "\n",
    "Python çš„èªæ³•æ¸…æ™°æ˜“è®€ã€‚é€™ä½¿å®ƒæˆç‚ºåˆå­¸è€…çš„çµ•ä½³é¸æ“‡ã€‚è¨±å¤šå…¬å¸ä½¿ç”¨ Python é–‹ç™¼å°ˆæ¡ˆã€‚\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ä¸­æ–‡æ–‡å­—åˆ†æï¼š\")\n",
    "print(\"=\" * 50)\n",
    "print_analysis(chinese_text)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å»¶ä¼¸æ€è€ƒ\n",
    "1. å¦‚ä½•æ”¯æ´ä¸­æ–‡åˆ†è©ï¼ˆéœ€è¦å¤–éƒ¨å¥—ä»¶å¦‚ jiebaï¼‰ï¼Ÿ\n",
    "2. å¦‚ä½•åˆ†ææ–‡å­—çš„æƒ…æ„Ÿï¼ˆæ­£é¢/è² é¢ï¼‰ï¼Ÿ\n",
    "3. å¦‚ä½•è¨ˆç®—æ–‡å­—çš„å¯è®€æ€§åˆ†æ•¸ï¼ˆFlesch Reading Easeï¼‰ï¼Ÿ\n",
    "4. å¦‚ä½•æ‰¾å‡ºé—œéµå­—ï¼ˆTF-IDFï¼‰ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## ç¸½çµ\n",
    "\n",
    "é€™ 5 å€‹ç¯„ä¾‹å±•ç¤ºäº†å…ƒçµ„èˆ‡å­—ä¸²åœ¨å¯¦å‹™ä¸­çš„æ‡‰ç”¨ï¼š\n",
    "\n",
    "1. **ç¯„ä¾‹ 1**ï¼šå…ƒçµ„ç”¨æ–¼å„²å­˜åº§æ¨™ã€å¤šå›å‚³å€¼\n",
    "2. **ç¯„ä¾‹ 2**ï¼šå­—ä¸²æ¸…ç†èˆ‡æ¨™æº–åŒ–\n",
    "3. **ç¯„ä¾‹ 3**ï¼šCSV è³‡æ–™è§£æèˆ‡é©—è­‰\n",
    "4. **ç¯„ä¾‹ 4**ï¼šå¯†ç¢¼é©—è­‰èˆ‡å®‰å…¨æ€§æª¢æŸ¥\n",
    "5. **ç¯„ä¾‹ 5**ï¼šæ–‡å­—åˆ†æèˆ‡çµ±è¨ˆ\n",
    "\n",
    "**é—œéµæŠ€å·§**ï¼š\n",
    "- å…ƒçµ„è§£åŒ…ç°¡åŒ–ç¨‹å¼ç¢¼\n",
    "- å­—ä¸²æ–¹æ³•éˆå¼å‘¼å«\n",
    "- `split()` + `join()` è™•ç†æ–‡å­—\n",
    "- å­—ä¸²é©—è­‰èˆ‡æ¸…ç†\n",
    "- è©é »çµ±è¨ˆèˆ‡åˆ†æ\n",
    "\n",
    "ç¹¼çºŒç·´ç¿’ `03-practice.ipynb` å’Œ `04-exercises.ipynb` ä»¥éå›ºé€™äº›æŠ€èƒ½ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
