{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 04: æ–‡å­—è™•ç†å·¥å…·ç®± - éœ€æ±‚è¦æ ¼æ›¸\n",
    "\n",
    "## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°\n",
    "\n",
    "æœ¬å°ˆæ¡ˆæ—¨åœ¨æ•´åˆ **Ch12-15** çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå»ºç«‹ä¸€å€‹åŠŸèƒ½å®Œæ•´çš„æ–‡å­—è™•ç†å·¥å…·ç®±ã€‚é€éæ¨¡çµ„åŒ–çš„å‡½å¼è¨­è¨ˆï¼Œå±•ç¤ºå‡½å¼å¼ç¨‹å¼è¨­è¨ˆçš„å¨åŠ›ã€‚\n",
    "\n",
    "### æŠ€è¡“æ•´åˆé‡é»\n",
    "- **Ch12 å‡½å¼è¨­è¨ˆåŸºç¤**: æ¨¡çµ„åŒ–è¨­è¨ˆã€åƒæ•¸è™•ç†ã€æ–‡ä»¶å­—ä¸²\n",
    "- **Ch13 ä½œç”¨åŸŸèˆ‡ç”Ÿå‘½é€±æœŸ**: å…§åµŒå‡½å¼ã€é–‰åŒ…ã€è®Šæ•¸ä½œç”¨åŸŸ\n",
    "- **Ch14 é«˜éšå‡½å¼èˆ‡ Lambda**: map/filter/reduceã€å‡½å¼çµ„åˆ\n",
    "- **Ch15 éè¿´æ€ç¶­**: éè¿´æª”æ¡ˆè™•ç†ã€åˆ†æ²»æ³•æ‡‰ç”¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ åŠŸèƒ½éœ€æ±‚è©³ç´°è¦æ ¼\n",
    "\n",
    "### æ¨¡çµ„ 1: æ–‡å­—çµ±è¨ˆæ¨¡çµ„ (statistics)\n",
    "\n",
    "#### å¿…é ˆå¯¦ä½œçš„å‡½å¼:\n",
    "\n",
    "**1. åŸºæœ¬çµ±è¨ˆå‡½å¼**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_characters(text):\n",
    "    \"\"\"\n",
    "    çµ±è¨ˆæ–‡å­—å­—å…ƒæ•¸é‡ï¼ˆå«ç©ºæ ¼èˆ‡æ¨™é»ï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦çµ±è¨ˆçš„æ–‡å­—\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: åŒ…å«å„ç¨®å­—å…ƒçµ±è¨ˆè³‡è¨Š\n",
    "        {\n",
    "            'total_chars': int,      # ç¸½å­—å…ƒæ•¸\n",
    "            'alphabetic': int,       # å­—æ¯æ•¸é‡\n",
    "            'numeric': int,          # æ•¸å­—æ•¸é‡\n",
    "            'whitespace': int,       # ç©ºç™½å­—å…ƒæ•¸\n",
    "            'punctuation': int       # æ¨™é»ç¬¦è™Ÿæ•¸\n",
    "        }\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> count_characters(\"Hello, World! 123\")\n",
    "        {'total_chars': 17, 'alphabetic': 10, 'numeric': 3, 'whitespace': 2, 'punctuation': 2}\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    çµ±è¨ˆè©å½™æ•¸é‡èˆ‡è©é »\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦åˆ†æçš„æ–‡å­—\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: è©å½™çµ±è¨ˆçµæœ\n",
    "        {\n",
    "            'total_words': int,           # ç¸½è©æ•¸\n",
    "            'unique_words': int,          # ä¸é‡è¤‡è©æ•¸\n",
    "            'word_frequency': dict,       # è©é »å­—å…¸ {word: count}\n",
    "            'average_word_length': float  # å¹³å‡è©é•·\n",
    "        }\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> count_words(\"Python is great. Python is powerful.\")\n",
    "        {\n",
    "            'total_words': 6,\n",
    "            'unique_words': 5,\n",
    "            'word_frequency': {'python': 2, 'is': 2, 'great': 1, 'powerful': 1},\n",
    "            'average_word_length': 5.5\n",
    "        }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def count_lines(text):\n",
    "    \"\"\"\n",
    "    çµ±è¨ˆè¡Œæ•¸ç›¸é—œè³‡è¨Š\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦åˆ†æçš„æ–‡å­—\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: è¡Œæ•¸çµ±è¨ˆçµæœ\n",
    "        {\n",
    "            'total_lines': int,       # ç¸½è¡Œæ•¸\n",
    "            'non_empty_lines': int,   # éç©ºç™½è¡Œæ•¸\n",
    "            'empty_lines': int,       # ç©ºç™½è¡Œæ•¸\n",
    "            'average_line_length': float  # å¹³å‡è¡Œé•·\n",
    "        }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def analyze_text_statistics(text):\n",
    "    \"\"\"\n",
    "    ç¶œåˆæ–‡å­—çµ±è¨ˆåˆ†æï¼ˆæ•´åˆä¸Šè¿°æ‰€æœ‰å‡½å¼ï¼‰\n",
    "    å±•ç¤º Ch12 å‡½å¼çµ„åˆæ¦‚å¿µ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦åˆ†æçš„æ–‡å­—\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: å®Œæ•´çµ±è¨ˆå ±å‘Š\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ç¯„ä¾‹è¼¸å…¥èˆ‡è¼¸å‡º:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦è³‡æ–™\n",
    "sample_text = \"\"\"\n",
    "Python æ˜¯ä¸€ç¨®é«˜éšç¨‹å¼èªè¨€ã€‚\n",
    "å®ƒæ˜“æ–¼å­¸ç¿’ä¸”åŠŸèƒ½å¼·å¤§ã€‚\n",
    "\n",
    "è¨±å¤šå…¬å¸éƒ½ä½¿ç”¨ Python é–‹ç™¼è»Ÿé«”ã€‚\n",
    "Python çš„èªæ³•ç°¡æ½”å„ªé›…ã€‚\n",
    "\"\"\"\n",
    "\n",
    "# æœŸæœ›è¼¸å‡ºç¯„ä¾‹\n",
    "expected_output = {\n",
    "    'characters': {\n",
    "        'total_chars': 65,\n",
    "        'alphabetic': 35,\n",
    "        'numeric': 0,\n",
    "        'whitespace': 15,\n",
    "        'punctuation': 4\n",
    "    },\n",
    "    'words': {\n",
    "        'total_words': 18,\n",
    "        'unique_words': 15,\n",
    "        'word_frequency': {\n",
    "            'python': 3,\n",
    "            'æ˜¯': 1,\n",
    "            'ä¸€ç¨®': 1,\n",
    "            # ... å…¶ä»–è©å½™\n",
    "        },\n",
    "        'average_word_length': 2.8\n",
    "    },\n",
    "    'lines': {\n",
    "        'total_lines': 6,\n",
    "        'non_empty_lines': 4,\n",
    "        'empty_lines': 2,\n",
    "        'average_line_length': 16.25\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡çµ„ 2: æ–‡å­—æœå°‹æ¨¡çµ„ (search)\n",
    "\n",
    "#### å¿…é ˆå¯¦ä½œçš„å‡½å¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword(text, keyword, case_sensitive=False):\n",
    "    \"\"\"\n",
    "    åœ¨æ–‡å­—ä¸­æœå°‹é—œéµå­—\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦æœå°‹çš„æ–‡å­—\n",
    "        keyword (str): é—œéµå­—\n",
    "        case_sensitive (bool): æ˜¯å¦å€åˆ†å¤§å°å¯«\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: æœå°‹çµæœ\n",
    "        {\n",
    "            'keyword': str,           # æœå°‹çš„é—œéµå­—\n",
    "            'count': int,             # å‡ºç¾æ¬¡æ•¸\n",
    "            'positions': list,        # å‡ºç¾ä½ç½®åˆ—è¡¨ [start_index, ...]\n",
    "            'line_numbers': list,     # å‡ºç¾è¡Œè™Ÿåˆ—è¡¨ [line_num, ...]\n",
    "            'context_lines': list     # åŒ…å«é—œéµå­—çš„å®Œæ•´è¡Œå…§å®¹\n",
    "        }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def find_multiple_keywords(text, keywords, case_sensitive=False):\n",
    "    \"\"\"\n",
    "    åŒæ™‚æœå°‹å¤šå€‹é—œéµå­—\n",
    "    å±•ç¤º Ch14 map å‡½å¼æ‡‰ç”¨\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦æœå°‹çš„æ–‡å­—\n",
    "        keywords (list): é—œéµå­—åˆ—è¡¨\n",
    "        case_sensitive (bool): æ˜¯å¦å€åˆ†å¤§å°å¯«\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: {keyword: search_result} çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def search_in_lines(text, pattern, filter_func=None):\n",
    "    \"\"\"\n",
    "    æŒ‰è¡Œæœå°‹ä¸¦æ”¯æ´è‡ªè¨‚éæ¿¾æ¢ä»¶\n",
    "    å±•ç¤º Ch14 filter å‡½å¼èˆ‡ Lambda æ‡‰ç”¨\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦æœå°‹çš„æ–‡å­—\n",
    "        pattern (str): æœå°‹æ¨¡å¼\n",
    "        filter_func (callable): è‡ªè¨‚éæ¿¾å‡½å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        list: ç¬¦åˆæ¢ä»¶çš„è¡Œåˆ—è¡¨\n",
    "        [\n",
    "            {\n",
    "                'line_number': int,\n",
    "                'content': str,\n",
    "                'match_count': int\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        # æœå°‹åŒ…å« \"Python\" ä¸”è¡Œé•·åº¦ > 10 çš„è¡Œ\n",
    "        >>> search_in_lines(text, \"Python\", lambda line: len(line) > 10)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡çµ„ 3: æ–‡å­—è½‰æ›æ¨¡çµ„ (transform)\n",
    "\n",
    "#### å¿…é ˆå¯¦ä½œçš„å‡½å¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_case(text, mode='lower'):\n",
    "    \"\"\"\n",
    "    è½‰æ›æ–‡å­—å¤§å°å¯«\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦è½‰æ›çš„æ–‡å­—\n",
    "        mode (str): è½‰æ›æ¨¡å¼ ('lower', 'upper', 'title', 'capitalize')\n",
    "    \n",
    "    å›å‚³:\n",
    "        str: è½‰æ›å¾Œçš„æ–‡å­—\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def replace_text_advanced(text, replacements, use_regex=False):\n",
    "    \"\"\"\n",
    "    é€²éšæ–‡å­—æ›¿æ›åŠŸèƒ½\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): åŸå§‹æ–‡å­—\n",
    "        replacements (dict): æ›¿æ›è¦å‰‡ {old: new}\n",
    "        use_regex (bool): æ˜¯å¦ä½¿ç”¨æ­£è¦è¡¨é”å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        str: æ›¿æ›å¾Œçš„æ–‡å­—\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> replace_text_advanced(\"Hello World\", {\"Hello\": \"Hi\", \"World\": \"Python\"})\n",
    "        \"Hi Python\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def create_text_transformer(config):\n",
    "    \"\"\"\n",
    "    å»ºç«‹å®¢è£½åŒ–æ–‡å­—è½‰æ›å™¨ï¼ˆå±•ç¤º Ch13 é–‰åŒ…æ¦‚å¿µï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        config (dict): è½‰æ›è¨­å®š\n",
    "        {\n",
    "            'case_mode': str,      # å¤§å°å¯«æ¨¡å¼\n",
    "            'remove_punctuation': bool,\n",
    "            'replace_numbers': bool,\n",
    "            'custom_replacements': dict\n",
    "        }\n",
    "    \n",
    "    å›å‚³:\n",
    "        function: è½‰æ›å‡½å¼ï¼ˆé–‰åŒ…ï¼‰\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> transformer = create_text_transformer({\n",
    "        ...     'case_mode': 'lower',\n",
    "        ...     'remove_punctuation': True\n",
    "        ... })\n",
    "        >>> transformer(\"Hello, World!\")\n",
    "        \"hello world\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def batch_transform_texts(text_list, transform_func):\n",
    "    \"\"\"\n",
    "    æ‰¹æ¬¡è™•ç†æ–‡å­—åˆ—è¡¨ï¼ˆå±•ç¤º Ch14 map å‡½å¼ï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text_list (list): æ–‡å­—åˆ—è¡¨\n",
    "        transform_func (callable): è½‰æ›å‡½å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        list: è½‰æ›å¾Œçš„æ–‡å­—åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡çµ„ 4: æ–‡å­—æ ¼å¼åŒ–æ¨¡çµ„ (format)\n",
    "\n",
    "#### å¿…é ˆå¯¦ä½œçš„å‡½å¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_text(text, width=80, alignment='left'):\n",
    "    \"\"\"\n",
    "    æ–‡å­—å°é½Šè™•ç†\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦å°é½Šçš„æ–‡å­—\n",
    "        width (int): å°é½Šå¯¬åº¦\n",
    "        alignment (str): å°é½Šæ–¹å¼ ('left', 'right', 'center')\n",
    "    \n",
    "    å›å‚³:\n",
    "        str: å°é½Šå¾Œçš„æ–‡å­—\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def indent_lines(text, indent_size=4, indent_char=' '):\n",
    "    \"\"\"\n",
    "    ç‚ºæ–‡å­—è¡Œæ·»åŠ ç¸®æ’\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦ç¸®æ’çš„æ–‡å­—\n",
    "        indent_size (int): ç¸®æ’å¤§å°\n",
    "        indent_char (str): ç¸®æ’å­—å…ƒ\n",
    "    \n",
    "    å›å‚³:\n",
    "        str: ç¸®æ’å¾Œçš„æ–‡å­—\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def create_columns(text_list, columns=2, separator='  |  '):\n",
    "    \"\"\"\n",
    "    å°‡æ–‡å­—åˆ—è¡¨æ ¼å¼åŒ–ç‚ºå¤šæ¬„é¡¯ç¤º\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text_list (list): æ–‡å­—åˆ—è¡¨\n",
    "        columns (int): æ¬„æ•¸\n",
    "        separator (str): æ¬„åˆ†éš”ç¬¦\n",
    "    \n",
    "    å›å‚³:\n",
    "        str: æ ¼å¼åŒ–å¾Œçš„å¤šæ¬„æ–‡å­—\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> create_columns(['Apple', 'Banana', 'Cherry', 'Date'], columns=2)\n",
    "        \"Apple   |  Banana\\nCherry  |  Date\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def format_table(data, headers=None, align='left'):\n",
    "    \"\"\"\n",
    "    æ ¼å¼åŒ–è³‡æ–™ç‚ºè¡¨æ ¼\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        data (list): è³‡æ–™åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚ºä¸€è¡Œè³‡æ–™\n",
    "        headers (list): è¡¨é ­åˆ—è¡¨\n",
    "        align (str): å°é½Šæ–¹å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        str: æ ¼å¼åŒ–çš„è¡¨æ ¼å­—ä¸²\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡çµ„ 5: æ–‡å­—åˆ†ææ¨¡çµ„ (analysis)\n",
    "\n",
    "#### å¿…é ˆå¯¦ä½œçš„å‡½å¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentences(text):\n",
    "    \"\"\"\n",
    "    å¥å­åˆ†æ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦åˆ†æçš„æ–‡å­—\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: å¥å­åˆ†æçµæœ\n",
    "        {\n",
    "            'sentence_count': int,\n",
    "            'sentences': list,           # æ‰€æœ‰å¥å­åˆ—è¡¨\n",
    "            'average_sentence_length': float,\n",
    "            'longest_sentence': str,\n",
    "            'shortest_sentence': str\n",
    "        }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def detect_duplicates(text, min_length=5):\n",
    "    \"\"\"\n",
    "    æª¢æ¸¬é‡è¤‡ç‰‡æ®µ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦æª¢æ¸¬çš„æ–‡å­—\n",
    "        min_length (int): æœ€å°é‡è¤‡é•·åº¦\n",
    "    \n",
    "    å›å‚³:\n",
    "        list: é‡è¤‡ç‰‡æ®µåˆ—è¡¨\n",
    "        [\n",
    "            {\n",
    "                'fragment': str,      # é‡è¤‡ç‰‡æ®µ\n",
    "                'count': int,         # é‡è¤‡æ¬¡æ•¸\n",
    "                'positions': list     # å‡ºç¾ä½ç½®\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def calculate_readability_score(text):\n",
    "    \"\"\"\n",
    "    è¨ˆç®—æ–‡å­—å¯è®€æ€§åˆ†æ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦åˆ†æçš„æ–‡å­—\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: å¯è®€æ€§åˆ†æçµæœ\n",
    "        {\n",
    "            'avg_sentence_length': float,\n",
    "            'avg_word_length': float,\n",
    "            'complexity_score': float,   # 0-100ï¼Œè¶Šä½è¶Šå®¹æ˜“é–±è®€\n",
    "            'difficulty_level': str      # 'Easy', 'Medium', 'Hard'\n",
    "        }\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ é€²éšéœ€æ±‚ (é¸åšï¼Œé¡å¤–åŠ åˆ†)\n",
    "\n",
    "### æ¨¡çµ„ 6: éè¿´æª”æ¡ˆè™•ç† (recursive) - Ch15 é‡é»\n",
    "\n",
    "#### å±•ç¤ºéè¿´æ€ç¶­çš„å‡½å¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_files_recursive(directory, pattern, file_extension='.txt', max_depth=5):\n",
    "    \"\"\"\n",
    "    éè¿´æœå°‹ç›®éŒ„ä¸­çš„æ–‡å­—æª”æ¡ˆ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        directory (str): æœå°‹ç›®éŒ„è·¯å¾‘\n",
    "        pattern (str): æœå°‹æ¨¡å¼\n",
    "        file_extension (str): æª”æ¡ˆå‰¯æª”å\n",
    "        max_depth (int): æœ€å¤§æœå°‹æ·±åº¦\n",
    "    \n",
    "    å›å‚³:\n",
    "        list: æœå°‹çµæœåˆ—è¡¨\n",
    "        [\n",
    "            {\n",
    "                'file_path': str,     # æª”æ¡ˆè·¯å¾‘\n",
    "                'matches': int,       # ç¬¦åˆæ¬¡æ•¸\n",
    "                'depth': int,         # ç›®éŒ„æ·±åº¦\n",
    "                'file_size': int      # æª”æ¡ˆå¤§å°\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    \n",
    "    æ³¨æ„: å¿…é ˆå±•ç¤ºéè¿´çš„ä¸‰è¦ç´ ï¼š\n",
    "    1. åŸºæœ¬æƒ…æ³ï¼ˆBase Caseï¼‰ï¼šé”åˆ°æœ€å¤§æ·±åº¦æˆ–æ²’æœ‰å­ç›®éŒ„\n",
    "    2. éè¿´æƒ…æ³ï¼ˆRecursive Caseï¼‰ï¼šå°å­ç›®éŒ„é€²è¡Œéè¿´æœå°‹\n",
    "    3. ç‹€æ…‹æ”¹è®Šï¼šæ·±åº¦éå¢\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def count_pattern_recursive(text, pattern):\n",
    "    \"\"\"\n",
    "    éè¿´è¨ˆç®—æ¨¡å¼å‡ºç¾æ¬¡æ•¸\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦æœå°‹çš„æ–‡å­—\n",
    "        pattern (str): æœå°‹æ¨¡å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        int: æ¨¡å¼å‡ºç¾æ¬¡æ•¸\n",
    "    \n",
    "    æ³¨æ„: é€™æ˜¯å±•ç¤ºéè¿´æ€ç¶­çš„ç·´ç¿’ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­ç›´æ¥ä½¿ç”¨ text.count() æ›´é«˜æ•ˆ\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def parse_nested_structure(text, open_tag='[', close_tag=']'):\n",
    "    \"\"\"\n",
    "    éè¿´è§£æå·¢ç‹€çµæ§‹ï¼ˆå¦‚æ‹¬è™ŸåŒ¹é…ï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text (str): è¦è§£æçš„æ–‡å­—\n",
    "        open_tag (str): é–‹å§‹æ¨™è¨˜\n",
    "        close_tag (str): çµæŸæ¨™è¨˜\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: è§£æçµæœ\n",
    "        {\n",
    "            'is_balanced': bool,      # æ˜¯å¦å¹³è¡¡\n",
    "            'max_depth': int,         # æœ€å¤§å·¢ç‹€æ·±åº¦\n",
    "            'structure': list         # å·¢ç‹€çµæ§‹åˆ—è¡¨\n",
    "        }\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> parse_nested_structure(\"[A[B[C]D]E]\")\n",
    "        {'is_balanced': True, 'max_depth': 3, 'structure': ['A', ['B', ['C'], 'D'], 'E']}\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡çµ„ 7: é«˜éšå‡½å¼æ‡‰ç”¨ (functional) - Ch14 é‡é»\n",
    "\n",
    "#### å±•ç¤ºå‡½å¼å¼ç¨‹å¼è¨­è¨ˆçš„å‡½å¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_pipeline(*operations):\n",
    "    \"\"\"\n",
    "    å»ºç«‹æ–‡å­—è™•ç†æµæ°´ç·šï¼ˆå±•ç¤ºå‡½å¼çµ„åˆï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        *operations: å¯è®Šæ•¸é‡çš„è™•ç†å‡½å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        function: çµ„åˆå¾Œçš„è™•ç†å‡½å¼\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> pipeline = create_text_pipeline(\n",
    "        ...     lambda x: x.lower(),\n",
    "        ...     lambda x: x.replace(' ', '_'),\n",
    "        ...     lambda x: x.strip()\n",
    "        ... )\n",
    "        >>> pipeline(\"  Hello World  \")\n",
    "        \"hello_world\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def apply_text_filters(text_list, *filters):\n",
    "    \"\"\"\n",
    "    ä¾åºå¥—ç”¨å¤šå€‹éæ¿¾å™¨ï¼ˆå±•ç¤º filter å‡½å¼é€£é–ï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text_list (list): æ–‡å­—åˆ—è¡¨\n",
    "        *filters: å¯è®Šæ•¸é‡çš„éæ¿¾å‡½å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        list: éæ¿¾å¾Œçš„æ–‡å­—åˆ—è¡¨\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> apply_text_filters(\n",
    "        ...     [\"hello\", \"\", \"world\", \"python\"],\n",
    "        ...     lambda x: x != \"\",           # ç§»é™¤ç©ºå­—ä¸²\n",
    "        ...     lambda x: len(x) > 4         # ä¿ç•™é•·åº¦ > 4 çš„è©\n",
    "        ... )\n",
    "        [\"hello\", \"world\", \"python\"]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def reduce_text_analysis(text_list, analysis_func):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ reduce é€²è¡Œæ–‡å­—åˆ†æèšåˆ\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        text_list (list): æ–‡å­—åˆ—è¡¨\n",
    "        analysis_func (callable): åˆ†æå‡½å¼\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: èšåˆåˆ†æçµæœ\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> reduce_text_analysis(\n",
    "        ...     [\"hello world\", \"python rocks\"],\n",
    "        ...     lambda acc, text: {\n",
    "        ...         'total_words': acc.get('total_words', 0) + len(text.split()),\n",
    "        ...         'total_chars': acc.get('total_chars', 0) + len(text)\n",
    "        ...     }\n",
    "        ... )\n",
    "        {'total_words': 4, 'total_chars': 23}\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def create_custom_filters():\n",
    "    \"\"\"\n",
    "    å»ºç«‹å¸¸ç”¨çš„ Lambda éæ¿¾å™¨é›†åˆ\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: éæ¿¾å™¨å­—å…¸\n",
    "        {\n",
    "            'non_empty': lambda,           # éç©ºéæ¿¾å™¨\n",
    "            'min_length': lambda,          # æœ€å°é•·åº¦éæ¿¾å™¨ï¼ˆè¿”å›é«˜éšå‡½å¼ï¼‰\n",
    "            'contains_keyword': lambda,    # åŒ…å«é—œéµå­—éæ¿¾å™¨ï¼ˆè¿”å›é«˜éšå‡½å¼ï¼‰\n",
    "            'starts_with': lambda,         # é–‹é ­åŒ¹é…éæ¿¾å™¨ï¼ˆè¿”å›é«˜éšå‡½å¼ï¼‰\n",
    "            'ends_with': lambda            # çµå°¾åŒ¹é…éæ¿¾å™¨ï¼ˆè¿”å›é«˜éšå‡½å¼ï¼‰\n",
    "        }\n",
    "    \n",
    "    ç¯„ä¾‹:\n",
    "        >>> filters = create_custom_filters()\n",
    "        >>> min_5_chars = filters['min_length'](5)\n",
    "        >>> min_5_chars(\"hello\")  # True\n",
    "        >>> min_5_chars(\"hi\")     # False\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ç³»çµ±æ•´åˆéœ€æ±‚\n",
    "\n",
    "### ä¸»ç¨‹å¼çµæ§‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_toolkit():\n",
    "    \"\"\"\n",
    "    å»ºç«‹æ–‡å­—è™•ç†å·¥å…·ç®±ä¸»ä»‹é¢\n",
    "    å±•ç¤º Ch12 æ¨¡çµ„åŒ–è¨­è¨ˆ\n",
    "    \n",
    "    å›å‚³:\n",
    "        dict: å·¥å…·ç®±å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰æ¨¡çµ„åŠŸèƒ½\n",
    "        {\n",
    "            'statistics': {\n",
    "                'count_characters': function,\n",
    "                'count_words': function,\n",
    "                'count_lines': function,\n",
    "                'analyze_text_statistics': function\n",
    "            },\n",
    "            'search': {\n",
    "                'find_keyword': function,\n",
    "                'find_multiple_keywords': function,\n",
    "                'search_in_lines': function\n",
    "            },\n",
    "            'transform': {\n",
    "                'transform_case': function,\n",
    "                'replace_text_advanced': function,\n",
    "                'create_text_transformer': function,\n",
    "                'batch_transform_texts': function\n",
    "            },\n",
    "            'format': {\n",
    "                'align_text': function,\n",
    "                'indent_lines': function,\n",
    "                'create_columns': function,\n",
    "                'format_table': function\n",
    "            },\n",
    "            'analysis': {\n",
    "                'analyze_sentences': function,\n",
    "                'detect_duplicates': function,\n",
    "                'calculate_readability_score': function\n",
    "            },\n",
    "            # é€²éšæ¨¡çµ„ï¼ˆé¸åšï¼‰\n",
    "            'recursive': {\n",
    "                'search_files_recursive': function,\n",
    "                'count_pattern_recursive': function,\n",
    "                'parse_nested_structure': function\n",
    "            },\n",
    "            'functional': {\n",
    "                'create_text_pipeline': function,\n",
    "                'apply_text_filters': function,\n",
    "                'reduce_text_analysis': function,\n",
    "                'create_custom_filters': function\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def interactive_menu():\n",
    "    \"\"\"\n",
    "    äº’å‹•å¼é¸å–®ç³»çµ±\n",
    "    \n",
    "    åŠŸèƒ½é¸å–®:\n",
    "    1. æ–‡å­—çµ±è¨ˆåˆ†æ\n",
    "    2. æ–‡å­—æœå°‹åŠŸèƒ½\n",
    "    3. æ–‡å­—è½‰æ›å·¥å…·\n",
    "    4. æ–‡å­—æ ¼å¼åŒ–\n",
    "    5. æ–‡å­—æ·±åº¦åˆ†æ\n",
    "    6. éè¿´æª”æ¡ˆè™•ç† (é€²éš)\n",
    "    7. å‡½å¼å¼è™•ç† (é€²éš)\n",
    "    0. çµæŸç¨‹å¼\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def handle_menu_choice(choice, toolkit):\n",
    "    \"\"\"\n",
    "    è™•ç†é¸å–®é¸æ“‡\n",
    "    \n",
    "    åƒæ•¸:\n",
    "        choice (str): ä½¿ç”¨è€…é¸æ“‡\n",
    "        toolkit (dict): å·¥å…·ç®±ç‰©ä»¶\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ¸¬è©¦éœ€æ±‚\n",
    "\n",
    "### å¿…é ˆé€šéçš„æ¸¬è©¦æ¡ˆä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_toolkit():\n",
    "    \"\"\"\n",
    "    å®Œæ•´åŠŸèƒ½æ¸¬è©¦å¥—ä»¶\n",
    "    æ‰€æœ‰å¯¦ä½œéƒ½å¿…é ˆé€šéé€™äº›æ¸¬è©¦\n",
    "    \"\"\"\n",
    "    \n",
    "    # æ¸¬è©¦è³‡æ–™\n",
    "    test_text = \"\"\"\n",
    "    Python æ˜¯ä¸€ç¨®é«˜éšç¨‹å¼èªè¨€ã€‚\n",
    "    Python æ˜“æ–¼å­¸ç¿’ä¸”åŠŸèƒ½å¼·å¤§ã€‚\n",
    "    è¨±å¤šå…¬å¸éƒ½ä½¿ç”¨ Python é–‹ç™¼è»Ÿé«”ã€‚\n",
    "    Python çš„èªæ³•ç°¡æ½”å„ªé›…ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª é–‹å§‹æ¸¬è©¦æ–‡å­—è™•ç†å·¥å…·ç®±...\")\n",
    "    \n",
    "    # æ¸¬è©¦ 1: æ–‡å­—çµ±è¨ˆ\n",
    "    print(\"\\n1. æ¸¬è©¦æ–‡å­—çµ±è¨ˆæ¨¡çµ„\")\n",
    "    stats = analyze_text_statistics(test_text)\n",
    "    assert 'characters' in stats, \"ç¼ºå°‘å­—å…ƒçµ±è¨ˆ\"\n",
    "    assert 'words' in stats, \"ç¼ºå°‘è©å½™çµ±è¨ˆ\"\n",
    "    assert 'lines' in stats, \"ç¼ºå°‘è¡Œæ•¸çµ±è¨ˆ\"\n",
    "    assert stats['words']['word_frequency']['python'] == 4, \"è©é »çµ±è¨ˆéŒ¯èª¤\"\n",
    "    print(\"âœ… æ–‡å­—çµ±è¨ˆæ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 2: æœå°‹åŠŸèƒ½\n",
    "    print(\"\\n2. æ¸¬è©¦æ–‡å­—æœå°‹æ¨¡çµ„\")\n",
    "    search_result = find_keyword(test_text, \"Python\")\n",
    "    assert search_result['count'] == 4, \"æœå°‹è¨ˆæ•¸éŒ¯èª¤\"\n",
    "    assert len(search_result['positions']) == 4, \"ä½ç½®è¨˜éŒ„éŒ¯èª¤\"\n",
    "    print(\"âœ… æ–‡å­—æœå°‹æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 3: è½‰æ›åŠŸèƒ½\n",
    "    print(\"\\n3. æ¸¬è©¦æ–‡å­—è½‰æ›æ¨¡çµ„\")\n",
    "    lower_text = transform_case(test_text, 'lower')\n",
    "    assert 'PYTHON' not in lower_text, \"å¤§å°å¯«è½‰æ›å¤±æ•—\"\n",
    "    print(\"âœ… æ–‡å­—è½‰æ›æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 4: æ ¼å¼åŒ–åŠŸèƒ½\n",
    "    print(\"\\n4. æ¸¬è©¦æ–‡å­—æ ¼å¼åŒ–æ¨¡çµ„\")\n",
    "    aligned = align_text(\"Test\", width=10, alignment='center')\n",
    "    assert len(aligned.strip()) <= 10, \"å°é½Šå¯¬åº¦éŒ¯èª¤\"\n",
    "    print(\"âœ… æ–‡å­—æ ¼å¼åŒ–æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 5: åˆ†æåŠŸèƒ½\n",
    "    print(\"\\n5. æ¸¬è©¦æ–‡å­—åˆ†ææ¨¡çµ„\")\n",
    "    sentence_analysis = analyze_sentences(test_text)\n",
    "    assert sentence_analysis['sentence_count'] > 0, \"å¥å­åˆ†æå¤±æ•—\"\n",
    "    print(\"âœ… æ–‡å­—åˆ†ææ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 6: é«˜éšå‡½å¼ï¼ˆCh14 é‡é»ï¼‰\n",
    "    print(\"\\n6. æ¸¬è©¦é«˜éšå‡½å¼æ‡‰ç”¨\")\n",
    "    lines = test_text.strip().split('\\n')\n",
    "    non_empty_lines = list(filter(lambda x: x.strip() != '', lines))\n",
    "    assert len(non_empty_lines) == 4, \"filter å‡½å¼æ‡‰ç”¨éŒ¯èª¤\"\n",
    "    \n",
    "    uppercase_lines = list(map(lambda x: x.upper(), non_empty_lines))\n",
    "    assert all('PYTHON' in line for line in uppercase_lines), \"map å‡½å¼æ‡‰ç”¨éŒ¯èª¤\"\n",
    "    print(\"âœ… é«˜éšå‡½å¼æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 7: éè¿´åŠŸèƒ½ï¼ˆCh15 é‡é»ï¼‰\n",
    "    print(\"\\n7. æ¸¬è©¦éè¿´åŠŸèƒ½\")\n",
    "    recursive_count = count_pattern_recursive(test_text, \"Python\")\n",
    "    assert recursive_count == 4, \"éè¿´è¨ˆæ•¸éŒ¯èª¤\"\n",
    "    print(\"âœ… éè¿´åŠŸèƒ½æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    # æ¸¬è©¦ 8: é–‰åŒ…åŠŸèƒ½ï¼ˆCh13 é‡é»ï¼‰\n",
    "    print(\"\\n8. æ¸¬è©¦é–‰åŒ…åŠŸèƒ½\")\n",
    "    transformer = create_text_transformer({\n",
    "        'case_mode': 'lower',\n",
    "        'remove_punctuation': True\n",
    "    })\n",
    "    transformed = transformer(\"Hello, World!\")\n",
    "    assert transformed == \"hello world\", \"é–‰åŒ…è½‰æ›å™¨éŒ¯èª¤\"\n",
    "    print(\"âœ… é–‰åŒ…åŠŸèƒ½æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å·¥å…·ç®±åŠŸèƒ½æ­£å¸¸ã€‚\")\n",
    "\n",
    "# æ•ˆèƒ½æ¸¬è©¦\n",
    "def performance_test():\n",
    "    \"\"\"\n",
    "    æ•ˆèƒ½æ¸¬è©¦ï¼ˆé¸åšï¼‰\n",
    "    æ¸¬è©¦å¤§æ–‡å­—è™•ç†çš„æ•ˆèƒ½\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    # ç”Ÿæˆå¤§æ–‡å­— (10MB)\n",
    "    large_text = \"Python is awesome! \" * 500000\n",
    "    \n",
    "    print(\"â±ï¸ é–‹å§‹æ•ˆèƒ½æ¸¬è©¦...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    stats = analyze_text_statistics(large_text)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    processing_time = end_time - start_time\n",
    "    print(f\"ğŸ“Š è™•ç† {len(large_text):,} å­—å…ƒè€—æ™‚: {processing_time:.2f} ç§’\")\n",
    "    \n",
    "    if processing_time < 5:  # 5ç§’å…§å®Œæˆè¦–ç‚ºåˆæ ¼\n",
    "        print(\"âœ… æ•ˆèƒ½æ¸¬è©¦é€šé\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æ•ˆèƒ½éœ€è¦å„ªåŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ç¨‹å¼ç¢¼å“è³ªè¦æ±‚\n",
    "\n",
    "### 1. æ–‡ä»¶å­—ä¸² (Docstring) è¦æ±‚\n",
    "- æ‰€æœ‰å‡½å¼å¿…é ˆæœ‰å®Œæ•´çš„æ–‡ä»¶å­—ä¸²\n",
    "- åŒ…å«åƒæ•¸èªªæ˜ã€å›å‚³å€¼èªªæ˜ã€ä½¿ç”¨ç¯„ä¾‹\n",
    "- éµå¾ª Google Style æˆ– NumPy Style\n",
    "\n",
    "### 2. ç¨‹å¼ç¢¼é¢¨æ ¼\n",
    "- éµå¾ª PEP 8 è¦ç¯„\n",
    "- ä½¿ç”¨æœ‰æ„ç¾©çš„è®Šæ•¸åç¨±\n",
    "- é©ç•¶çš„è¨»è§£èªªæ˜è¤‡é›œé‚è¼¯\n",
    "\n",
    "### 3. éŒ¯èª¤è™•ç†\n",
    "- è™•ç†ç©ºå­—ä¸²ã€None ç­‰é‚Šç•Œæƒ…æ³\n",
    "- ä½¿ç”¨ try-except è™•ç†å¯èƒ½çš„ä¾‹å¤–\n",
    "- æä¾›æœ‰æ„ç¾©çš„éŒ¯èª¤è¨Šæ¯\n",
    "\n",
    "### 4. å‡½å¼è¨­è¨ˆåŸå‰‡\n",
    "- å–®ä¸€è·è²¬åŸå‰‡ï¼šæ¯å€‹å‡½å¼åªåšä¸€ä»¶äº‹\n",
    "- å‡½å¼é•·åº¦æ§åˆ¶åœ¨ 20-30 è¡Œå…§\n",
    "- é¿å…å…¨åŸŸè®Šæ•¸ï¼Œå„ªå…ˆä½¿ç”¨åƒæ•¸å‚³é\n",
    "- ç›¡é‡ä½¿ç”¨ç´”å‡½å¼ï¼ˆç„¡å‰¯ä½œç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç« ç¯€æ¦‚å¿µå°æ‡‰è¡¨\n",
    "\n",
    "| ç« ç¯€ | æ ¸å¿ƒæ¦‚å¿µ | å°æ‡‰å‡½å¼ | å±•ç¤ºé‡é» |\n",
    "|:-----|:---------|:---------|:---------|\n",
    "| **Ch12 å‡½å¼è¨­è¨ˆåŸºç¤** | æ¨¡çµ„åŒ–è¨­è¨ˆã€åƒæ•¸è™•ç†ã€æ–‡ä»¶å­—ä¸² | `create_text_toolkit()`, `analyze_text_statistics()` | å‡½å¼åˆ†è§£ã€ä»‹é¢è¨­è¨ˆ |\n",
    "| **Ch13 ä½œç”¨åŸŸèˆ‡ç”Ÿå‘½é€±æœŸ** | å…§åµŒå‡½å¼ã€é–‰åŒ…ã€è®Šæ•¸ä½œç”¨åŸŸ | `create_text_transformer()`, `create_text_pipeline()` | é–‰åŒ…å¯¦ä½œã€ç‹€æ…‹ä¿å­˜ |\n",
    "| **Ch14 é«˜éšå‡½å¼èˆ‡ Lambda** | map/filter/reduceã€å‡½å¼çµ„åˆ | `apply_text_filters()`, `batch_transform_texts()` | å‡½å¼å¼ç¨‹å¼è¨­è¨ˆ |\n",
    "| **Ch15 éè¿´æ€ç¶­** | éè¿´çµæ§‹ã€çµ‚æ­¢æ¢ä»¶ã€åˆ†æ²»æ³• | `search_files_recursive()`, `count_pattern_recursive()` | éè¿´æ‡‰ç”¨å ´æ™¯ |\n",
    "\n",
    "## ğŸ“ˆ è©•åˆ†æ¬Šé‡åˆ†é…\n",
    "\n",
    "| è©•åˆ†é …ç›® | é…åˆ† | è©³ç´°èªªæ˜ |\n",
    "|:---------|:-----|:---------|\n",
    "| **åŸºæœ¬åŠŸèƒ½å¯¦ä½œ** | 70% | 5å€‹åŸºæœ¬æ¨¡çµ„åŠŸèƒ½æ­£å¸¸é‹ä½œ |\n",
    "| **Ch12-15 æ¦‚å¿µæ‡‰ç”¨** | 20% | å„ç« ç¯€æ ¸å¿ƒæ¦‚å¿µçš„æ­£ç¢ºå±•ç¤º |\n",
    "| **ç¨‹å¼ç¢¼å“è³ª** | 10% | æ–‡ä»¶ã€é¢¨æ ¼ã€éŒ¯èª¤è™•ç†ã€æ¶æ§‹ |\n",
    "| **é€²éšåŠŸèƒ½** | +30% | éè¿´æª”æ¡ˆè™•ç†ã€å‡½å¼å¼ç¨‹å¼è¨­è¨ˆç­‰ |\n",
    "\n",
    "**ç¸½åˆ†ä¸Šé™**: 130% (åŸºæœ¬ 100% + é€²éš 30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ é–‹ç™¼å»ºè­°\n",
    "\n",
    "### é–‹ç™¼é †åºå»ºè­°:\n",
    "1. **éšæ®µ 1**: å¯¦ä½œåŸºæœ¬çµ±è¨ˆæ¨¡çµ„ï¼ˆç†Ÿæ‚‰å°ˆæ¡ˆçµæ§‹ï¼‰\n",
    "2. **éšæ®µ 2**: å¯¦ä½œæœå°‹å’Œè½‰æ›æ¨¡çµ„ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰\n",
    "3. **éšæ®µ 3**: å¯¦ä½œæ ¼å¼åŒ–å’Œåˆ†ææ¨¡çµ„ï¼ˆå®Œå–„åŠŸèƒ½ï¼‰\n",
    "4. **éšæ®µ 4**: æ•´åˆæ‰€æœ‰æ¨¡çµ„ï¼Œå»ºç«‹ä¸»ä»‹é¢\n",
    "5. **éšæ®µ 5**: å¯¦ä½œé€²éšåŠŸèƒ½ï¼ˆéè¿´ã€é«˜éšå‡½å¼ï¼‰\n",
    "6. **éšæ®µ 6**: æ¸¬è©¦ã€å„ªåŒ–ã€æ–‡ä»¶å®Œå–„\n",
    "\n",
    "### æŠ€è¡“é›£é»æç¤º:\n",
    "- **é–‰åŒ…æ‡‰ç”¨**: æ³¨æ„å¤–å±¤è®Šæ•¸çš„æ­£ç¢ºå¼•ç”¨\n",
    "- **éè¿´è¨­è¨ˆ**: ç¢ºä¿æœ‰æ˜ç¢ºçš„çµ‚æ­¢æ¢ä»¶\n",
    "- **é«˜éšå‡½å¼**: ç†è§£ map/filter/reduce çš„é©ç”¨å ´æ™¯\n",
    "- **éŒ¯èª¤è™•ç†**: è€ƒæ…®å„ç¨®é‚Šç•Œæƒ…æ³\n",
    "\n",
    "### é™¤éŒ¯å»ºè­°:\n",
    "- æ¯å®Œæˆä¸€å€‹å‡½å¼ç«‹å³æ¸¬è©¦\n",
    "- ä½¿ç”¨ `print()` è¼¸å‡ºä¸­é–“çµæœé™¤éŒ¯\n",
    "- å¾ç°¡å–®ç¯„ä¾‹é–‹å§‹ï¼Œé€æ­¥å¢åŠ è¤‡é›œåº¦\n",
    "- å–„ç”¨ Python äº’å‹•æ¨¡å¼æ¸¬è©¦å°ç‰‡æ®µç¨‹å¼ç¢¼\n",
    "\n",
    "---\n",
    "\n",
    "**ç¥ä½ é–‹ç™¼é †åˆ©ï¼è¨˜å¾—å±•ç¤ºæ¯å€‹ç« ç¯€çš„æ ¸å¿ƒæ¦‚å¿µï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}